{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: API details.\n",
    "output-file: optim.html\n",
    "title: Optimizer\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ECL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/antonpf/mlmvn/blob/main/mlmvn/optim.py#L112){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ecl\n",
       "\n",
       ">      ecl (params:List[torch.Tensor], d_p_list:List[torch.Tensor],\n",
       ">           inputs:torch.Tensor, layers:List,\n",
       ">           momentum_buffer_list:List[Optional[torch.Tensor]],\n",
       ">           has_sparse_grad:bool=None, foreach:bool=None, weight_decay:float,\n",
       ">           momentum:float, lr:float, dampening:float, nesterov:bool,\n",
       ">           maximize:bool, clip_angle_value:float)\n",
       "\n",
       "Functional API that performs SGD algorithm computation.\n",
       "\n",
       "See :class:`~torch.optim.SGD` for details.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| params | typing.List[torch.Tensor] |  |  |\n",
       "| d_p_list | typing.List[torch.Tensor] |  |  |\n",
       "| inputs | Tensor |  |  |\n",
       "| layers | typing.List |  |  |\n",
       "| momentum_buffer_list | typing.List[typing.Optional[torch.Tensor]] |  |  |\n",
       "| has_sparse_grad | bool | None | kwonly args with defaults are not supported by functions compiled with torchscript issue #70627<br>setting this as kwarg for now as functional API is compiled by torch/distributed/optim |\n",
       "| foreach | bool | None |  |\n",
       "| weight_decay | float |  |  |\n",
       "| momentum | float |  |  |\n",
       "| lr | float |  |  |\n",
       "| dampening | float |  |  |\n",
       "| nesterov | bool |  |  |\n",
       "| maximize | bool |  |  |\n",
       "| clip_angle_value | float |  |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/antonpf/mlmvn/blob/main/mlmvn/optim.py#L112){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ecl\n",
       "\n",
       ">      ecl (params:List[torch.Tensor], d_p_list:List[torch.Tensor],\n",
       ">           inputs:torch.Tensor, layers:List,\n",
       ">           momentum_buffer_list:List[Optional[torch.Tensor]],\n",
       ">           has_sparse_grad:bool=None, foreach:bool=None, weight_decay:float,\n",
       ">           momentum:float, lr:float, dampening:float, nesterov:bool,\n",
       ">           maximize:bool, clip_angle_value:float)\n",
       "\n",
       "Functional API that performs SGD algorithm computation.\n",
       "\n",
       "See :class:`~torch.optim.SGD` for details.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| params | typing.List[torch.Tensor] |  |  |\n",
       "| d_p_list | typing.List[torch.Tensor] |  |  |\n",
       "| inputs | Tensor |  |  |\n",
       "| layers | typing.List |  |  |\n",
       "| momentum_buffer_list | typing.List[typing.Optional[torch.Tensor]] |  |  |\n",
       "| has_sparse_grad | bool | None | kwonly args with defaults are not supported by functions compiled with torchscript issue #70627<br>setting this as kwarg for now as functional API is compiled by torch/distributed/optim |\n",
       "| foreach | bool | None |  |\n",
       "| weight_decay | float |  |  |\n",
       "| momentum | float |  |  |\n",
       "| lr | float |  |  |\n",
       "| dampening | float |  |  |\n",
       "| nesterov | bool |  |  |\n",
       "| maximize | bool |  |  |\n",
       "| clip_angle_value | float |  |  |"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# |output: asis\n",
    "# | echo: false\n",
    "show_doc(ecl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/antonpf/mlmvn/blob/main/mlmvn/optim.py#L13){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ECL\n",
       "\n",
       ">      ECL (params, lr=<required parameter>, momentum=0, dampening=0,\n",
       ">           weight_decay=0, nesterov=False, maximize=False,\n",
       ">           foreach:Optional[bool]=None, clip_angle_value=0)\n",
       "\n",
       "Base class for all optimizers.\n",
       "\n",
       ".. warning::\n",
       "    Parameters need to be specified as collections that have a deterministic\n",
       "    ordering that is consistent between runs. Examples of objects that don't\n",
       "    satisfy those properties are sets and iterators over values of dictionaries.\n",
       "\n",
       "Args:\n",
       "    params (iterable): an iterable of :class:`torch.Tensor` s or\n",
       "        :class:`dict` s. Specifies what Tensors should be optimized.\n",
       "    defaults: (dict): a dict containing default values of optimization\n",
       "        options (used when a parameter group doesn't specify them)."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/antonpf/mlmvn/blob/main/mlmvn/optim.py#L13){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ECL\n",
       "\n",
       ">      ECL (params, lr=<required parameter>, momentum=0, dampening=0,\n",
       ">           weight_decay=0, nesterov=False, maximize=False,\n",
       ">           foreach:Optional[bool]=None, clip_angle_value=0)\n",
       "\n",
       "Base class for all optimizers.\n",
       "\n",
       ".. warning::\n",
       "    Parameters need to be specified as collections that have a deterministic\n",
       "    ordering that is consistent between runs. Examples of objects that don't\n",
       "    satisfy those properties are sets and iterators over values of dictionaries.\n",
       "\n",
       "Args:\n",
       "    params (iterable): an iterable of :class:`torch.Tensor` s or\n",
       "        :class:`dict` s. Specifies what Tensors should be optimized.\n",
       "    defaults: (dict): a dict containing default values of optimization\n",
       "        options (used when a parameter group doesn't specify them)."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# |output: asis\n",
    "# | echo: false\n",
    "show_doc(ECL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/antonpf/mlmvn/blob/main/mlmvn/optim.py#L375){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### sgd\n",
       "\n",
       ">      sgd (params:List[torch.Tensor], d_p_list:List[torch.Tensor],\n",
       ">           momentum_buffer_list:List[Optional[torch.Tensor]],\n",
       ">           has_sparse_grad:bool=None, foreach:bool=None, weight_decay:float,\n",
       ">           momentum:float, lr:float, dampening:float, nesterov:bool,\n",
       ">           maximize:bool)\n",
       "\n",
       "Functional API that performs SGD algorithm computation.\n",
       "\n",
       "See :class:`~torch.optim.SGD` for details.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| params | typing.List[torch.Tensor] |  |  |\n",
       "| d_p_list | typing.List[torch.Tensor] |  |  |\n",
       "| momentum_buffer_list | typing.List[typing.Optional[torch.Tensor]] |  |  |\n",
       "| has_sparse_grad | bool | None | kwonly args with defaults are not supported by functions compiled with torchscript issue #70627<br>setting this as kwarg for now as functional API is compiled by torch/distributed/optim |\n",
       "| foreach | bool | None |  |\n",
       "| weight_decay | float |  |  |\n",
       "| momentum | float |  |  |\n",
       "| lr | float |  |  |\n",
       "| dampening | float |  |  |\n",
       "| nesterov | bool |  |  |\n",
       "| maximize | bool |  |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/antonpf/mlmvn/blob/main/mlmvn/optim.py#L375){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### sgd\n",
       "\n",
       ">      sgd (params:List[torch.Tensor], d_p_list:List[torch.Tensor],\n",
       ">           momentum_buffer_list:List[Optional[torch.Tensor]],\n",
       ">           has_sparse_grad:bool=None, foreach:bool=None, weight_decay:float,\n",
       ">           momentum:float, lr:float, dampening:float, nesterov:bool,\n",
       ">           maximize:bool)\n",
       "\n",
       "Functional API that performs SGD algorithm computation.\n",
       "\n",
       "See :class:`~torch.optim.SGD` for details.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| params | typing.List[torch.Tensor] |  |  |\n",
       "| d_p_list | typing.List[torch.Tensor] |  |  |\n",
       "| momentum_buffer_list | typing.List[typing.Optional[torch.Tensor]] |  |  |\n",
       "| has_sparse_grad | bool | None | kwonly args with defaults are not supported by functions compiled with torchscript issue #70627<br>setting this as kwarg for now as functional API is compiled by torch/distributed/optim |\n",
       "| foreach | bool | None |  |\n",
       "| weight_decay | float |  |  |\n",
       "| momentum | float |  |  |\n",
       "| lr | float |  |  |\n",
       "| dampening | float |  |  |\n",
       "| nesterov | bool |  |  |\n",
       "| maximize | bool |  |  |"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# |output: asis\n",
    "# | echo: false\n",
    "show_doc(sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/antonpf/mlmvn/blob/main/mlmvn/optim.py#L281){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MySGD\n",
       "\n",
       ">      MySGD (params, lr=<required parameter>, momentum=0, dampening=0,\n",
       ">             weight_decay=0, nesterov=False, maximize=False,\n",
       ">             foreach:Optional[bool]=None)\n",
       "\n",
       "Base class for all optimizers.\n",
       "\n",
       ".. warning::\n",
       "    Parameters need to be specified as collections that have a deterministic\n",
       "    ordering that is consistent between runs. Examples of objects that don't\n",
       "    satisfy those properties are sets and iterators over values of dictionaries.\n",
       "\n",
       "Args:\n",
       "    params (iterable): an iterable of :class:`torch.Tensor` s or\n",
       "        :class:`dict` s. Specifies what Tensors should be optimized.\n",
       "    defaults: (dict): a dict containing default values of optimization\n",
       "        options (used when a parameter group doesn't specify them)."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/antonpf/mlmvn/blob/main/mlmvn/optim.py#L281){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MySGD\n",
       "\n",
       ">      MySGD (params, lr=<required parameter>, momentum=0, dampening=0,\n",
       ">             weight_decay=0, nesterov=False, maximize=False,\n",
       ">             foreach:Optional[bool]=None)\n",
       "\n",
       "Base class for all optimizers.\n",
       "\n",
       ".. warning::\n",
       "    Parameters need to be specified as collections that have a deterministic\n",
       "    ordering that is consistent between runs. Examples of objects that don't\n",
       "    satisfy those properties are sets and iterators over values of dictionaries.\n",
       "\n",
       "Args:\n",
       "    params (iterable): an iterable of :class:`torch.Tensor` s or\n",
       "        :class:`dict` s. Specifies what Tensors should be optimized.\n",
       "    defaults: (dict): a dict containing default values of optimization\n",
       "        options (used when a parameter group doesn't specify them)."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# |output: asis\n",
    "# | echo: false\n",
    "show_doc(MySGD)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('mlmvn')",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
