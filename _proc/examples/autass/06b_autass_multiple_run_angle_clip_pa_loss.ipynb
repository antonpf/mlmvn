{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: In this example, the main focus is the classification of individual states\n",
    "  of a motor.\n",
    "output-file: autass_multiple_run_angle_clip_pa_loss.html\n",
    "title: Sensorless Drive Diagnosis\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv(\n",
    "    \"data/autass_data2.csv\",\n",
    "    header=None,\n",
    "    dtype=np.double,\n",
    ")\n",
    "data = np.array(train_csv.values[:, 1:50])\n",
    "del train_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "X = data[:, 0:48]\n",
    "y = data[:, 48].astype(int) - 1\n",
    "\n",
    "yt = copy.copy(y)\n",
    "yt[yt == 0] = 20\n",
    "yt[yt == 1] = 21\n",
    "yt[yt == 2] = 22\n",
    "yt[yt == 3] = 23\n",
    "yt[yt == 4] = 26\n",
    "yt[yt == 5] = 24\n",
    "yt[yt == 6] = 27\n",
    "yt[yt == 7] = 29\n",
    "yt[yt == 8] = 30\n",
    "yt[yt == 9] = 25\n",
    "yt[yt == 10] = 28\n",
    "yt -= 20\n",
    "y = yt\n",
    "del yt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "batch_size = 538\n",
    "lr = 1\n",
    "clip_angle_value = 1000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLMVN [48-10-11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "PATH = str(Path.cwd() / \"models/autass-mlmvn_48-10-11.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, categories, periodicity):\n",
    "        super().__init__()\n",
    "        self.categories = categories\n",
    "        self.periodicity = periodicity\n",
    "        self.first_linear = FirstLayer(48, 10)\n",
    "        self.phase_act1 = cmplx_phase_activation()\n",
    "        self.linear_out = OutputLayer(10, 11)\n",
    "        self.phase_act2 = cmplx_phase_activation()\n",
    "        # Hooks\n",
    "        self.first_layer_hook_handle = self.first_linear.register_full_backward_hook(\n",
    "            self.first_layer_backward_hook\n",
    "        )\n",
    "        self.output_hook_handle = self.linear_out.register_full_backward_hook(\n",
    "            self.output_layer_backward_hook\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first_linear(x)\n",
    "        x = self.phase_act1(x)\n",
    "        x = self.linear_out(x)\n",
    "        x = self.phase_act2(x)\n",
    "        return x\n",
    "\n",
    "    def first_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"first_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def hidden_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"hidden_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def output_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"output_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def angle2class(self, x: torch.tensor) -> torch.tensor:\n",
    "        tmp = x.angle() + 2 * np.pi\n",
    "        angle = torch.remainder(tmp, 2 * np.pi)\n",
    "\n",
    "        # This will be the discrete output (the number of sector)\n",
    "        o = torch.floor(self.categories * self.periodicity * angle / (2 * np.pi))\n",
    "        return torch.remainder(o, self.categories)\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Performs the prediction task of the network\n",
    "\n",
    "        Args:\n",
    "          x: torch.Tensor\n",
    "            Input tensor of size ([3])\n",
    "\n",
    "        Returns:\n",
    "          Most likely class i.e., Label with the highest score\n",
    "        \"\"\"\n",
    "        # Pass the data through the networks\n",
    "        output = self.forward(x)\n",
    "\n",
    "        # # Choose the label with the highest score\n",
    "        # return torch.argmax(output, 1)\n",
    "        return self.angle2class(output)\n",
    "\n",
    "\n",
    "def fit(model, X, y, epochs, batch_size, optimizer, criterion, categories, periodicity):\n",
    "    # List of losses for visualization\n",
    "    losses = []\n",
    "    scores = []\n",
    "    acc_best = 0\n",
    "\n",
    "    for i in range(epochs):\n",
    "        # Pass the data through the network and compute the loss\n",
    "        # We'll use the whole dataset during the training instead of using batches\n",
    "        # in to order to keep the code simple for now.\n",
    "\n",
    "        batch_loss = []\n",
    "\n",
    "        for j in range((X.shape[0] - 1) // batch_size + 1):\n",
    "            start_j = j * batch_size\n",
    "            end_j = start_j + batch_size\n",
    "            xb = X[start_j:end_j]\n",
    "            yb = y[start_j:end_j]\n",
    "\n",
    "            y_pred = model(xb)\n",
    "            loss = criterion(y_pred, yb, categories, periodicity)\n",
    "            batch_loss.append((torch.abs(loss)).detach().numpy())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step(inputs=xb, layers=list(model.children()))\n",
    "\n",
    "        losses.append(sum(batch_loss) / len(batch_loss))\n",
    "        if i % 10 == 9:\n",
    "            print(f\"Epoch {i} loss is {losses[-1]}\")\n",
    "        y_pred = model.predict(X)\n",
    "        scores.append(accuracy(y_pred.squeeze(), y))\n",
    "\n",
    "        if scores[-1] > acc_best:\n",
    "            acc_best = scores[-1]\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "    return losses, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=aed2c1e548d44d02876e693409da4ac3\n",
      "ClearML results page: http://194.94.231.172:8080/projects/cdefd6ee85454e49be01962ad715eca0/experiments/aed2c1e548d44d02876e693409da4ac3/output/log\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 1,\n",
       " 'epochs': 200,\n",
       " 'batch_size': 538,\n",
       " 'optim': 'ECL',\n",
       " 'categories': 2,\n",
       " 'periodicity': 1,\n",
       " 'layer': '[48-10-11]',\n",
       " 'loss': 'ComplexMSE_adjusted_error',\n",
       " 'clip_angle_value': 1000000}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = Task.init(\n",
    "    project_name=\"mlmvn\",\n",
    "    task_name=\"SDD-mlmvn-[48-10-11]\",\n",
    "    tags=[\"mlmvn\", \"SDD\", \"multiple_runs\", \"adjusted_loss_clip_angle_value\"],\n",
    ")\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# â€ƒcapture a dictionary of hyperparameters with config\n",
    "config_dict = {\n",
    "    \"learning_rate\": 1,\n",
    "    \"epochs\": epochs,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"optim\": \"ECL\",\n",
    "    \"categories\": categories,\n",
    "    \"periodicity\": periodicity,\n",
    "    \"layer\": \"[48-10-11]\",\n",
    "    \"loss\": \"ComplexMSE_adjusted_error\",\n",
    "    \"clip_angle_value\": clip_angle_value,\n",
    "}\n",
    "task.connect(config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13327/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-27 22:37:31,629 - clearml.frameworks - INFO - Found existing registered model id=caa96da5a415490ca1ea0f95b383f403 [/home/antonpfeifer/Documents/mlmvn/nbs/examples/autass/models/autass-mlmvn_48-10-11.pt] reusing it.\n",
      "Epoch 9 loss is 0.24486756715526192\n",
      "Epoch 19 loss is 0.16472245788019146\n",
      "Epoch 29 loss is 0.16197286684855702\n",
      "Epoch 39 loss is 0.15777335760350167\n",
      "Epoch 49 loss is 0.16362277181734114\n",
      "Epoch 59 loss is 0.1599623075779962\n",
      "Epoch 69 loss is 0.15505627729450555\n",
      "Epoch 79 loss is 0.1516815979779308\n",
      "Epoch 89 loss is 0.14756507300426192\n",
      "Epoch 99 loss is 0.14990614337584326\n",
      "Epoch 109 loss is 0.14464806634677907\n",
      "Epoch 119 loss is 0.14414441882839768\n",
      "Epoch 129 loss is 0.133414154667594\n",
      "Epoch 139 loss is 0.1568121289545272\n",
      "Epoch 149 loss is 0.13148384624669937\n",
      "Epoch 159 loss is 0.15520714324892884\n",
      "Epoch 169 loss is 0.15488150667967812\n",
      "Epoch 179 loss is 0.16196303491616978\n",
      "Epoch 189 loss is 0.17048013425110728\n",
      "Epoch 199 loss is 0.253481823204663\n",
      "Train Acc.:  0.9061037878949729\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95      1063\n",
      "           1       0.88      0.91      0.90      1064\n",
      "           2       0.97      0.95      0.96      1064\n",
      "           3       0.92      0.93      0.93      1064\n",
      "           4       0.90      0.87      0.88      1064\n",
      "           5       0.92      0.89      0.90      1063\n",
      "           6       0.88      0.85      0.86      1064\n",
      "           7       0.99      0.97      0.98      1064\n",
      "           8       1.00      0.99      1.00      1064\n",
      "           9       0.92      0.90      0.91      1064\n",
      "          10       0.95      0.97      0.96      1064\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     11702\n",
      "   macro avg       0.93      0.93      0.93     11702\n",
      "weighted avg       0.93      0.93      0.93     11702\n",
      " samples avg       0.91      0.93      0.92     11702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13327/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss is 0.23206087884330276\n",
      "Epoch 19 loss is 0.223541648173787\n",
      "Epoch 29 loss is 0.19793911944454762\n",
      "Epoch 39 loss is 0.20525953919872755\n",
      "Epoch 49 loss is 0.19172214725700548\n",
      "Epoch 59 loss is 0.180403134615211\n",
      "Epoch 69 loss is 0.20454411746859222\n",
      "Epoch 79 loss is 0.22207294107387418\n",
      "Epoch 89 loss is 0.1823581614612617\n",
      "Epoch 99 loss is 0.1984208152000532\n",
      "Epoch 109 loss is 0.21770198580729927\n",
      "Epoch 119 loss is 0.26321624687915784\n",
      "Epoch 129 loss is 0.2366645070320064\n",
      "Epoch 139 loss is 0.26308797516611215\n",
      "Epoch 149 loss is 0.2796785803565688\n",
      "Epoch 159 loss is 0.19642007623052968\n",
      "Epoch 169 loss is 0.3310147275301174\n",
      "Epoch 179 loss is 0.2874490546335206\n",
      "Epoch 189 loss is 0.2595535203540301\n",
      "Epoch 199 loss is 0.3217917178123802\n",
      "Train Acc.:  0.8804452325506869\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94      1063\n",
      "           1       0.89      0.87      0.88      1064\n",
      "           2       0.98      0.96      0.97      1064\n",
      "           3       0.98      0.95      0.97      1063\n",
      "           4       0.84      0.71      0.77      1064\n",
      "           5       0.92      0.86      0.89      1064\n",
      "           6       0.84      0.83      0.83      1064\n",
      "           7       0.99      0.99      0.99      1064\n",
      "           8       1.00      0.99      1.00      1064\n",
      "           9       0.87      0.90      0.88      1064\n",
      "          10       0.92      0.93      0.93      1064\n",
      "\n",
      "   micro avg       0.93      0.90      0.91     11702\n",
      "   macro avg       0.93      0.90      0.91     11702\n",
      "weighted avg       0.93      0.90      0.91     11702\n",
      " samples avg       0.89      0.90      0.89     11702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13327/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss is 0.23712313444477043\n",
      "Epoch 19 loss is 0.21309815317807554\n",
      "Epoch 29 loss is 0.2151226041409042\n",
      "Epoch 39 loss is 0.22794682641424854\n",
      "Epoch 49 loss is 0.18590490342052546\n",
      "Epoch 59 loss is 0.17194472537314034\n",
      "Epoch 69 loss is 0.18656052422193878\n",
      "Epoch 79 loss is 0.1756717054349332\n",
      "Epoch 89 loss is 0.19215676606052032\n",
      "Epoch 99 loss is 0.19421889588535315\n",
      "Epoch 109 loss is 0.23849424654511947\n",
      "Epoch 119 loss is 0.21172349809503013\n",
      "Epoch 129 loss is 0.310951138936457\n",
      "Epoch 139 loss is 0.40137440459088775\n",
      "Epoch 149 loss is 0.3257708635272683\n",
      "Epoch 159 loss is 0.3058673858224232\n",
      "Epoch 169 loss is 0.3393692446068119\n",
      "Epoch 179 loss is 0.3696819123265627\n",
      "Epoch 189 loss is 0.3599098499384412\n",
      "Epoch 199 loss is 0.4304120007418079\n",
      "Train Acc.:  0.8721558741213921\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95      1064\n",
      "           1       0.84      0.81      0.82      1064\n",
      "           2       0.96      0.91      0.93      1064\n",
      "           3       0.96      0.92      0.94      1063\n",
      "           4       0.89      0.84      0.86      1064\n",
      "           5       0.87      0.84      0.86      1064\n",
      "           6       0.88      0.76      0.81      1063\n",
      "           7       1.00      0.99      0.99      1064\n",
      "           8       1.00      0.99      1.00      1064\n",
      "           9       0.86      0.86      0.86      1064\n",
      "          10       0.92      0.91      0.91      1064\n",
      "\n",
      "   micro avg       0.92      0.89      0.90     11702\n",
      "   macro avg       0.92      0.89      0.90     11702\n",
      "weighted avg       0.92      0.89      0.90     11702\n",
      " samples avg       0.88      0.89      0.88     11702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13327/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss is 0.22525142483966729\n",
      "Epoch 19 loss is 0.21769357020501426\n",
      "Epoch 29 loss is 0.2577133298481112\n",
      "Epoch 39 loss is 0.22213481954372305\n",
      "Epoch 49 loss is 0.23841117493258804\n",
      "Epoch 59 loss is 0.309014874649911\n",
      "Epoch 69 loss is 0.35371038376681546\n",
      "Epoch 79 loss is 0.3699092508438563\n",
      "Epoch 89 loss is 0.36114378942190123\n",
      "Epoch 99 loss is 0.3760639842052328\n",
      "Epoch 109 loss is 0.289880557557834\n",
      "Epoch 119 loss is 0.3542478901455959\n",
      "Epoch 129 loss is 0.2415444508855365\n",
      "Epoch 139 loss is 0.25469037973175684\n",
      "Epoch 149 loss is 0.23138965174619833\n",
      "Epoch 159 loss is 0.21245593786661174\n",
      "Epoch 169 loss is 0.28983951582336215\n",
      "Epoch 179 loss is 0.2624560468178941\n",
      "Epoch 189 loss is 0.22517652315304382\n",
      "Epoch 199 loss is 0.30955816883738974\n",
      "Train Acc.:  0.830303159783793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95      1063\n",
      "           1       0.89      0.81      0.85      1064\n",
      "           2       0.95      0.85      0.90      1064\n",
      "           3       0.96      0.94      0.95      1063\n",
      "           4       0.89      0.81      0.85      1064\n",
      "           5       0.88      0.81      0.85      1064\n",
      "           6       0.77      0.70      0.73      1064\n",
      "           7       1.00      0.99      1.00      1064\n",
      "           8       0.99      0.99      0.99      1064\n",
      "           9       0.86      0.89      0.87      1064\n",
      "          10       0.91      0.84      0.87      1064\n",
      "\n",
      "   micro avg       0.92      0.87      0.89     11702\n",
      "   macro avg       0.91      0.87      0.89     11702\n",
      "weighted avg       0.91      0.87      0.89     11702\n",
      " samples avg       0.85      0.87      0.86     11702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13327/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss is 0.2563851438763014\n",
      "Epoch 19 loss is 0.21581594458135714\n",
      "Epoch 29 loss is 0.2354525347648366\n",
      "Epoch 39 loss is 0.19813069646116785\n",
      "Epoch 49 loss is 0.23640784807386372\n",
      "Epoch 59 loss is 0.2855586216205039\n",
      "Epoch 69 loss is 0.31419042978716966\n",
      "Epoch 79 loss is 0.3396274724821675\n",
      "Epoch 89 loss is 0.3805541273460192\n",
      "Epoch 99 loss is 0.2594859077291225\n",
      "Epoch 109 loss is 0.27091326668934435\n",
      "Epoch 119 loss is 0.26640856164548926\n",
      "Epoch 129 loss is 0.2599984885766787\n",
      "Epoch 139 loss is 0.24273455139343672\n",
      "Epoch 149 loss is 0.3339575152030492\n",
      "Epoch 159 loss is 0.2597825247475023\n",
      "Epoch 169 loss is 0.2548200790331675\n",
      "Epoch 179 loss is 0.2912208067110613\n",
      "Epoch 189 loss is 0.29534861061989254\n",
      "Epoch 199 loss is 0.35203137025199627\n",
      "Train Acc.:  0.8437840493943214\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94      1064\n",
      "           1       0.88      0.80      0.84      1064\n",
      "           2       0.92      0.85      0.88      1064\n",
      "           3       0.93      0.81      0.87      1064\n",
      "           4       0.89      0.81      0.85      1064\n",
      "           5       0.85      0.81      0.83      1064\n",
      "           6       0.84      0.81      0.83      1063\n",
      "           7       0.99      0.99      0.99      1064\n",
      "           8       1.00      1.00      1.00      1063\n",
      "           9       0.86      0.86      0.86      1064\n",
      "          10       0.94      0.85      0.89      1064\n",
      "\n",
      "   micro avg       0.91      0.86      0.89     11702\n",
      "   macro avg       0.91      0.86      0.89     11702\n",
      "weighted avg       0.91      0.86      0.89     11702\n",
      " samples avg       0.85      0.86      0.86     11702\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "list_losses = []\n",
    "list_scores = []\n",
    "list_acc = []\n",
    "list_loss = []\n",
    "list_f1 = []\n",
    "list_precision = []\n",
    "list_recall = []\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    model_dict: dict = {}\n",
    "    x_train, x_valid, y_train, y_valid = get_splitted_data_by_index(\n",
    "        X, y, neuronCats, train_index, test_index\n",
    "    )\n",
    "\n",
    "    model = Model(categories=categories, periodicity=periodicity)\n",
    "    criterion = ComplexMSE_adjusted_error.apply\n",
    "    optimizer = ECL(model.parameters(), lr=lr)\n",
    "\n",
    "    losses, scores = fit(\n",
    "        model,\n",
    "        x_train,\n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        categories=categories,\n",
    "        periodicity=periodicity,\n",
    "    )\n",
    "\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "    list_scores.append(scores)\n",
    "    list_losses.append(losses)\n",
    "\n",
    "    y_pred = model.predict(x_train)\n",
    "    acc = accuracy(y_pred.squeeze(), y_train)\n",
    "    print(\"Train Acc.: \", acc)\n",
    "\n",
    "    y_pred = model.predict(x_valid)\n",
    "    acc = accuracy(y_pred.squeeze(), y_valid)\n",
    "    list_acc.append(acc)\n",
    "\n",
    "    print(classification_report(y_valid, y_pred.detach().numpy(), zero_division=0))\n",
    "    list_f1.append(\n",
    "        f1_score(y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0)\n",
    "    )\n",
    "    list_precision.append(\n",
    "        precision_score(\n",
    "            y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0\n",
    "        )\n",
    "    )\n",
    "    list_recall.append(\n",
    "        recall_score(\n",
    "            y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0\n",
    "        )\n",
    "    )\n",
    "\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_accuracy_mean\",\n",
    "    value=np.mean(list_acc),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_accuracy_std\",\n",
    "    value=np.std(list_acc),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_f1_mean\",\n",
    "    value=np.mean(list_f1),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_f1_std\",\n",
    "    value=np.std(list_f1),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_precision_mean\",\n",
    "    value=np.mean(list_precision),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_precision_std\",\n",
    "    value=np.std(list_precision),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_recall_mean\",\n",
    "    value=np.mean(list_recall),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_recall_std\",\n",
    "    value=np.std(list_recall),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "task.mark_completed()\n",
    "task.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLMVN [48-20-11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "PATH = str(Path.cwd() / \"models/autass-mlmvn_48-20-11.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, categories, periodicity):\n",
    "        super().__init__()\n",
    "        self.categories = categories\n",
    "        self.periodicity = periodicity\n",
    "        self.first_linear = FirstLayer(48, 20)\n",
    "        self.phase_act1 = cmplx_phase_activation()\n",
    "        self.linear_out = OutputLayer(20, 11)\n",
    "        self.phase_act2 = cmplx_phase_activation()\n",
    "        # Hooks\n",
    "        self.first_layer_hook_handle = self.first_linear.register_full_backward_hook(\n",
    "            self.first_layer_backward_hook\n",
    "        )\n",
    "        self.output_hook_handle = self.linear_out.register_full_backward_hook(\n",
    "            self.output_layer_backward_hook\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first_linear(x)\n",
    "        x = self.phase_act1(x)\n",
    "        x = self.linear_out(x)\n",
    "        x = self.phase_act2(x)\n",
    "        return x\n",
    "\n",
    "    def first_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"first_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def hidden_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"hidden_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def output_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"output_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def angle2class(self, x: torch.tensor) -> torch.tensor:\n",
    "        tmp = x.angle() + 2 * np.pi\n",
    "        angle = torch.remainder(tmp, 2 * np.pi)\n",
    "\n",
    "        # This will be the discrete output (the number of sector)\n",
    "        o = torch.floor(self.categories * self.periodicity * angle / (2 * np.pi))\n",
    "        return torch.remainder(o, self.categories)\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Performs the prediction task of the network\n",
    "\n",
    "        Args:\n",
    "          x: torch.Tensor\n",
    "            Input tensor of size ([3])\n",
    "\n",
    "        Returns:\n",
    "          Most likely class i.e., Label with the highest score\n",
    "        \"\"\"\n",
    "        # Pass the data through the networks\n",
    "        output = self.forward(x)\n",
    "\n",
    "        # # Choose the label with the highest score\n",
    "        # return torch.argmax(output, 1)\n",
    "        return self.angle2class(output)\n",
    "\n",
    "\n",
    "def fit(model, X, y, epochs, batch_size, optimizer, criterion, categories, periodicity):\n",
    "    # List of losses for visualization\n",
    "    losses = []\n",
    "    scores = []\n",
    "    acc_best = 0\n",
    "\n",
    "    for i in range(epochs):\n",
    "        # Pass the data through the network and compute the loss\n",
    "        # We'll use the whole dataset during the training instead of using batches\n",
    "        # in to order to keep the code simple for now.\n",
    "\n",
    "        batch_loss = []\n",
    "\n",
    "        for j in range((X.shape[0] - 1) // batch_size + 1):\n",
    "            start_j = j * batch_size\n",
    "            end_j = start_j + batch_size\n",
    "            xb = X[start_j:end_j]\n",
    "            yb = y[start_j:end_j]\n",
    "\n",
    "            y_pred = model(xb)\n",
    "            loss = criterion(y_pred, yb, categories, periodicity)\n",
    "            batch_loss.append((torch.abs(loss)).detach().numpy())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step(inputs=xb, layers=list(model.children()))\n",
    "\n",
    "        losses.append(sum(batch_loss) / len(batch_loss))\n",
    "        if i % 10 == 9:\n",
    "            print(f\"Epoch {i} loss is {losses[-1]}\")\n",
    "        y_pred = model.predict(X)\n",
    "        scores.append(accuracy(y_pred.squeeze(), y))\n",
    "\n",
    "        if scores[-1] > acc_best:\n",
    "            acc_best = scores[-1]\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "    return losses, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=7e81250b8f8a4d31b43661579158b428\n",
      "ClearML results page: http://194.94.231.172:8080/projects/cdefd6ee85454e49be01962ad715eca0/experiments/7e81250b8f8a4d31b43661579158b428/output/log\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 1,\n",
       " 'epochs': 200,\n",
       " 'batch_size': 538,\n",
       " 'optim': 'ECL',\n",
       " 'categories': 2,\n",
       " 'periodicity': 1,\n",
       " 'layer': '[48-20-11]',\n",
       " 'loss': 'ComplexMSE_adjusted_error',\n",
       " 'clip_angle_value': 1000000}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = Task.init(\n",
    "    project_name=\"mlmvn\",\n",
    "    task_name=\"SDD-mlmvn-[48-20-11]\",\n",
    "    tags=[\"mlmvn\", \"SDD\", \"multiple_runs\", \"adjusted_loss_clip_angle_value\"],\n",
    ")\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# â€ƒcapture a dictionary of hyperparameters with config\n",
    "config_dict = {\n",
    "    \"learning_rate\": 1,\n",
    "    \"epochs\": epochs,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"optim\": \"ECL\",\n",
    "    \"categories\": categories,\n",
    "    \"periodicity\": periodicity,\n",
    "    \"layer\": \"[48-20-11]\",\n",
    "    \"loss\": \"ComplexMSE_adjusted_error\",\n",
    "    \"clip_angle_value\": clip_angle_value,\n",
    "}\n",
    "task.connect(config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13327/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-27 22:55:28,643 - clearml.frameworks - INFO - Found existing registered model id=c337b94a22444d809d449783726d8ee2 [/home/antonpfeifer/Documents/mlmvn/nbs/examples/autass/models/autass-mlmvn_48-20-11.pt] reusing it.\n",
      "Epoch 9 loss is 0.2058236759317573\n",
      "Epoch 19 loss is 0.1825360529148008\n",
      "Epoch 29 loss is 0.13331677743733528\n",
      "Epoch 39 loss is 0.11695840664945023\n",
      "Epoch 49 loss is 0.11103621118112407\n",
      "Epoch 59 loss is 0.12555862590235578\n",
      "Epoch 69 loss is 0.12181158857175331\n",
      "Epoch 79 loss is 0.09544202089592545\n",
      "Epoch 89 loss is 0.11178487401744581\n",
      "Epoch 99 loss is 0.12958967446816022\n",
      "Epoch 109 loss is 0.11905161904742857\n",
      "Epoch 119 loss is 0.10873579923307998\n",
      "Epoch 129 loss is 0.09673697400248864\n",
      "Epoch 139 loss is 0.09588223402448456\n",
      "Epoch 149 loss is 0.11162506774666282\n",
      "Epoch 159 loss is 0.09059592728792225\n",
      "Epoch 169 loss is 0.09758258176950994\n",
      "Epoch 179 loss is 0.10536165971500439\n",
      "Epoch 189 loss is 0.10205764671734051\n",
      "Epoch 199 loss is 0.14389611907866479\n",
      "Train Acc.:  0.9354583716110838\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1063\n",
      "           1       0.93      0.93      0.93      1064\n",
      "           2       0.98      0.95      0.96      1064\n",
      "           3       0.96      0.95      0.96      1064\n",
      "           4       0.94      0.93      0.94      1064\n",
      "           5       0.94      0.94      0.94      1063\n",
      "           6       0.88      0.88      0.88      1064\n",
      "           7       1.00      0.99      0.99      1064\n",
      "           8       1.00      1.00      1.00      1064\n",
      "           9       0.94      0.92      0.93      1064\n",
      "          10       0.97      0.95      0.96      1064\n",
      "\n",
      "   micro avg       0.95      0.94      0.95     11702\n",
      "   macro avg       0.95      0.94      0.95     11702\n",
      "weighted avg       0.95      0.94      0.95     11702\n",
      " samples avg       0.94      0.94      0.94     11702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13327/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss is 0.2307281778017605\n",
      "Epoch 19 loss is 0.18615664526599873\n",
      "Epoch 29 loss is 0.16207854951403944\n",
      "Epoch 39 loss is 0.15162521963532127\n",
      "Epoch 49 loss is 0.16081494726357065\n",
      "Epoch 59 loss is 0.1257449738051931\n",
      "Epoch 69 loss is 0.10937442608829037\n",
      "Epoch 79 loss is 0.12329823825151687\n",
      "Epoch 89 loss is 0.12930987857639764\n",
      "Epoch 99 loss is 0.12765360621548777\n",
      "Epoch 109 loss is 0.15596338287786382\n",
      "Epoch 119 loss is 0.16634696725086548\n",
      "Epoch 129 loss is 0.1495299076006498\n",
      "Epoch 139 loss is 0.1502898510399668\n",
      "Epoch 149 loss is 0.15832158268949942\n",
      "Epoch 159 loss is 0.17899469216655411\n",
      "Epoch 169 loss is 0.23058719525799198\n",
      "Epoch 179 loss is 0.2102188014453179\n",
      "Epoch 189 loss is 0.23088950030054886\n",
      "Epoch 199 loss is 0.21150270029799098\n",
      "Train Acc.:  0.9071933685132566\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      1063\n",
      "           1       0.91      0.89      0.90      1064\n",
      "           2       0.98      0.97      0.97      1064\n",
      "           3       0.94      0.94      0.94      1063\n",
      "           4       0.91      0.92      0.92      1064\n",
      "           5       0.93      0.93      0.93      1064\n",
      "           6       0.90      0.89      0.90      1064\n",
      "           7       0.99      0.99      0.99      1064\n",
      "           8       1.00      0.99      1.00      1064\n",
      "           9       0.92      0.88      0.90      1064\n",
      "          10       0.92      0.89      0.90      1064\n",
      "\n",
      "   micro avg       0.94      0.93      0.94     11702\n",
      "   macro avg       0.94      0.93      0.94     11702\n",
      "weighted avg       0.94      0.93      0.94     11702\n",
      " samples avg       0.92      0.93      0.92     11702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13327/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss is 0.21257633823646344\n",
      "Epoch 19 loss is 0.17318814963579834\n",
      "Epoch 29 loss is 0.1458617958714956\n",
      "Epoch 39 loss is 0.14125668374187184\n",
      "Epoch 49 loss is 0.128772752498416\n",
      "Epoch 59 loss is 0.1352171863065471\n",
      "Epoch 69 loss is 0.10681416437897072\n",
      "Epoch 79 loss is 0.13216534508015265\n",
      "Epoch 89 loss is 0.11111060725019\n",
      "Epoch 99 loss is 0.11440525031960108\n",
      "Epoch 109 loss is 0.1094888755315214\n",
      "Epoch 119 loss is 0.11533819118199232\n",
      "Epoch 129 loss is 0.10736030126824322\n",
      "Epoch 139 loss is 0.10061210309481297\n",
      "Epoch 149 loss is 0.10068345790438905\n",
      "Epoch 159 loss is 0.09078661822690025\n",
      "Epoch 169 loss is 0.09375741469930386\n",
      "Epoch 179 loss is 0.09420665138442623\n",
      "Epoch 189 loss is 0.09327934878515685\n",
      "Epoch 199 loss is 0.09550257254442705\n",
      "Train Acc.:  0.9378939047578354\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96      1064\n",
      "           1       0.94      0.91      0.92      1064\n",
      "           2       0.97      0.96      0.97      1064\n",
      "           3       0.99      0.97      0.98      1063\n",
      "           4       0.94      0.92      0.93      1064\n",
      "           5       0.94      0.93      0.93      1064\n",
      "           6       0.91      0.86      0.88      1063\n",
      "           7       1.00      0.99      1.00      1064\n",
      "           8       1.00      1.00      1.00      1064\n",
      "           9       0.92      0.91      0.92      1064\n",
      "          10       0.96      0.95      0.96      1064\n",
      "\n",
      "   micro avg       0.96      0.94      0.95     11702\n",
      "   macro avg       0.96      0.94      0.95     11702\n",
      "weighted avg       0.96      0.94      0.95     11702\n",
      " samples avg       0.93      0.94      0.94     11702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13327/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss is 0.20641349230841313\n",
      "Epoch 19 loss is 0.15738830801178577\n",
      "Epoch 29 loss is 0.1799417678605428\n",
      "Epoch 39 loss is 0.13007205544481562\n",
      "Epoch 49 loss is 0.11737783309073208\n",
      "Epoch 59 loss is 0.1114466828734566\n",
      "Epoch 69 loss is 0.11852908050617135\n",
      "Epoch 79 loss is 0.11542474814310127\n",
      "Epoch 89 loss is 0.10236658536166438\n",
      "Epoch 99 loss is 0.12045357416608558\n",
      "Epoch 109 loss is 0.1051365830820148\n",
      "Epoch 119 loss is 0.09761249375093389\n",
      "Epoch 129 loss is 0.09216019224495184\n",
      "Epoch 139 loss is 0.09421224180251014\n",
      "Epoch 149 loss is 0.09233837313904565\n",
      "Epoch 159 loss is 0.09223922889858933\n",
      "Epoch 169 loss is 0.08829034240388713\n",
      "Epoch 179 loss is 0.09375694157319493\n",
      "Epoch 189 loss is 0.08536116014844801\n",
      "Epoch 199 loss is 0.08500084532665717\n",
      "Train Acc.:  0.94060717414062\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      1063\n",
      "           1       0.93      0.93      0.93      1064\n",
      "           2       0.98      0.96      0.97      1064\n",
      "           3       0.97      0.95      0.96      1063\n",
      "           4       0.96      0.92      0.94      1064\n",
      "           5       0.95      0.92      0.93      1064\n",
      "           6       0.90      0.90      0.90      1064\n",
      "           7       0.99      0.99      0.99      1064\n",
      "           8       1.00      1.00      1.00      1064\n",
      "           9       0.95      0.92      0.93      1064\n",
      "          10       0.97      0.95      0.96      1064\n",
      "\n",
      "   micro avg       0.96      0.95      0.95     11702\n",
      "   macro avg       0.96      0.95      0.95     11702\n",
      "weighted avg       0.96      0.95      0.95     11702\n",
      " samples avg       0.94      0.95      0.94     11702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13327/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss is 0.20548555472102373\n",
      "Epoch 19 loss is 0.15323632791255185\n",
      "Epoch 29 loss is 0.1295082539268068\n",
      "Epoch 39 loss is 0.12081646040093838\n",
      "Epoch 49 loss is 0.10243967732402894\n",
      "Epoch 59 loss is 0.10126855908153241\n",
      "Epoch 69 loss is 0.11296332021354512\n",
      "Epoch 79 loss is 0.09185533808063474\n",
      "Epoch 89 loss is 0.09732833351838127\n",
      "Epoch 99 loss is 0.09188653614455912\n",
      "Epoch 109 loss is 0.10085898797344649\n",
      "Epoch 119 loss is 0.10443676031698373\n",
      "Epoch 129 loss is 0.1023311360663922\n",
      "Epoch 139 loss is 0.10306230769293823\n",
      "Epoch 149 loss is 0.11354442989486692\n",
      "Epoch 159 loss is 0.10403630260181586\n",
      "Epoch 169 loss is 0.09833004415491228\n",
      "Epoch 179 loss is 0.14203489341950598\n",
      "Epoch 189 loss is 0.10320350983155654\n",
      "Epoch 199 loss is 0.11371829480246762\n",
      "Train Acc.:  0.9411626466126861\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      1064\n",
      "           1       0.93      0.92      0.93      1064\n",
      "           2       0.98      0.94      0.96      1064\n",
      "           3       0.98      0.96      0.97      1064\n",
      "           4       0.95      0.91      0.93      1064\n",
      "           5       0.94      0.93      0.93      1064\n",
      "           6       0.90      0.90      0.90      1063\n",
      "           7       1.00      1.00      1.00      1064\n",
      "           8       1.00      1.00      1.00      1063\n",
      "           9       0.94      0.91      0.93      1064\n",
      "          10       0.98      0.96      0.97      1064\n",
      "\n",
      "   micro avg       0.96      0.94      0.95     11702\n",
      "   macro avg       0.96      0.94      0.95     11702\n",
      "weighted avg       0.96      0.94      0.95     11702\n",
      " samples avg       0.94      0.94      0.94     11702\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "list_losses = []\n",
    "list_scores = []\n",
    "list_acc = []\n",
    "list_loss = []\n",
    "list_f1 = []\n",
    "list_precision = []\n",
    "list_recall = []\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    model_dict: dict = {}\n",
    "    x_train, x_valid, y_train, y_valid = get_splitted_data_by_index(\n",
    "        X, y, neuronCats, train_index, test_index\n",
    "    )\n",
    "\n",
    "    model = Model(categories=categories, periodicity=periodicity)\n",
    "    criterion = ComplexMSE_adjusted_error.apply\n",
    "    optimizer = ECL(model.parameters(), lr=lr)\n",
    "\n",
    "    losses, scores = fit(\n",
    "        model,\n",
    "        x_train,\n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        categories=categories,\n",
    "        periodicity=periodicity,\n",
    "    )\n",
    "\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "    list_scores.append(scores)\n",
    "    list_losses.append(losses)\n",
    "\n",
    "    y_pred = model.predict(x_train)\n",
    "    acc = accuracy(y_pred.squeeze(), y_train)\n",
    "    print(\"Train Acc.: \", acc)\n",
    "\n",
    "    y_pred = model.predict(x_valid)\n",
    "    acc = accuracy(y_pred.squeeze(), y_valid)\n",
    "    list_acc.append(acc)\n",
    "\n",
    "    print(classification_report(y_valid, y_pred.detach().numpy(), zero_division=0))\n",
    "    list_f1.append(\n",
    "        f1_score(y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0)\n",
    "    )\n",
    "    list_precision.append(\n",
    "        precision_score(\n",
    "            y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0\n",
    "        )\n",
    "    )\n",
    "    list_recall.append(\n",
    "        recall_score(\n",
    "            y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0\n",
    "        )\n",
    "    )\n",
    "\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_accuracy_mean\",\n",
    "    value=np.mean(list_acc),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_accuracy_std\",\n",
    "    value=np.std(list_acc),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_f1_mean\",\n",
    "    value=np.mean(list_f1),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_f1_std\",\n",
    "    value=np.std(list_f1),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_precision_mean\",\n",
    "    value=np.mean(list_precision),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_precision_std\",\n",
    "    value=np.std(list_precision),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_recall_mean\",\n",
    "    value=np.mean(list_recall),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_recall_std\",\n",
    "    value=np.std(list_recall),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "task.mark_completed()\n",
    "task.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLMVN [48-50-11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "PATH = str(Path.cwd() / \"models/autass-mlmvn_48-50-11.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, categories, periodicity):\n",
    "        super().__init__()\n",
    "        self.categories = categories\n",
    "        self.periodicity = periodicity\n",
    "        self.first_linear = FirstLayer(48, 50)\n",
    "        self.phase_act1 = cmplx_phase_activation()\n",
    "        self.linear_out = OutputLayer(50, 11)\n",
    "        self.phase_act2 = cmplx_phase_activation()\n",
    "        # Hooks\n",
    "        self.first_layer_hook_handle = self.first_linear.register_full_backward_hook(\n",
    "            self.first_layer_backward_hook\n",
    "        )\n",
    "        self.output_hook_handle = self.linear_out.register_full_backward_hook(\n",
    "            self.output_layer_backward_hook\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first_linear(x)\n",
    "        x = self.phase_act1(x)\n",
    "        x = self.linear_out(x)\n",
    "        x = self.phase_act2(x)\n",
    "        return x\n",
    "\n",
    "    def first_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"first_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def hidden_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"hidden_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def output_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"output_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def angle2class(self, x: torch.tensor) -> torch.tensor:\n",
    "        tmp = x.angle() + 2 * np.pi\n",
    "        angle = torch.remainder(tmp, 2 * np.pi)\n",
    "\n",
    "        # This will be the discrete output (the number of sector)\n",
    "        o = torch.floor(self.categories * self.periodicity * angle / (2 * np.pi))\n",
    "        return torch.remainder(o, self.categories)\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Performs the prediction task of the network\n",
    "\n",
    "        Args:\n",
    "          x: torch.Tensor\n",
    "            Input tensor of size ([3])\n",
    "\n",
    "        Returns:\n",
    "          Most likely class i.e., Label with the highest score\n",
    "        \"\"\"\n",
    "        # Pass the data through the networks\n",
    "        output = self.forward(x)\n",
    "\n",
    "        # # Choose the label with the highest score\n",
    "        # return torch.argmax(output, 1)\n",
    "        return self.angle2class(output)\n",
    "\n",
    "\n",
    "def fit(model, X, y, epochs, batch_size, optimizer, criterion, categories, periodicity):\n",
    "    # List of losses for visualization\n",
    "    losses = []\n",
    "    scores = []\n",
    "    acc_best = 0\n",
    "\n",
    "    for i in range(epochs):\n",
    "        # Pass the data through the network and compute the loss\n",
    "        # We'll use the whole dataset during the training instead of using batches\n",
    "        # in to order to keep the code simple for now.\n",
    "\n",
    "        batch_loss = []\n",
    "\n",
    "        for j in range((X.shape[0] - 1) // batch_size + 1):\n",
    "            start_j = j * batch_size\n",
    "            end_j = start_j + batch_size\n",
    "            xb = X[start_j:end_j]\n",
    "            yb = y[start_j:end_j]\n",
    "\n",
    "            y_pred = model(xb)\n",
    "            loss = criterion(y_pred, yb, categories, periodicity)\n",
    "            batch_loss.append((torch.abs(loss)).detach().numpy())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step(inputs=xb, layers=list(model.children()))\n",
    "\n",
    "        losses.append(sum(batch_loss) / len(batch_loss))\n",
    "        if i % 10 == 9:\n",
    "            print(f\"Epoch {i} loss is {losses[-1]}\")\n",
    "        y_pred = model.predict(X)\n",
    "        scores.append(accuracy(y_pred.squeeze(), y))\n",
    "\n",
    "        if scores[-1] > acc_best:\n",
    "            acc_best = scores[-1]\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "    return losses, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=2d2bd92d33c3458882439af599c0d219\n",
      "ClearML results page: http://194.94.231.172:8080/projects/cdefd6ee85454e49be01962ad715eca0/experiments/2d2bd92d33c3458882439af599c0d219/output/log\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 1,\n",
       " 'epochs': 200,\n",
       " 'batch_size': 538,\n",
       " 'optim': 'ECL',\n",
       " 'categories': 2,\n",
       " 'periodicity': 1,\n",
       " 'layer': '[48-50-11]',\n",
       " 'loss': 'ComplexMSE_adjusted_error',\n",
       " 'clip_angle_value': 1000000}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = Task.init(\n",
    "    project_name=\"mlmvn\",\n",
    "    task_name=\"SDD-mlmvn-[48-50-11]\",\n",
    "    tags=[\"mlmvn\", \"SDD\", \"multiple_runs\", \"adjusted_loss_clip_angle_value\"],\n",
    ")\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# â€ƒcapture a dictionary of hyperparameters with config\n",
    "config_dict = {\n",
    "    \"learning_rate\": 1,\n",
    "    \"epochs\": epochs,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"optim\": \"ECL\",\n",
    "    \"categories\": categories,\n",
    "    \"periodicity\": periodicity,\n",
    "    \"layer\": \"[48-50-11]\",\n",
    "    \"loss\": \"ComplexMSE_adjusted_error\",\n",
    "    \"clip_angle_value\": clip_angle_value,\n",
    "}\n",
    "task.connect(config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13327/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-27 23:20:32,297 - clearml.frameworks - INFO - Found existing registered model id=bb96e63090904339bf87c4852d30bdb6 [/home/antonpfeifer/Documents/mlmvn/nbs/examples/autass/models/autass-mlmvn_48-50-11.pt] reusing it.\n",
      "Epoch 9 loss is 0.24396016163019188\n",
      "Epoch 19 loss is 0.1408100184642106\n",
      "Epoch 29 loss is 0.10649778199752649\n",
      "Epoch 39 loss is 0.0854672719392131\n",
      "Epoch 49 loss is 0.09677528437761192\n",
      "Epoch 59 loss is 0.08491636262762711\n",
      "Epoch 69 loss is 0.07073853121933514\n",
      "Epoch 79 loss is 0.0623588742935536\n",
      "Epoch 89 loss is 0.06493405545145113\n",
      "Epoch 99 loss is 0.06570635803032455\n",
      "Epoch 109 loss is 0.05703714881850874\n",
      "Epoch 119 loss is 0.06868247092465077\n",
      "Epoch 129 loss is 0.05820049851283152\n",
      "Epoch 139 loss is 0.057654175689656244\n",
      "Epoch 149 loss is 0.054585099955762065\n",
      "Epoch 159 loss is 0.07306441308956363\n",
      "Epoch 169 loss is 0.06311269411213584\n",
      "Epoch 179 loss is 0.0785263104691008\n",
      "Epoch 189 loss is 0.08227202587346817\n",
      "Epoch 199 loss is 0.055809321412454364\n",
      "Train Acc.:  0.9670775738671566\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      1063\n",
      "           1       0.96      0.94      0.95      1064\n",
      "           2       0.99      0.99      0.99      1064\n",
      "           3       0.98      0.98      0.98      1064\n",
      "           4       0.96      0.92      0.94      1064\n",
      "           5       0.97      0.95      0.96      1063\n",
      "           6       0.95      0.94      0.95      1064\n",
      "           7       1.00      1.00      1.00      1064\n",
      "           8       1.00      1.00      1.00      1064\n",
      "           9       0.97      0.96      0.97      1064\n",
      "          10       0.98      0.96      0.97      1064\n",
      "\n",
      "   micro avg       0.98      0.97      0.97     11702\n",
      "   macro avg       0.98      0.97      0.97     11702\n",
      "weighted avg       0.98      0.97      0.97     11702\n",
      " samples avg       0.96      0.97      0.96     11702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13327/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss is 0.2661679163999582\n",
      "Epoch 19 loss is 0.14625262471743808\n",
      "Epoch 29 loss is 0.12002121900326053\n",
      "Epoch 39 loss is 0.11372154790877459\n",
      "Epoch 49 loss is 0.09963077571846711\n",
      "Epoch 59 loss is 0.08699985949055491\n",
      "Epoch 69 loss is 0.08908419619519271\n",
      "Epoch 79 loss is 0.077337234526038\n",
      "Epoch 89 loss is 0.0786930436278074\n",
      "Epoch 99 loss is 0.06691134614071381\n",
      "Epoch 109 loss is 0.07431928775441791\n",
      "Epoch 119 loss is 0.059303313881029024\n",
      "Epoch 129 loss is 0.05999768811650241\n",
      "Epoch 139 loss is 0.05597988277724091\n",
      "Epoch 149 loss is 0.05467993967785231\n",
      "Epoch 159 loss is 0.054380003065822906\n",
      "Epoch 169 loss is 0.055407265453249616\n",
      "Epoch 179 loss is 0.05802883371582689\n",
      "Epoch 189 loss is 0.05513524843130078\n",
      "Epoch 199 loss is 0.04906545557802202\n",
      "Train Acc.:  0.9664793727433931\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98      1063\n",
      "           1       0.96      0.94      0.95      1064\n",
      "           2       0.99      0.99      0.99      1064\n",
      "           3       0.99      0.98      0.98      1063\n",
      "           4       0.94      0.94      0.94      1064\n",
      "           5       0.97      0.96      0.97      1064\n",
      "           6       0.97      0.94      0.95      1064\n",
      "           7       1.00      1.00      1.00      1064\n",
      "           8       1.00      1.00      1.00      1064\n",
      "           9       0.97      0.96      0.97      1064\n",
      "          10       0.99      0.98      0.98      1064\n",
      "\n",
      "   micro avg       0.98      0.97      0.97     11702\n",
      "   macro avg       0.98      0.97      0.97     11702\n",
      "weighted avg       0.98      0.97      0.97     11702\n",
      " samples avg       0.96      0.97      0.96     11702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13327/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss is 0.20502371384654208\n",
      "Epoch 19 loss is 0.1600604545972537\n",
      "Epoch 29 loss is 0.17638293655801232\n",
      "Epoch 39 loss is 0.11561468644927743\n",
      "Epoch 49 loss is 0.09013697049000392\n",
      "Epoch 59 loss is 0.08748177132875291\n",
      "Epoch 69 loss is 0.07197819254783605\n",
      "Epoch 79 loss is 0.0702369190086657\n",
      "Epoch 89 loss is 0.07234675932731245\n",
      "Epoch 99 loss is 0.068253828507892\n",
      "Epoch 109 loss is 0.07305692741178821\n",
      "Epoch 119 loss is 0.07672600907945662\n",
      "Epoch 129 loss is 0.07097353389268429\n",
      "Epoch 139 loss is 0.06347196049334779\n",
      "Epoch 149 loss is 0.0644738520961493\n",
      "Epoch 159 loss is 0.05376314275695037\n",
      "Epoch 169 loss is 0.05644687125414726\n",
      "Epoch 179 loss is 0.048773048522865105\n",
      "Epoch 189 loss is 0.04476576239785017\n",
      "Epoch 199 loss is 0.04786218107136711\n",
      "Train Acc.:  0.9728032131946076\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      1064\n",
      "           1       0.96      0.96      0.96      1064\n",
      "           2       0.99      0.99      0.99      1064\n",
      "           3       0.98      0.97      0.98      1063\n",
      "           4       0.97      0.95      0.96      1064\n",
      "           5       0.96      0.96      0.96      1064\n",
      "           6       0.96      0.94      0.95      1063\n",
      "           7       1.00      1.00      1.00      1064\n",
      "           8       1.00      1.00      1.00      1064\n",
      "           9       0.95      0.95      0.95      1064\n",
      "          10       0.98      0.96      0.97      1064\n",
      "\n",
      "   micro avg       0.98      0.97      0.97     11702\n",
      "   macro avg       0.98      0.97      0.97     11702\n",
      "weighted avg       0.98      0.97      0.97     11702\n",
      " samples avg       0.96      0.97      0.97     11702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13327/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss is 0.22543501013461756\n",
      "Epoch 19 loss is 0.17068695324254124\n",
      "Epoch 29 loss is 0.12409391685149763\n",
      "Epoch 39 loss is 0.11697496548175042\n",
      "Epoch 49 loss is 0.08876241864971807\n",
      "Epoch 59 loss is 0.08153087295328582\n",
      "Epoch 69 loss is 0.07483510813769084\n",
      "Epoch 79 loss is 0.10710111668977772\n",
      "Epoch 89 loss is 0.08042401739956408\n",
      "Epoch 99 loss is 0.07369310521635002\n",
      "Epoch 109 loss is 0.07451935209149846\n",
      "Epoch 119 loss is 0.059885478707408256\n",
      "Epoch 129 loss is 0.0567862421178645\n",
      "Epoch 139 loss is 0.05093684395615367\n",
      "Epoch 149 loss is 0.06306265519934738\n",
      "Epoch 159 loss is 0.05432974760807225\n",
      "Epoch 169 loss is 0.04892963285147231\n",
      "Epoch 179 loss is 0.04994840531613505\n",
      "Epoch 189 loss is 0.051194054698050454\n",
      "Epoch 199 loss is 0.044596025063632284\n",
      "Train Acc.:  0.9714572606661397\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      1063\n",
      "           1       0.96      0.96      0.96      1064\n",
      "           2       0.99      0.99      0.99      1064\n",
      "           3       0.98      0.99      0.98      1063\n",
      "           4       0.96      0.96      0.96      1064\n",
      "           5       0.96      0.95      0.95      1064\n",
      "           6       0.95      0.94      0.95      1064\n",
      "           7       1.00      1.00      1.00      1064\n",
      "           8       1.00      1.00      1.00      1064\n",
      "           9       0.97      0.94      0.95      1064\n",
      "          10       0.99      0.97      0.98      1064\n",
      "\n",
      "   micro avg       0.98      0.97      0.97     11702\n",
      "   macro avg       0.98      0.97      0.97     11702\n",
      "weighted avg       0.98      0.97      0.97     11702\n",
      " samples avg       0.97      0.97      0.97     11702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13327/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss is 0.2782503201838837\n",
      "Epoch 19 loss is 0.16120408621727206\n",
      "Epoch 29 loss is 0.12418159289722493\n",
      "Epoch 39 loss is 0.09063661342210186\n",
      "Epoch 49 loss is 0.08274663620794244\n",
      "Epoch 59 loss is 0.07859951940472655\n",
      "Epoch 69 loss is 0.07256532240445507\n",
      "Epoch 79 loss is 0.06916262503726474\n",
      "Epoch 89 loss is 0.0630058410204737\n",
      "Epoch 99 loss is 0.07026817485377791\n",
      "Epoch 109 loss is 0.05949501562367503\n",
      "Epoch 119 loss is 0.053246533281885174\n",
      "Epoch 129 loss is 0.05572973071008147\n",
      "Epoch 139 loss is 0.05570382762746428\n",
      "Epoch 149 loss is 0.08662761110902355\n",
      "Epoch 159 loss is 0.057920531802435\n",
      "Epoch 169 loss is 0.06671310002777765\n",
      "Epoch 179 loss is 0.06361666252378624\n",
      "Epoch 189 loss is 0.0634835982068112\n",
      "Epoch 199 loss is 0.05273022961513594\n",
      "Train Acc.:  0.9670989381930053\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      1064\n",
      "           1       0.95      0.94      0.95      1064\n",
      "           2       0.99      0.98      0.98      1064\n",
      "           3       0.99      0.98      0.98      1064\n",
      "           4       0.96      0.96      0.96      1064\n",
      "           5       0.95      0.95      0.95      1064\n",
      "           6       0.94      0.95      0.94      1063\n",
      "           7       1.00      0.99      1.00      1064\n",
      "           8       1.00      1.00      1.00      1063\n",
      "           9       0.98      0.94      0.96      1064\n",
      "          10       0.98      0.96      0.97      1064\n",
      "\n",
      "   micro avg       0.97      0.97      0.97     11702\n",
      "   macro avg       0.97      0.97      0.97     11702\n",
      "weighted avg       0.97      0.97      0.97     11702\n",
      " samples avg       0.96      0.97      0.96     11702\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "list_losses = []\n",
    "list_scores = []\n",
    "list_acc = []\n",
    "list_loss = []\n",
    "list_f1 = []\n",
    "list_precision = []\n",
    "list_recall = []\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    model_dict: dict = {}\n",
    "    x_train, x_valid, y_train, y_valid = get_splitted_data_by_index(\n",
    "        X, y, neuronCats, train_index, test_index\n",
    "    )\n",
    "\n",
    "    model = Model(categories=categories, periodicity=periodicity)\n",
    "    criterion = ComplexMSE_adjusted_error.apply\n",
    "    optimizer = ECL(model.parameters(), lr=lr)\n",
    "\n",
    "    losses, scores = fit(\n",
    "        model,\n",
    "        x_train,\n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        categories=categories,\n",
    "        periodicity=periodicity,\n",
    "    )\n",
    "\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "    list_scores.append(scores)\n",
    "    list_losses.append(losses)\n",
    "\n",
    "    y_pred = model.predict(x_train)\n",
    "    acc = accuracy(y_pred.squeeze(), y_train)\n",
    "    print(\"Train Acc.: \", acc)\n",
    "\n",
    "    y_pred = model.predict(x_valid)\n",
    "    acc = accuracy(y_pred.squeeze(), y_valid)\n",
    "    list_acc.append(acc)\n",
    "\n",
    "    print(classification_report(y_valid, y_pred.detach().numpy(), zero_division=0))\n",
    "    list_f1.append(\n",
    "        f1_score(y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0)\n",
    "    )\n",
    "    list_precision.append(\n",
    "        precision_score(\n",
    "            y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0\n",
    "        )\n",
    "    )\n",
    "    list_recall.append(\n",
    "        recall_score(\n",
    "            y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0\n",
    "        )\n",
    "    )\n",
    "\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_accuracy_mean\",\n",
    "    value=np.mean(list_acc),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_accuracy_std\",\n",
    "    value=np.std(list_acc),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_f1_mean\",\n",
    "    value=np.mean(list_f1),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_f1_std\",\n",
    "    value=np.std(list_f1),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_precision_mean\",\n",
    "    value=np.mean(list_precision),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_precision_std\",\n",
    "    value=np.std(list_precision),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_recall_mean\",\n",
    "    value=np.mean(list_recall),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_recall_std\",\n",
    "    value=np.std(list_recall),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "task.mark_completed()\n",
    "task.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLMVN [48-100-11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "PATH = str(Path.cwd() / \"models/autass-mlmvn_48-100-11.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, categories, periodicity):\n",
    "        super().__init__()\n",
    "        self.categories = categories\n",
    "        self.periodicity = periodicity\n",
    "        self.first_linear = FirstLayer(48, 100)\n",
    "        self.phase_act1 = cmplx_phase_activation()\n",
    "        self.linear_out = OutputLayer(100, 11)\n",
    "        self.phase_act2 = cmplx_phase_activation()\n",
    "        # Hooks\n",
    "        self.first_layer_hook_handle = self.first_linear.register_full_backward_hook(\n",
    "            self.first_layer_backward_hook\n",
    "        )\n",
    "        self.output_hook_handle = self.linear_out.register_full_backward_hook(\n",
    "            self.output_layer_backward_hook\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first_linear(x)\n",
    "        x = self.phase_act1(x)\n",
    "        x = self.linear_out(x)\n",
    "        x = self.phase_act2(x)\n",
    "        return x\n",
    "\n",
    "    def first_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"first_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def hidden_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"hidden_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def output_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"output_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def angle2class(self, x: torch.tensor) -> torch.tensor:\n",
    "        tmp = x.angle() + 2 * np.pi\n",
    "        angle = torch.remainder(tmp, 2 * np.pi)\n",
    "\n",
    "        # This will be the discrete output (the number of sector)\n",
    "        o = torch.floor(self.categories * self.periodicity * angle / (2 * np.pi))\n",
    "        return torch.remainder(o, self.categories)\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Performs the prediction task of the network\n",
    "\n",
    "        Args:\n",
    "          x: torch.Tensor\n",
    "            Input tensor of size ([3])\n",
    "\n",
    "        Returns:\n",
    "          Most likely class i.e., Label with the highest score\n",
    "        \"\"\"\n",
    "        # Pass the data through the networks\n",
    "        output = self.forward(x)\n",
    "\n",
    "        # # Choose the label with the highest score\n",
    "        # return torch.argmax(output, 1)\n",
    "        return self.angle2class(output)\n",
    "\n",
    "\n",
    "def fit(model, X, y, epochs, batch_size, optimizer, criterion, categories, periodicity):\n",
    "    # List of losses for visualization\n",
    "    losses = []\n",
    "    scores = []\n",
    "    acc_best = 0\n",
    "\n",
    "    for i in range(epochs):\n",
    "        # Pass the data through the network and compute the loss\n",
    "        # We'll use the whole dataset during the training instead of using batches\n",
    "        # in to order to keep the code simple for now.\n",
    "\n",
    "        batch_loss = []\n",
    "\n",
    "        for j in range((X.shape[0] - 1) // batch_size + 1):\n",
    "            start_j = j * batch_size\n",
    "            end_j = start_j + batch_size\n",
    "            xb = X[start_j:end_j]\n",
    "            yb = y[start_j:end_j]\n",
    "\n",
    "            y_pred = model(xb)\n",
    "            loss = criterion(y_pred, yb, categories, periodicity)\n",
    "            batch_loss.append((torch.abs(loss)).detach().numpy())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step(inputs=xb, layers=list(model.children()))\n",
    "\n",
    "        losses.append(sum(batch_loss) / len(batch_loss))\n",
    "        if i % 10 == 9:\n",
    "            print(f\"Epoch {i} loss is {losses[-1]}\")\n",
    "        y_pred = model.predict(X)\n",
    "        scores.append(accuracy(y_pred.squeeze(), y))\n",
    "\n",
    "        if scores[-1] > acc_best:\n",
    "            acc_best = scores[-1]\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "    return losses, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=f7488ccec9764284a4512cb815d86956\n",
      "ClearML results page: http://194.94.231.172:8080/projects/cdefd6ee85454e49be01962ad715eca0/experiments/f7488ccec9764284a4512cb815d86956/output/log\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 1,\n",
       " 'epochs': 200,\n",
       " 'batch_size': 538,\n",
       " 'optim': 'ECL',\n",
       " 'categories': 2,\n",
       " 'periodicity': 1,\n",
       " 'layer': '[48-100-11]',\n",
       " 'loss': 'ComplexMSE_adjusted_error',\n",
       " 'clip_angle_value': 1000000}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = Task.init(\n",
    "    project_name=\"mlmvn\",\n",
    "    task_name=\"SDD-mlmvn-[48-100-11]\",\n",
    "    tags=[\"mlmvn\", \"SDD\", \"multiple_runs\", \"adjusted_loss_clip_angle_value\"],\n",
    ")\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# â€ƒcapture a dictionary of hyperparameters with config\n",
    "config_dict = {\n",
    "    \"learning_rate\": 1,\n",
    "    \"epochs\": epochs,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"optim\": \"ECL\",\n",
    "    \"categories\": categories,\n",
    "    \"periodicity\": periodicity,\n",
    "    \"layer\": \"[48-100-11]\",\n",
    "    \"loss\": \"ComplexMSE_adjusted_error\",\n",
    "    \"clip_angle_value\": clip_angle_value,\n",
    "}\n",
    "task.connect(config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13327/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-27 23:53:35,971 - clearml.frameworks - INFO - Found existing registered model id=0f73e6db01fc42988672e4f44c0add5f [/home/antonpfeifer/Documents/mlmvn/nbs/examples/autass/models/autass-mlmvn_48-100-11.pt] reusing it.\n",
      "Epoch 9 loss is 0.2013734097530227\n",
      "Epoch 19 loss is 0.13194389245179217\n",
      "Epoch 29 loss is 0.10095062501209577\n",
      "Epoch 39 loss is 0.09074072104898326\n",
      "Epoch 49 loss is 0.08300947225827868\n",
      "Epoch 59 loss is 0.0738162527877322\n",
      "Epoch 69 loss is 0.07072649592151344\n",
      "Epoch 79 loss is 0.07138726478663758\n",
      "Epoch 89 loss is 0.06214147198340652\n",
      "Epoch 99 loss is 0.07020503698271563\n",
      "Epoch 109 loss is 0.074644080701454\n",
      "Epoch 119 loss is 0.06734553316012935\n",
      "Epoch 129 loss is 0.059474967215059765\n",
      "Epoch 139 loss is 0.07335145914140831\n",
      "Epoch 149 loss is 0.062376795077677044\n",
      "Epoch 159 loss is 0.0526909906751619\n",
      "Epoch 169 loss is 0.04941692807072795\n",
      "Epoch 179 loss is 0.04210521010111257\n",
      "Epoch 189 loss is 0.0447379761754187\n",
      "Epoch 199 loss is 0.03882946678160469\n",
      "Train Acc.:  0.97899886769073\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      1063\n",
      "           1       0.95      0.94      0.95      1064\n",
      "           2       0.99      0.99      0.99      1064\n",
      "           3       0.99      0.99      0.99      1064\n",
      "           4       0.97      0.96      0.97      1064\n",
      "           5       0.95      0.95      0.95      1063\n",
      "           6       0.96      0.95      0.95      1064\n",
      "           7       1.00      1.00      1.00      1064\n",
      "           8       1.00      1.00      1.00      1064\n",
      "           9       0.97      0.94      0.96      1064\n",
      "          10       0.99      0.98      0.98      1064\n",
      "\n",
      "   micro avg       0.98      0.97      0.97     11702\n",
      "   macro avg       0.98      0.97      0.97     11702\n",
      "weighted avg       0.98      0.97      0.97     11702\n",
      " samples avg       0.96      0.97      0.97     11702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13327/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss is 0.21319071325891403\n",
      "Epoch 19 loss is 0.1541410855291198\n",
      "Epoch 29 loss is 0.12536923443070858\n",
      "Epoch 39 loss is 0.09970140587708567\n",
      "Epoch 49 loss is 0.08215366375661032\n",
      "Epoch 59 loss is 0.07893182432329253\n",
      "Epoch 69 loss is 0.07569625143171067\n",
      "Epoch 79 loss is 0.07090777313842668\n",
      "Epoch 89 loss is 0.06514219463825727\n",
      "Epoch 99 loss is 0.06887248604052763\n",
      "Epoch 109 loss is 0.057908520270728236\n",
      "Epoch 119 loss is 0.057421434582441984\n",
      "Epoch 129 loss is 0.04913560375422588\n",
      "Epoch 139 loss is 0.04935810215299344\n",
      "Epoch 149 loss is 0.04237250334663373\n",
      "Epoch 159 loss is 0.040383543448331234\n",
      "Epoch 169 loss is 0.036213423181436236\n",
      "Epoch 179 loss is 0.03839429011389191\n",
      "Epoch 189 loss is 0.03846825102366323\n",
      "Epoch 199 loss is 0.037638064394336875\n",
      "Train Acc.:  0.9823317025231268\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      1063\n",
      "           1       0.96      0.96      0.96      1064\n",
      "           2       1.00      0.99      1.00      1064\n",
      "           3       0.98      0.99      0.99      1063\n",
      "           4       0.96      0.97      0.96      1064\n",
      "           5       0.97      0.96      0.96      1064\n",
      "           6       0.96      0.95      0.96      1064\n",
      "           7       1.00      1.00      1.00      1064\n",
      "           8       1.00      1.00      1.00      1064\n",
      "           9       0.97      0.96      0.97      1064\n",
      "          10       0.99      0.97      0.98      1064\n",
      "\n",
      "   micro avg       0.98      0.97      0.98     11702\n",
      "   macro avg       0.98      0.97      0.98     11702\n",
      "weighted avg       0.98      0.97      0.98     11702\n",
      " samples avg       0.97      0.97      0.97     11702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13327/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss is 0.20835717627283434\n",
      "Epoch 19 loss is 0.1410003145381981\n",
      "Epoch 29 loss is 0.10362160718673499\n",
      "Epoch 39 loss is 0.09535519170107241\n",
      "Epoch 49 loss is 0.08623970792143622\n",
      "Epoch 59 loss is 0.06967393203823516\n",
      "Epoch 69 loss is 0.07223157768403805\n",
      "Epoch 79 loss is 0.06292363524435325\n",
      "Epoch 89 loss is 0.06516889101094622\n",
      "Epoch 99 loss is 0.05962646936523845\n",
      "Epoch 109 loss is 0.052085959520220305\n",
      "Epoch 119 loss is 0.05127448522332268\n",
      "Epoch 129 loss is 0.04993565878003458\n",
      "Epoch 139 loss is 0.04217621548518707\n",
      "Epoch 149 loss is 0.04918457656177097\n",
      "Epoch 159 loss is 0.03850822431866483\n",
      "Epoch 169 loss is 0.038279677015932684\n",
      "Epoch 179 loss is 0.039339300558995774\n",
      "Epoch 189 loss is 0.03874658731757177\n",
      "Epoch 199 loss is 0.036737692281627654\n",
      "Train Acc.:  0.9827589890401008\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1064\n",
      "           1       0.95      0.95      0.95      1064\n",
      "           2       0.99      0.99      0.99      1064\n",
      "           3       1.00      0.98      0.99      1063\n",
      "           4       0.97      0.96      0.97      1064\n",
      "           5       0.97      0.95      0.96      1064\n",
      "           6       0.96      0.94      0.95      1063\n",
      "           7       1.00      1.00      1.00      1064\n",
      "           8       1.00      1.00      1.00      1064\n",
      "           9       0.97      0.97      0.97      1064\n",
      "          10       0.99      0.98      0.98      1064\n",
      "\n",
      "   micro avg       0.98      0.97      0.98     11702\n",
      "   macro avg       0.98      0.97      0.98     11702\n",
      "weighted avg       0.98      0.97      0.98     11702\n",
      " samples avg       0.97      0.97      0.97     11702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13327/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss is 0.2047739384042335\n",
      "Epoch 19 loss is 0.1240691449665739\n",
      "Epoch 29 loss is 0.1250756910889213\n",
      "Epoch 39 loss is 0.09980943240036731\n",
      "Epoch 49 loss is 0.07931262188990955\n",
      "Epoch 59 loss is 0.06880595699322983\n",
      "Epoch 69 loss is 0.07295263256108461\n",
      "Epoch 79 loss is 0.0657251223690606\n",
      "Epoch 89 loss is 0.06288437799940251\n",
      "Epoch 99 loss is 0.06078154801969977\n",
      "Epoch 109 loss is 0.05630173979958109\n",
      "Epoch 119 loss is 0.05059079914071474\n",
      "Epoch 129 loss is 0.0519624732081652\n",
      "Epoch 139 loss is 0.04989906966215809\n",
      "Epoch 149 loss is 0.046105722466105954\n",
      "Epoch 159 loss is 0.04479487999819714\n",
      "Epoch 169 loss is 0.05169914293629347\n",
      "Epoch 179 loss is 0.05468717561123138\n",
      "Epoch 189 loss is 0.04472661993607276\n",
      "Epoch 199 loss is 0.04167204375351288\n",
      "Train Acc.:  0.9793193325784605\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      1063\n",
      "           1       0.93      0.96      0.94      1064\n",
      "           2       1.00      0.99      1.00      1064\n",
      "           3       0.99      0.98      0.99      1063\n",
      "           4       0.97      0.97      0.97      1064\n",
      "           5       0.97      0.94      0.95      1064\n",
      "           6       0.96      0.94      0.95      1064\n",
      "           7       1.00      1.00      1.00      1064\n",
      "           8       1.00      1.00      1.00      1064\n",
      "           9       0.97      0.96      0.97      1064\n",
      "          10       0.98      0.97      0.98      1064\n",
      "\n",
      "   micro avg       0.98      0.97      0.97     11702\n",
      "   macro avg       0.98      0.97      0.97     11702\n",
      "weighted avg       0.98      0.97      0.97     11702\n",
      " samples avg       0.97      0.97      0.97     11702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13327/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss is 0.24100019695211888\n",
      "Epoch 19 loss is 0.15365636763706683\n",
      "Epoch 29 loss is 0.11363793386653538\n",
      "Epoch 39 loss is 0.09423439262203624\n",
      "Epoch 49 loss is 0.08824477344066799\n",
      "Epoch 59 loss is 0.07361807474799302\n",
      "Epoch 69 loss is 0.07530689777501173\n",
      "Epoch 79 loss is 0.06350203232630086\n",
      "Epoch 89 loss is 0.061400948333146264\n",
      "Epoch 99 loss is 0.05771039868957064\n",
      "Epoch 109 loss is 0.057609481716596814\n",
      "Epoch 119 loss is 0.05653083207399525\n",
      "Epoch 129 loss is 0.05154005805827653\n",
      "Epoch 139 loss is 0.05072576182283894\n",
      "Epoch 149 loss is 0.046395221236291556\n",
      "Epoch 159 loss is 0.04620623101501136\n",
      "Epoch 169 loss is 0.042652961928911375\n",
      "Epoch 179 loss is 0.0574112161346133\n",
      "Epoch 189 loss is 0.044568967625431236\n",
      "Epoch 199 loss is 0.03852016601626823\n",
      "Train Acc.:  0.9786570384771508\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      1064\n",
      "           1       0.95      0.96      0.95      1064\n",
      "           2       0.99      0.98      0.99      1064\n",
      "           3       0.99      0.98      0.99      1064\n",
      "           4       0.98      0.95      0.96      1064\n",
      "           5       0.96      0.94      0.95      1064\n",
      "           6       0.94      0.95      0.95      1063\n",
      "           7       1.00      1.00      1.00      1064\n",
      "           8       1.00      1.00      1.00      1063\n",
      "           9       0.96      0.95      0.96      1064\n",
      "          10       0.99      0.98      0.98      1064\n",
      "\n",
      "   micro avg       0.98      0.97      0.97     11702\n",
      "   macro avg       0.98      0.97      0.97     11702\n",
      "weighted avg       0.98      0.97      0.97     11702\n",
      " samples avg       0.96      0.97      0.97     11702\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "list_losses = []\n",
    "list_scores = []\n",
    "list_acc = []\n",
    "list_loss = []\n",
    "list_f1 = []\n",
    "list_precision = []\n",
    "list_recall = []\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    model_dict: dict = {}\n",
    "    x_train, x_valid, y_train, y_valid = get_splitted_data_by_index(\n",
    "        X, y, neuronCats, train_index, test_index\n",
    "    )\n",
    "\n",
    "    model = Model(categories=categories, periodicity=periodicity)\n",
    "    criterion = ComplexMSE_adjusted_error.apply\n",
    "    optimizer = ECL(model.parameters(), lr=lr)\n",
    "\n",
    "    losses, scores = fit(\n",
    "        model,\n",
    "        x_train,\n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        categories=categories,\n",
    "        periodicity=periodicity,\n",
    "    )\n",
    "\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "    list_scores.append(scores)\n",
    "    list_losses.append(losses)\n",
    "\n",
    "    y_pred = model.predict(x_train)\n",
    "    acc = accuracy(y_pred.squeeze(), y_train)\n",
    "    print(\"Train Acc.: \", acc)\n",
    "\n",
    "    y_pred = model.predict(x_valid)\n",
    "    acc = accuracy(y_pred.squeeze(), y_valid)\n",
    "    list_acc.append(acc)\n",
    "\n",
    "    print(classification_report(y_valid, y_pred.detach().numpy(), zero_division=0))\n",
    "    list_f1.append(\n",
    "        f1_score(y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0)\n",
    "    )\n",
    "    list_precision.append(\n",
    "        precision_score(\n",
    "            y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0\n",
    "        )\n",
    "    )\n",
    "    list_recall.append(\n",
    "        recall_score(\n",
    "            y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0\n",
    "        )\n",
    "    )\n",
    "\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_accuracy_mean\",\n",
    "    value=np.mean(list_acc),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_accuracy_std\",\n",
    "    value=np.std(list_acc),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_f1_mean\",\n",
    "    value=np.mean(list_f1),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_f1_std\",\n",
    "    value=np.std(list_f1),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_precision_mean\",\n",
    "    value=np.mean(list_precision),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_precision_std\",\n",
    "    value=np.std(list_precision),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_recall_mean\",\n",
    "    value=np.mean(list_recall),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_recall_std\",\n",
    "    value=np.std(list_recall),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "task.mark_completed()\n",
    "task.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLMVN [48-10-10-11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "PATH = str(Path.cwd() / \"models/autass-mlmvn_48-10-10-11.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, categories, periodicity):\n",
    "        super().__init__()\n",
    "        self.categories = categories\n",
    "        self.periodicity = periodicity\n",
    "        self.first_linear = FirstLayer(48, 10)\n",
    "        self.phase_act1 = cmplx_phase_activation()\n",
    "        self.hidden_layer = HiddenLayer(10, 10)\n",
    "        self.phase_act2 = cmplx_phase_activation()\n",
    "        self.linear_out = OutputLayer(10, 11)\n",
    "        self.phase_act3 = cmplx_phase_activation()\n",
    "        # Hooks\n",
    "        self.first_layer_hook_handle = self.first_linear.register_full_backward_hook(\n",
    "            self.first_layer_backward_hook\n",
    "        )\n",
    "        self.hidden_layer_hook_handle = self.hidden_layer.register_full_backward_hook(\n",
    "            self.hidden_layer_backward_hook\n",
    "        )\n",
    "        self.output_hook_handle = self.linear_out.register_full_backward_hook(\n",
    "            self.output_layer_backward_hook\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first_linear(x)\n",
    "        x = self.phase_act1(x)\n",
    "        x = self.hidden_layer(x)\n",
    "        x = self.phase_act2(x)\n",
    "        x = self.linear_out(x)\n",
    "        x = self.phase_act3(x)\n",
    "        return x\n",
    "\n",
    "    def first_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"first_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def hidden_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"hidden_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def output_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"output_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def angle2class(self, x: torch.tensor) -> torch.tensor:\n",
    "        tmp = x.angle() + 2 * np.pi\n",
    "        angle = torch.remainder(tmp, 2 * np.pi)\n",
    "\n",
    "        # This will be the discrete output (the number of sector)\n",
    "        o = torch.floor(self.categories * self.periodicity * angle / (2 * np.pi))\n",
    "        return torch.remainder(o, self.categories)\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Performs the prediction task of the network\n",
    "\n",
    "        Args:\n",
    "          x: torch.Tensor\n",
    "            Input tensor of size ([3])\n",
    "\n",
    "        Returns:\n",
    "          Most likely class i.e., Label with the highest score\n",
    "        \"\"\"\n",
    "        # Pass the data through the networks\n",
    "        output = self.forward(x)\n",
    "\n",
    "        # # Choose the label with the highest score\n",
    "        # return torch.argmax(output, 1)\n",
    "        return self.angle2class(output)\n",
    "\n",
    "\n",
    "def fit(model, X, y, epochs, batch_size, optimizer, criterion, categories, periodicity):\n",
    "    # List of losses for visualization\n",
    "    losses = []\n",
    "    scores = []\n",
    "    acc_best = 0\n",
    "\n",
    "    for i in range(epochs):\n",
    "        # Pass the data through the network and compute the loss\n",
    "        # We'll use the whole dataset during the training instead of using batches\n",
    "        # in to order to keep the code simple for now.\n",
    "\n",
    "        batch_loss = []\n",
    "\n",
    "        for j in range((X.shape[0] - 1) // batch_size + 1):\n",
    "            start_j = j * batch_size\n",
    "            end_j = start_j + batch_size\n",
    "            xb = X[start_j:end_j]\n",
    "            yb = y[start_j:end_j]\n",
    "\n",
    "            y_pred = model(xb)\n",
    "            loss = criterion(y_pred, yb, categories, periodicity)\n",
    "            batch_loss.append((torch.abs(loss)).detach().numpy())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step(inputs=xb, layers=list(model.children()))\n",
    "\n",
    "        losses.append(sum(batch_loss) / len(batch_loss))\n",
    "        if i % 10 == 9:\n",
    "            print(f\"Epoch {i} loss is {losses[-1]}\")\n",
    "        y_pred = model.predict(X)\n",
    "        scores.append(accuracy(y_pred.squeeze(), y))\n",
    "\n",
    "        if scores[-1] > acc_best:\n",
    "            acc_best = scores[-1]\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "    return losses, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=981abbac21de4753879436acdf36c17b\n",
      "ClearML results page: http://194.94.231.172:8080/projects/cdefd6ee85454e49be01962ad715eca0/experiments/981abbac21de4753879436acdf36c17b/output/log\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 1,\n",
       " 'epochs': 200,\n",
       " 'batch_size': 538,\n",
       " 'optim': 'ECL',\n",
       " 'categories': 2,\n",
       " 'periodicity': 1,\n",
       " 'layer': '[48-10-10-11]',\n",
       " 'loss': 'ComplexMSE_adjusted_error',\n",
       " 'clip_angle_value': 1000000}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = Task.init(\n",
    "    project_name=\"mlmvn\",\n",
    "    task_name=\"SDD-mlmvn-[48-10-10-11]\",\n",
    "    tags=[\"mlmvn\", \"SDD\", \"multiple_runs\", \"adjusted_loss_clip_angle_value\"],\n",
    ")\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# â€ƒcapture a dictionary of hyperparameters with config\n",
    "config_dict = {\n",
    "    \"learning_rate\": 1,\n",
    "    \"epochs\": epochs,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"optim\": \"ECL\",\n",
    "    \"categories\": categories,\n",
    "    \"periodicity\": periodicity,\n",
    "    \"layer\": \"[48-10-10-11]\",\n",
    "    \"loss\": \"ComplexMSE_adjusted_error\",\n",
    "    \"clip_angle_value\": clip_angle_value,\n",
    "}\n",
    "task.connect(config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13327/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-28 00:41:30,778 - clearml.frameworks - INFO - Found existing registered model id=410edb2915b24269b7d34f2e38593dff [/home/antonpfeifer/Documents/mlmvn/nbs/examples/autass/models/autass-mlmvn_48-10-10-11.pt] reusing it.\n",
      "Epoch 9 loss is 0.541454749663616\n",
      "Epoch 19 loss is 0.8791410713849316\n",
      "Epoch 29 loss is 0.8839316416940527\n",
      "Epoch 39 loss is 0.8966399825316692\n",
      "Epoch 49 loss is 0.9264105355661884\n",
      "Epoch 59 loss is 0.951371120459427\n",
      "Epoch 69 loss is 0.9412028121256291\n",
      "Epoch 79 loss is 0.9732946912045937\n",
      "Epoch 89 loss is 0.9181100154489218\n",
      "Epoch 99 loss is 0.9329806316494657\n",
      "Epoch 109 loss is 0.9328285713006949\n",
      "Epoch 119 loss is 0.9419897937541761\n",
      "Epoch 129 loss is 0.9427600691188952\n",
      "Epoch 139 loss is 0.9091315900275359\n",
      "Epoch 149 loss is 0.9324776865430842\n",
      "Epoch 159 loss is 0.9134668719369948\n",
      "Epoch 169 loss is 0.9403598662976411\n",
      "Epoch 179 loss is 0.9422566273044115\n",
      "Epoch 189 loss is 0.9543148096619407\n",
      "Epoch 199 loss is 0.9549645974775849\n",
      "Train Acc.:  0.5539342406050377\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.60      0.68      1063\n",
      "           1       0.65      0.47      0.55      1064\n",
      "           2       0.94      0.67      0.78      1064\n",
      "           3       0.89      0.62      0.73      1064\n",
      "           4       0.32      0.16      0.21      1064\n",
      "           5       0.73      0.69      0.71      1063\n",
      "           6       0.82      0.44      0.57      1064\n",
      "           7       0.91      0.69      0.78      1064\n",
      "           8       0.98      0.95      0.97      1064\n",
      "           9       0.68      0.90      0.77      1064\n",
      "          10       0.76      0.69      0.72      1064\n",
      "\n",
      "   micro avg       0.78      0.63      0.69     11702\n",
      "   macro avg       0.77      0.63      0.68     11702\n",
      "weighted avg       0.77      0.63      0.68     11702\n",
      " samples avg       0.59      0.63      0.60     11702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13327/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss is 0.34781102538165637\n",
      "Epoch 19 loss is 0.4926261439071808\n",
      "Epoch 29 loss is 0.6328775813367924\n",
      "Epoch 39 loss is 0.7170839574504813\n",
      "Epoch 49 loss is 0.6934163739177756\n",
      "Epoch 59 loss is 0.7141162567964217\n",
      "Epoch 69 loss is 0.7691114368900678\n",
      "Epoch 79 loss is 0.7562372003321447\n",
      "Epoch 89 loss is 0.7766109368260417\n",
      "Epoch 99 loss is 0.7075230256227628\n",
      "Epoch 109 loss is 0.7393482060014152\n",
      "Epoch 119 loss is 0.7458410915657656\n",
      "Epoch 129 loss is 0.7585006377982786\n",
      "Epoch 139 loss is 0.7711069196763435\n",
      "Epoch 149 loss is 0.7341288291259812\n",
      "Epoch 159 loss is 0.7801133649364619\n",
      "Epoch 169 loss is 0.7263681341448134\n",
      "Epoch 179 loss is 0.7519011054649812\n",
      "Epoch 189 loss is 0.7048160484621695\n",
      "Epoch 199 loss is 0.7475459901191056\n",
      "Train Acc.:  0.7177986198645502\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.83      0.86      1063\n",
      "           1       0.83      0.74      0.78      1064\n",
      "           2       0.94      0.84      0.89      1064\n",
      "           3       0.82      0.79      0.81      1063\n",
      "           4       0.68      0.66      0.67      1064\n",
      "           5       0.83      0.83      0.83      1064\n",
      "           6       0.70      0.60      0.64      1064\n",
      "           7       0.99      0.94      0.96      1064\n",
      "           8       0.99      0.97      0.98      1064\n",
      "           9       0.83      0.75      0.79      1064\n",
      "          10       0.76      0.75      0.76      1064\n",
      "\n",
      "   micro avg       0.84      0.79      0.82     11702\n",
      "   macro avg       0.84      0.79      0.81     11702\n",
      "weighted avg       0.84      0.79      0.81     11702\n",
      " samples avg       0.75      0.79      0.77     11702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13327/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss is 0.608739696487545\n",
      "Epoch 19 loss is 0.7696193880760408\n",
      "Epoch 29 loss is 0.803278156062957\n",
      "Epoch 39 loss is 0.8387883156242925\n",
      "Epoch 49 loss is 0.7807021280520069\n",
      "Epoch 59 loss is 0.8088241619223006\n",
      "Epoch 69 loss is 0.8070463633451938\n",
      "Epoch 79 loss is 0.7945587323244073\n",
      "Epoch 89 loss is 0.8392897794392442\n",
      "Epoch 99 loss is 0.8214029347151293\n",
      "Epoch 109 loss is 0.8340895850326423\n",
      "Epoch 119 loss is 0.8219225005001145\n",
      "Epoch 129 loss is 0.8507321513973675\n",
      "Epoch 139 loss is 0.8635722140704808\n",
      "Epoch 149 loss is 0.8446035024910838\n",
      "Epoch 159 loss is 0.8153800610100258\n",
      "Epoch 169 loss is 0.860221271499099\n",
      "Epoch 179 loss is 0.8713979258843838\n",
      "Epoch 189 loss is 0.8423941483588755\n",
      "Epoch 199 loss is 0.7982078285674677\n",
      "Train Acc.:  0.5234687119447946\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.76      0.79      1064\n",
      "           1       0.73      0.59      0.66      1064\n",
      "           2       0.59      0.22      0.33      1064\n",
      "           3       0.75      0.68      0.71      1063\n",
      "           4       0.55      0.52      0.54      1064\n",
      "           5       0.49      0.48      0.48      1064\n",
      "           6       0.70      0.56      0.62      1063\n",
      "           7       0.88      0.77      0.83      1064\n",
      "           8       0.99      0.92      0.95      1064\n",
      "           9       0.76      0.57      0.65      1064\n",
      "          10       0.85      0.73      0.79      1064\n",
      "\n",
      "   micro avg       0.74      0.62      0.68     11702\n",
      "   macro avg       0.74      0.62      0.67     11702\n",
      "weighted avg       0.74      0.62      0.67     11702\n",
      " samples avg       0.57      0.62      0.58     11702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13327/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss is 0.2881004625544315\n",
      "Epoch 19 loss is 0.257601894880915\n",
      "Epoch 29 loss is 0.3070432292199646\n",
      "Epoch 39 loss is 1.0114987272533784\n",
      "Epoch 49 loss is 1.0626524147227299\n",
      "Epoch 59 loss is 0.7220235506940849\n",
      "Epoch 69 loss is 0.8701604350827594\n",
      "Epoch 79 loss is 1.2108727994663198\n",
      "Epoch 89 loss is 1.138239338460986\n",
      "Epoch 99 loss is 1.4603121925675742\n",
      "Epoch 109 loss is 1.4954496178854135\n",
      "Epoch 119 loss is 1.2679945725843622\n",
      "Epoch 129 loss is 1.0164146082349543\n",
      "Epoch 139 loss is 1.1297298068650685\n",
      "Epoch 149 loss is 1.253219169435164\n",
      "Epoch 159 loss is 1.1736291050368979\n",
      "Epoch 169 loss is 1.1826341111065124\n",
      "Epoch 179 loss is 1.4031484346107788\n",
      "Epoch 189 loss is 1.2205340600894026\n",
      "Epoch 199 loss is 1.3048065655004846\n",
      "Train Acc.:  0.7068600850300168\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.86      0.80      1063\n",
      "           1       0.81      0.79      0.80      1064\n",
      "           2       0.94      0.85      0.89      1064\n",
      "           3       0.87      0.84      0.85      1063\n",
      "           4       0.73      0.48      0.58      1064\n",
      "           5       0.85      0.77      0.81      1064\n",
      "           6       0.84      0.65      0.73      1064\n",
      "           7       0.97      0.97      0.97      1064\n",
      "           8       0.99      0.95      0.97      1064\n",
      "           9       0.53      0.97      0.69      1064\n",
      "          10       0.92      0.76      0.83      1064\n",
      "\n",
      "   micro avg       0.81      0.81      0.81     11702\n",
      "   macro avg       0.84      0.81      0.81     11702\n",
      "weighted avg       0.84      0.81      0.81     11702\n",
      " samples avg       0.75      0.81      0.77     11702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13327/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss is 0.5949722022582887\n",
      "Epoch 19 loss is 0.8542236273844039\n",
      "Epoch 29 loss is 0.8749541100255886\n",
      "Epoch 39 loss is 0.9226380212308712\n",
      "Epoch 49 loss is 0.9189451568276324\n",
      "Epoch 59 loss is 0.9365599144446709\n",
      "Epoch 69 loss is 0.9302873031362572\n",
      "Epoch 79 loss is 0.9133083164488084\n",
      "Epoch 89 loss is 0.867765838931149\n",
      "Epoch 99 loss is 0.9202292373715069\n",
      "Epoch 109 loss is 0.8840360283963321\n",
      "Epoch 119 loss is 0.8900084272652079\n",
      "Epoch 129 loss is 0.8624389865444407\n",
      "Epoch 139 loss is 0.86264759032102\n",
      "Epoch 149 loss is 0.877634036686458\n",
      "Epoch 159 loss is 0.8911980209206599\n",
      "Epoch 169 loss is 0.8815296026365007\n",
      "Epoch 179 loss is 0.8890566057952398\n",
      "Epoch 189 loss is 0.8732226294946295\n",
      "Epoch 199 loss is 0.9232258855476119\n",
      "Train Acc.:  0.5140470442455188\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.66      0.72      1064\n",
      "           1       0.72      0.55      0.62      1064\n",
      "           2       0.75      0.53      0.62      1064\n",
      "           3       0.75      0.55      0.64      1064\n",
      "           4       0.49      0.36      0.42      1064\n",
      "           5       0.76      0.72      0.74      1064\n",
      "           6       0.56      0.38      0.45      1063\n",
      "           7       0.94      0.90      0.92      1064\n",
      "           8       0.98      0.97      0.98      1063\n",
      "           9       0.64      0.47      0.54      1064\n",
      "          10       0.75      0.50      0.60      1064\n",
      "\n",
      "   micro avg       0.75      0.60      0.67     11702\n",
      "   macro avg       0.74      0.60      0.66     11702\n",
      "weighted avg       0.74      0.60      0.66     11702\n",
      " samples avg       0.55      0.60      0.57     11702\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "list_losses = []\n",
    "list_scores = []\n",
    "list_acc = []\n",
    "list_loss = []\n",
    "list_f1 = []\n",
    "list_precision = []\n",
    "list_recall = []\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    model_dict: dict = {}\n",
    "    x_train, x_valid, y_train, y_valid = get_splitted_data_by_index(\n",
    "        X, y, neuronCats, train_index, test_index\n",
    "    )\n",
    "\n",
    "    model = Model(categories=categories, periodicity=periodicity)\n",
    "    criterion = ComplexMSE_adjusted_error.apply\n",
    "    optimizer = ECL(model.parameters(), lr=lr)\n",
    "\n",
    "    losses, scores = fit(\n",
    "        model,\n",
    "        x_train,\n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        categories=categories,\n",
    "        periodicity=periodicity,\n",
    "    )\n",
    "\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "    list_scores.append(scores)\n",
    "    list_losses.append(losses)\n",
    "\n",
    "    y_pred = model.predict(x_train)\n",
    "    acc = accuracy(y_pred.squeeze(), y_train)\n",
    "    print(\"Train Acc.: \", acc)\n",
    "\n",
    "    y_pred = model.predict(x_valid)\n",
    "    acc = accuracy(y_pred.squeeze(), y_valid)\n",
    "    list_acc.append(acc)\n",
    "\n",
    "    print(classification_report(y_valid, y_pred.detach().numpy(), zero_division=0))\n",
    "    list_f1.append(\n",
    "        f1_score(y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0)\n",
    "    )\n",
    "    list_precision.append(\n",
    "        precision_score(\n",
    "            y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0\n",
    "        )\n",
    "    )\n",
    "    list_recall.append(\n",
    "        recall_score(\n",
    "            y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0\n",
    "        )\n",
    "    )\n",
    "\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_accuracy_mean\",\n",
    "    value=np.mean(list_acc),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_accuracy_std\",\n",
    "    value=np.std(list_acc),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_f1_mean\",\n",
    "    value=np.mean(list_f1),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_f1_std\",\n",
    "    value=np.std(list_f1),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_precision_mean\",\n",
    "    value=np.mean(list_precision),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_precision_std\",\n",
    "    value=np.std(list_precision),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_recall_mean\",\n",
    "    value=np.mean(list_recall),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_recall_std\",\n",
    "    value=np.std(list_recall),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "task.mark_completed()\n",
    "task.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLMVN [48-20-20-11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "PATH = str(Path.cwd() / \"models/autass-mlmvn_48-20-20-11.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, categories, periodicity):\n",
    "        super().__init__()\n",
    "        self.categories = categories\n",
    "        self.periodicity = periodicity\n",
    "        self.first_linear = FirstLayer(48, 20)\n",
    "        self.phase_act1 = cmplx_phase_activation()\n",
    "        self.hidden_layer = HiddenLayer(20, 20)\n",
    "        self.phase_act2 = cmplx_phase_activation()\n",
    "        self.linear_out = OutputLayer(20, 11)\n",
    "        self.phase_act3 = cmplx_phase_activation()\n",
    "        # Hooks\n",
    "        self.first_layer_hook_handle = self.first_linear.register_full_backward_hook(\n",
    "            self.first_layer_backward_hook\n",
    "        )\n",
    "        self.hidden_layer_hook_handle = self.hidden_layer.register_full_backward_hook(\n",
    "            self.hidden_layer_backward_hook\n",
    "        )\n",
    "        self.output_hook_handle = self.linear_out.register_full_backward_hook(\n",
    "            self.output_layer_backward_hook\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first_linear(x)\n",
    "        x = self.phase_act1(x)\n",
    "        x = self.hidden_layer(x)\n",
    "        x = self.phase_act2(x)\n",
    "        x = self.linear_out(x)\n",
    "        x = self.phase_act3(x)\n",
    "        return x\n",
    "\n",
    "    def first_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"first_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def hidden_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"hidden_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def output_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"output_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def angle2class(self, x: torch.tensor) -> torch.tensor:\n",
    "        tmp = x.angle() + 2 * np.pi\n",
    "        angle = torch.remainder(tmp, 2 * np.pi)\n",
    "\n",
    "        # This will be the discrete output (the number of sector)\n",
    "        o = torch.floor(self.categories * self.periodicity * angle / (2 * np.pi))\n",
    "        return torch.remainder(o, self.categories)\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Performs the prediction task of the network\n",
    "\n",
    "        Args:\n",
    "          x: torch.Tensor\n",
    "            Input tensor of size ([3])\n",
    "\n",
    "        Returns:\n",
    "          Most likely class i.e., Label with the highest score\n",
    "        \"\"\"\n",
    "        # Pass the data through the networks\n",
    "        output = self.forward(x)\n",
    "\n",
    "        # # Choose the label with the highest score\n",
    "        # return torch.argmax(output, 1)\n",
    "        return self.angle2class(output)\n",
    "\n",
    "\n",
    "def fit(model, X, y, epochs, batch_size, optimizer, criterion, categories, periodicity):\n",
    "    # List of losses for visualization\n",
    "    losses = []\n",
    "    scores = []\n",
    "    acc_best = 0\n",
    "\n",
    "    for i in range(epochs):\n",
    "        # Pass the data through the network and compute the loss\n",
    "        # We'll use the whole dataset during the training instead of using batches\n",
    "        # in to order to keep the code simple for now.\n",
    "\n",
    "        batch_loss = []\n",
    "\n",
    "        for j in range((X.shape[0] - 1) // batch_size + 1):\n",
    "            start_j = j * batch_size\n",
    "            end_j = start_j + batch_size\n",
    "            xb = X[start_j:end_j]\n",
    "            yb = y[start_j:end_j]\n",
    "\n",
    "            y_pred = model(xb)\n",
    "            loss = criterion(y_pred, yb, categories, periodicity)\n",
    "            batch_loss.append((torch.abs(loss)).detach().numpy())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step(inputs=xb, layers=list(model.children()))\n",
    "\n",
    "        losses.append(sum(batch_loss) / len(batch_loss))\n",
    "        if i % 10 == 9:\n",
    "            print(f\"Epoch {i} loss is {losses[-1]}\")\n",
    "        y_pred = model.predict(X)\n",
    "        scores.append(accuracy(y_pred.squeeze(), y))\n",
    "\n",
    "        if scores[-1] > acc_best:\n",
    "            acc_best = scores[-1]\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "    return losses, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=21bd2a05ea18403b8c16084955a62c7b\n",
      "ClearML results page: http://194.94.231.172:8080/projects/cdefd6ee85454e49be01962ad715eca0/experiments/21bd2a05ea18403b8c16084955a62c7b/output/log\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 1,\n",
       " 'epochs': 200,\n",
       " 'batch_size': 538,\n",
       " 'optim': 'ECL',\n",
       " 'categories': 2,\n",
       " 'periodicity': 1,\n",
       " 'layer': '[48-20-20-11]',\n",
       " 'loss': 'ComplexMSE_adjusted_error',\n",
       " 'clip_angle_value': 1000000}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = Task.init(\n",
    "    project_name=\"mlmvn\",\n",
    "    task_name=\"SDD-mlmvn-[48-20-20-11]\",\n",
    "    tags=[\"mlmvn\", \"SDD\", \"multiple_runs\", \"adjusted_loss_clip_angle_value\"],\n",
    ")\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# â€ƒcapture a dictionary of hyperparameters with config\n",
    "config_dict = {\n",
    "    \"learning_rate\": 1,\n",
    "    \"epochs\": epochs,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"optim\": \"ECL\",\n",
    "    \"categories\": categories,\n",
    "    \"periodicity\": periodicity,\n",
    "    \"layer\": \"[48-20-20-11]\",\n",
    "    \"loss\": \"ComplexMSE_adjusted_error\",\n",
    "    \"clip_angle_value\": clip_angle_value,\n",
    "}\n",
    "task.connect(config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13327/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-28 01:07:31,491 - clearml.frameworks - INFO - Found existing registered model id=22ba5a4169ed406a9e74f40200bd29a1 [/home/antonpfeifer/Documents/mlmvn/nbs/examples/autass/models/autass-mlmvn_48-20-20-11.pt] reusing it.\n",
      "Epoch 9 loss is 0.37705022557280987\n",
      "Epoch 19 loss is 0.2740187803883329\n",
      "Epoch 29 loss is 0.45516830949325443\n",
      "Epoch 39 loss is 0.6148356752471408\n",
      "Epoch 49 loss is 0.6222640142110359\n",
      "Epoch 59 loss is 0.6982017039915205\n",
      "Epoch 69 loss is 0.6373358815772685\n",
      "Epoch 79 loss is 0.6311755328631491\n",
      "Epoch 89 loss is 0.6082573092923741\n",
      "Epoch 99 loss is 0.603828268133041\n",
      "Epoch 109 loss is 0.6389025164997437\n",
      "Epoch 119 loss is 0.6260305680358405\n",
      "Epoch 129 loss is 0.6324748094532601\n",
      "Epoch 139 loss is 0.5943924798856283\n",
      "Epoch 149 loss is 0.6344508674597645\n",
      "Epoch 159 loss is 0.6141789833696603\n",
      "Epoch 169 loss is 0.6086970307893493\n",
      "Epoch 179 loss is 0.5824319841233837\n",
      "Epoch 189 loss is 0.6191231138277477\n",
      "Epoch 199 loss is 0.5666659157355745\n",
      "Train Acc.:  0.730681308351315\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.92      1063\n",
      "           1       0.82      0.70      0.76      1064\n",
      "           2       0.86      0.73      0.79      1064\n",
      "           3       0.89      0.83      0.86      1064\n",
      "           4       0.84      0.81      0.82      1064\n",
      "           5       0.86      0.76      0.81      1063\n",
      "           6       0.75      0.87      0.81      1064\n",
      "           7       0.97      0.91      0.94      1064\n",
      "           8       1.00      0.97      0.99      1064\n",
      "           9       0.80      0.68      0.73      1064\n",
      "          10       0.70      0.53      0.60      1064\n",
      "\n",
      "   micro avg       0.86      0.79      0.82     11702\n",
      "   macro avg       0.86      0.79      0.82     11702\n",
      "weighted avg       0.86      0.79      0.82     11702\n",
      " samples avg       0.76      0.79      0.77     11702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13327/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss is 0.28806597272279794\n",
      "Epoch 19 loss is 0.22970233591793254\n",
      "Epoch 29 loss is 0.28585426998250507\n",
      "Epoch 39 loss is 0.38502680568849784\n",
      "Epoch 49 loss is 0.7625332656829702\n",
      "Epoch 59 loss is 0.6732264557756368\n",
      "Epoch 69 loss is 0.6217295541960539\n",
      "Epoch 79 loss is 0.6893322196897432\n",
      "Epoch 89 loss is 0.6622742723169387\n",
      "Epoch 99 loss is 0.6960203626199706\n",
      "Epoch 109 loss is 0.6777245937457624\n",
      "Epoch 119 loss is 0.7176237176692954\n",
      "Epoch 129 loss is 0.742547024761961\n",
      "Epoch 139 loss is 0.7291200957471028\n",
      "Epoch 149 loss is 0.7470137933371792\n",
      "Epoch 159 loss is 0.7220883556014549\n",
      "Epoch 169 loss is 0.7159556336891169\n",
      "Epoch 179 loss is 0.7108887748361287\n",
      "Epoch 189 loss is 0.7436282315327294\n",
      "Epoch 199 loss is 0.694954785146677\n",
      "Train Acc.:  0.7865276561198111\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.94      1063\n",
      "           1       0.80      0.74      0.77      1064\n",
      "           2       0.90      0.76      0.82      1064\n",
      "           3       0.93      0.90      0.92      1063\n",
      "           4       0.85      0.81      0.83      1064\n",
      "           5       0.81      0.72      0.76      1064\n",
      "           6       0.76      0.70      0.73      1064\n",
      "           7       0.99      0.93      0.96      1064\n",
      "           8       1.00      0.98      0.99      1064\n",
      "           9       0.87      0.88      0.87      1064\n",
      "          10       0.91      0.89      0.90      1064\n",
      "\n",
      "   micro avg       0.89      0.84      0.86     11702\n",
      "   macro avg       0.89      0.84      0.86     11702\n",
      "weighted avg       0.89      0.84      0.86     11702\n",
      " samples avg       0.81      0.84      0.82     11702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13327/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss is 0.2511134256926335\n",
      "Epoch 19 loss is 0.22011394441410292\n",
      "Epoch 29 loss is 0.22056851414206183\n",
      "Epoch 39 loss is 0.2551644861115903\n",
      "Epoch 49 loss is 0.47249132940476685\n",
      "Epoch 59 loss is 0.6799162460754719\n",
      "Epoch 69 loss is 0.6906088651202789\n",
      "Epoch 79 loss is 0.7231533868835432\n",
      "Epoch 89 loss is 0.738398383750411\n",
      "Epoch 99 loss is 0.7811543296378222\n",
      "Epoch 109 loss is 0.7535960303277581\n",
      "Epoch 119 loss is 0.7163676381713118\n",
      "Epoch 129 loss is 0.7103477423606941\n",
      "Epoch 139 loss is 0.7078374401246286\n",
      "Epoch 149 loss is 0.7199227568498184\n",
      "Epoch 159 loss is 0.7107330170199827\n",
      "Epoch 169 loss is 0.7056031770853555\n",
      "Epoch 179 loss is 0.7327502640763232\n",
      "Epoch 189 loss is 0.7094453790723616\n",
      "Epoch 199 loss is 0.7120579963814156\n",
      "Train Acc.:  0.7947956502232572\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93      1064\n",
      "           1       0.85      0.80      0.82      1064\n",
      "           2       0.87      0.77      0.82      1064\n",
      "           3       0.93      0.86      0.89      1063\n",
      "           4       0.84      0.82      0.83      1064\n",
      "           5       0.85      0.86      0.86      1064\n",
      "           6       0.82      0.70      0.75      1063\n",
      "           7       0.96      0.90      0.93      1064\n",
      "           8       0.99      0.95      0.97      1064\n",
      "           9       0.86      0.87      0.86      1064\n",
      "          10       0.90      0.87      0.88      1064\n",
      "\n",
      "   micro avg       0.89      0.85      0.87     11702\n",
      "   macro avg       0.89      0.85      0.87     11702\n",
      "weighted avg       0.89      0.85      0.87     11702\n",
      " samples avg       0.82      0.85      0.83     11702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13327/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss is 0.28920254058590406\n",
      "Epoch 19 loss is 0.20422793527357072\n",
      "Epoch 29 loss is 0.23514562707658523\n",
      "Epoch 39 loss is 0.30951769319469474\n",
      "Epoch 49 loss is 0.802884197886128\n",
      "Epoch 59 loss is 0.629426963749978\n",
      "Epoch 69 loss is 0.6618189152336303\n",
      "Epoch 79 loss is 0.639523350080704\n",
      "Epoch 89 loss is 0.6033113390242072\n",
      "Epoch 99 loss is 0.6365305132984823\n",
      "Epoch 109 loss is 0.6149712207622507\n",
      "Epoch 119 loss is 0.6332012921437696\n",
      "Epoch 129 loss is 0.6520249413523534\n",
      "Epoch 139 loss is 0.6450135768078111\n",
      "Epoch 149 loss is 0.6724773114718959\n",
      "Epoch 159 loss is 0.637959073743463\n",
      "Epoch 169 loss is 0.5887977689032348\n",
      "Epoch 179 loss is 0.6275123627575196\n",
      "Epoch 189 loss is 0.6157577124370395\n",
      "Epoch 199 loss is 0.5571599018372312\n",
      "Train Acc.:  0.7962056957292712\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92      1063\n",
      "           1       0.84      0.81      0.83      1064\n",
      "           2       0.93      0.86      0.90      1064\n",
      "           3       0.89      0.87      0.88      1063\n",
      "           4       0.87      0.77      0.82      1064\n",
      "           5       0.84      0.81      0.83      1064\n",
      "           6       0.76      0.61      0.68      1064\n",
      "           7       0.99      0.98      0.98      1064\n",
      "           8       1.00      0.99      1.00      1064\n",
      "           9       0.83      0.77      0.80      1064\n",
      "          10       0.93      0.91      0.92      1064\n",
      "\n",
      "   micro avg       0.90      0.84      0.87     11702\n",
      "   macro avg       0.90      0.84      0.87     11702\n",
      "weighted avg       0.90      0.84      0.87     11702\n",
      " samples avg       0.82      0.84      0.83     11702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13327/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss is 0.3162340976591865\n",
      "Epoch 19 loss is 0.23035400757661567\n",
      "Epoch 29 loss is 0.3025872000844228\n",
      "Epoch 39 loss is 0.5825874736764202\n",
      "Epoch 49 loss is 0.5903150798951642\n",
      "Epoch 59 loss is 0.5290111967616761\n",
      "Epoch 69 loss is 0.48948755510049063\n",
      "Epoch 79 loss is 0.5536584861929144\n",
      "Epoch 89 loss is 0.5714292967837328\n",
      "Epoch 99 loss is 0.6023988021147385\n",
      "Epoch 109 loss is 0.6004173386515079\n",
      "Epoch 119 loss is 0.5901975806362378\n",
      "Epoch 129 loss is 0.607343459187801\n",
      "Epoch 139 loss is 0.6290455412143036\n",
      "Epoch 149 loss is 0.598815193614319\n",
      "Epoch 159 loss is 0.5928518543280813\n",
      "Epoch 169 loss is 0.6891633674581874\n",
      "Epoch 179 loss is 0.6508888532882792\n",
      "Epoch 189 loss is 0.6662645081833795\n",
      "Epoch 199 loss is 0.6955834762648595\n",
      "Train Acc.:  0.7916550943234987\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      1064\n",
      "           1       0.78      0.69      0.73      1064\n",
      "           2       0.89      0.81      0.85      1064\n",
      "           3       0.94      0.87      0.91      1064\n",
      "           4       0.95      0.89      0.92      1064\n",
      "           5       0.82      0.78      0.80      1064\n",
      "           6       0.77      0.78      0.78      1063\n",
      "           7       0.99      0.98      0.98      1064\n",
      "           8       1.00      0.98      0.99      1063\n",
      "           9       0.78      0.75      0.77      1064\n",
      "          10       0.93      0.82      0.87      1064\n",
      "\n",
      "   micro avg       0.89      0.84      0.87     11702\n",
      "   macro avg       0.89      0.84      0.87     11702\n",
      "weighted avg       0.89      0.84      0.87     11702\n",
      " samples avg       0.82      0.84      0.82     11702\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "list_losses = []\n",
    "list_scores = []\n",
    "list_acc = []\n",
    "list_loss = []\n",
    "list_f1 = []\n",
    "list_precision = []\n",
    "list_recall = []\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    model_dict: dict = {}\n",
    "    x_train, x_valid, y_train, y_valid = get_splitted_data_by_index(\n",
    "        X, y, neuronCats, train_index, test_index\n",
    "    )\n",
    "\n",
    "    model = Model(categories=categories, periodicity=periodicity)\n",
    "    criterion = ComplexMSE_adjusted_error.apply\n",
    "    optimizer = ECL(model.parameters(), lr=lr)\n",
    "\n",
    "    losses, scores = fit(\n",
    "        model,\n",
    "        x_train,\n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        categories=categories,\n",
    "        periodicity=periodicity,\n",
    "    )\n",
    "\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "    list_scores.append(scores)\n",
    "    list_losses.append(losses)\n",
    "\n",
    "    y_pred = model.predict(x_train)\n",
    "    acc = accuracy(y_pred.squeeze(), y_train)\n",
    "    print(\"Train Acc.: \", acc)\n",
    "\n",
    "    y_pred = model.predict(x_valid)\n",
    "    acc = accuracy(y_pred.squeeze(), y_valid)\n",
    "    list_acc.append(acc)\n",
    "\n",
    "    print(classification_report(y_valid, y_pred.detach().numpy(), zero_division=0))\n",
    "    list_f1.append(\n",
    "        f1_score(y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0)\n",
    "    )\n",
    "    list_precision.append(\n",
    "        precision_score(\n",
    "            y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0\n",
    "        )\n",
    "    )\n",
    "    list_recall.append(\n",
    "        recall_score(\n",
    "            y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0\n",
    "        )\n",
    "    )\n",
    "\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_accuracy_mean\",\n",
    "    value=np.mean(list_acc),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_accuracy_std\",\n",
    "    value=np.std(list_acc),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_f1_mean\",\n",
    "    value=np.mean(list_f1),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_f1_std\",\n",
    "    value=np.std(list_f1),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_precision_mean\",\n",
    "    value=np.mean(list_precision),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_precision_std\",\n",
    "    value=np.std(list_precision),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_recall_mean\",\n",
    "    value=np.mean(list_recall),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_recall_std\",\n",
    "    value=np.std(list_recall),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "task.mark_completed()\n",
    "task.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLMVN [48-50-50-11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "PATH = str(Path.cwd() / \"models/autass-mlmvn_48-50-50-11.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, categories, periodicity):\n",
    "        super().__init__()\n",
    "        self.categories = categories\n",
    "        self.periodicity = periodicity\n",
    "        self.first_linear = FirstLayer(48, 50)\n",
    "        self.phase_act1 = cmplx_phase_activation()\n",
    "        self.hidden_layer = HiddenLayer(50, 50)\n",
    "        self.phase_act2 = cmplx_phase_activation()\n",
    "        self.linear_out = OutputLayer(50, 11)\n",
    "        self.phase_act3 = cmplx_phase_activation()\n",
    "        # Hooks\n",
    "        self.first_layer_hook_handle = self.first_linear.register_full_backward_hook(\n",
    "            self.first_layer_backward_hook\n",
    "        )\n",
    "        self.hidden_layer_hook_handle = self.hidden_layer.register_full_backward_hook(\n",
    "            self.hidden_layer_backward_hook\n",
    "        )\n",
    "        self.output_hook_handle = self.linear_out.register_full_backward_hook(\n",
    "            self.output_layer_backward_hook\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first_linear(x)\n",
    "        x = self.phase_act1(x)\n",
    "        x = self.hidden_layer(x)\n",
    "        x = self.phase_act2(x)\n",
    "        x = self.linear_out(x)\n",
    "        x = self.phase_act3(x)\n",
    "        return x\n",
    "\n",
    "    def first_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"first_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def hidden_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"hidden_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def output_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"output_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def angle2class(self, x: torch.tensor) -> torch.tensor:\n",
    "        tmp = x.angle() + 2 * np.pi\n",
    "        angle = torch.remainder(tmp, 2 * np.pi)\n",
    "\n",
    "        # This will be the discrete output (the number of sector)\n",
    "        o = torch.floor(self.categories * self.periodicity * angle / (2 * np.pi))\n",
    "        return torch.remainder(o, self.categories)\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Performs the prediction task of the network\n",
    "\n",
    "        Args:\n",
    "          x: torch.Tensor\n",
    "            Input tensor of size ([3])\n",
    "\n",
    "        Returns:\n",
    "          Most likely class i.e., Label with the highest score\n",
    "        \"\"\"\n",
    "        # Pass the data through the networks\n",
    "        output = self.forward(x)\n",
    "\n",
    "        # # Choose the label with the highest score\n",
    "        # return torch.argmax(output, 1)\n",
    "        return self.angle2class(output)\n",
    "\n",
    "\n",
    "def fit(model, X, y, epochs, batch_size, optimizer, criterion, categories, periodicity):\n",
    "    # List of losses for visualization\n",
    "    losses = []\n",
    "    scores = []\n",
    "    acc_best = 0\n",
    "\n",
    "    for i in range(epochs):\n",
    "        # Pass the data through the network and compute the loss\n",
    "        # We'll use the whole dataset during the training instead of using batches\n",
    "        # in to order to keep the code simple for now.\n",
    "\n",
    "        batch_loss = []\n",
    "\n",
    "        for j in range((X.shape[0] - 1) // batch_size + 1):\n",
    "            start_j = j * batch_size\n",
    "            end_j = start_j + batch_size\n",
    "            xb = X[start_j:end_j]\n",
    "            yb = y[start_j:end_j]\n",
    "\n",
    "            y_pred = model(xb)\n",
    "            loss = criterion(y_pred, yb, categories, periodicity)\n",
    "            batch_loss.append((torch.abs(loss)).detach().numpy())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step(inputs=xb, layers=list(model.children()))\n",
    "\n",
    "        losses.append(sum(batch_loss) / len(batch_loss))\n",
    "        if i % 10 == 9:\n",
    "            print(f\"Epoch {i} loss is {losses[-1]}\")\n",
    "        y_pred = model.predict(X)\n",
    "        scores.append(accuracy(y_pred.squeeze(), y))\n",
    "\n",
    "        if scores[-1] > acc_best:\n",
    "            acc_best = scores[-1]\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "    return losses, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=fad0aa6b39774a1a941093cdfe9dbafe\n",
      "ClearML results page: http://194.94.231.172:8080/projects/cdefd6ee85454e49be01962ad715eca0/experiments/fad0aa6b39774a1a941093cdfe9dbafe/output/log\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 1,\n",
       " 'epochs': 200,\n",
       " 'batch_size': 538,\n",
       " 'optim': 'ECL',\n",
       " 'categories': 2,\n",
       " 'periodicity': 1,\n",
       " 'layer': '[48-50-50-11]',\n",
       " 'loss': 'ComplexMSE_adjusted_error',\n",
       " 'clip_angle_value': 1000000}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = Task.init(\n",
    "    project_name=\"mlmvn\",\n",
    "    task_name=\"SDD-mlmvn-[48-50-50-11]\",\n",
    "    tags=[\"mlmvn\", \"SDD\", \"multiple_runs\", \"adjusted_loss_clip_angle_value\"],\n",
    ")\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# â€ƒcapture a dictionary of hyperparameters with config\n",
    "config_dict = {\n",
    "    \"learning_rate\": 1,\n",
    "    \"epochs\": epochs,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"optim\": \"ECL\",\n",
    "    \"categories\": categories,\n",
    "    \"periodicity\": periodicity,\n",
    "    \"layer\": \"[48-50-50-11]\",\n",
    "    \"loss\": \"ComplexMSE_adjusted_error\",\n",
    "    \"clip_angle_value\": clip_angle_value,\n",
    "}\n",
    "task.connect(config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13327/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-28 01:32:30,550 - clearml.frameworks - INFO - Found existing registered model id=f13061c5d03a4e96b788becd5e54443a [/home/antonpfeifer/Documents/mlmvn/nbs/examples/autass/models/autass-mlmvn_48-50-50-11.pt] reusing it.\n",
      "Epoch 9 loss is 0.28872390806294274\n",
      "Epoch 19 loss is 0.17694585572096805\n",
      "Epoch 29 loss is 0.1425961563405807\n",
      "Epoch 39 loss is 0.12819857234772986\n",
      "Epoch 49 loss is 0.127805551287352\n",
      "Epoch 59 loss is 0.11392432030870624\n",
      "Epoch 69 loss is 0.09727040211071439\n",
      "Epoch 79 loss is 0.09686726724688864\n",
      "Epoch 89 loss is 0.09030257402693799\n",
      "Epoch 99 loss is 0.09027066309985042\n",
      "Epoch 109 loss is 0.08883324592656906\n",
      "Epoch 119 loss is 0.08907481171375083\n",
      "Epoch 129 loss is 0.08302457843559832\n",
      "Epoch 139 loss is 0.07895430465486417\n",
      "Epoch 149 loss is 0.07612614811554756\n",
      "Epoch 159 loss is 0.0712898657302396\n",
      "Epoch 169 loss is 0.08380639698034706\n",
      "Epoch 179 loss is 0.07950043128200916\n",
      "Epoch 189 loss is 0.08736764655981065\n",
      "Epoch 199 loss is 0.09124728414202767\n",
      "Train Acc.:  0.9411199179609887\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97      1063\n",
      "           1       0.93      0.91      0.92      1064\n",
      "           2       0.99      0.98      0.98      1064\n",
      "           3       0.97      0.97      0.97      1064\n",
      "           4       0.94      0.92      0.93      1064\n",
      "           5       0.93      0.94      0.93      1063\n",
      "           6       0.90      0.91      0.91      1064\n",
      "           7       1.00      0.99      0.99      1064\n",
      "           8       1.00      1.00      1.00      1064\n",
      "           9       0.96      0.93      0.94      1064\n",
      "          10       0.99      0.97      0.98      1064\n",
      "\n",
      "   micro avg       0.96      0.95      0.96     11702\n",
      "   macro avg       0.96      0.95      0.96     11702\n",
      "weighted avg       0.96      0.95      0.96     11702\n",
      " samples avg       0.94      0.95      0.95     11702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13327/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss is 0.2861673749427943\n",
      "Epoch 19 loss is 0.2201654650800628\n",
      "Epoch 29 loss is 0.1594589809702913\n",
      "Epoch 39 loss is 0.13540895566103234\n",
      "Epoch 49 loss is 0.11925421445742292\n",
      "Epoch 59 loss is 0.11962160650088925\n",
      "Epoch 69 loss is 0.11841529734011198\n",
      "Epoch 79 loss is 0.1179027595753925\n",
      "Epoch 89 loss is 0.1180392008192653\n",
      "Epoch 99 loss is 0.11441886133599923\n",
      "Epoch 109 loss is 0.10782047828315887\n",
      "Epoch 119 loss is 0.10705718301534183\n",
      "Epoch 129 loss is 0.10427072867703205\n",
      "Epoch 139 loss is 0.10474216368094652\n",
      "Epoch 149 loss is 0.10551091888301718\n",
      "Epoch 159 loss is 0.10684330984217699\n",
      "Epoch 169 loss is 0.09317834493277641\n",
      "Epoch 179 loss is 0.0892558164282839\n",
      "Epoch 189 loss is 0.08739703451707423\n",
      "Epoch 199 loss is 0.09199028421820245\n",
      "Train Acc.:  0.9275749353729144\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96      1063\n",
      "           1       0.92      0.88      0.90      1064\n",
      "           2       0.98      0.98      0.98      1064\n",
      "           3       0.97      0.95      0.96      1063\n",
      "           4       0.94      0.92      0.93      1064\n",
      "           5       0.93      0.95      0.94      1064\n",
      "           6       0.89      0.89      0.89      1064\n",
      "           7       0.99      1.00      1.00      1064\n",
      "           8       1.00      1.00      1.00      1064\n",
      "           9       0.95      0.93      0.94      1064\n",
      "          10       0.96      0.91      0.93      1064\n",
      "\n",
      "   micro avg       0.96      0.94      0.95     11702\n",
      "   macro avg       0.96      0.94      0.95     11702\n",
      "weighted avg       0.96      0.94      0.95     11702\n",
      " samples avg       0.93      0.94      0.93     11702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13327/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss is 0.27623336473650534\n",
      "Epoch 19 loss is 0.16289381252737087\n",
      "Epoch 29 loss is 0.14757027886946592\n",
      "Epoch 39 loss is 0.1330734318315473\n",
      "Epoch 49 loss is 0.11679790998549922\n",
      "Epoch 59 loss is 0.11167467752516336\n",
      "Epoch 69 loss is 0.11268039833791481\n",
      "Epoch 79 loss is 0.10041605954925376\n",
      "Epoch 89 loss is 0.10264455966541974\n",
      "Epoch 99 loss is 0.10157209891611255\n",
      "Epoch 109 loss is 0.09768154280892237\n",
      "Epoch 119 loss is 0.09983357506318141\n",
      "Epoch 129 loss is 0.09887546788082555\n",
      "Epoch 139 loss is 0.0888411840117014\n",
      "Epoch 149 loss is 0.10038184391363476\n",
      "Epoch 159 loss is 0.08949124574344279\n",
      "Epoch 169 loss is 0.09784304006405145\n",
      "Epoch 179 loss is 0.09877557601509657\n",
      "Epoch 189 loss is 0.10217435454327402\n",
      "Epoch 199 loss is 0.1057261382783362\n",
      "Train Acc.:  0.9322750870596278\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      1064\n",
      "           1       0.91      0.91      0.91      1064\n",
      "           2       0.98      0.96      0.97      1064\n",
      "           3       0.97      0.96      0.96      1063\n",
      "           4       0.91      0.91      0.91      1064\n",
      "           5       0.93      0.93      0.93      1064\n",
      "           6       0.91      0.88      0.89      1063\n",
      "           7       1.00      0.99      1.00      1064\n",
      "           8       1.00      1.00      1.00      1064\n",
      "           9       0.95      0.94      0.94      1064\n",
      "          10       0.98      0.95      0.97      1064\n",
      "\n",
      "   micro avg       0.95      0.94      0.95     11702\n",
      "   macro avg       0.95      0.94      0.95     11702\n",
      "weighted avg       0.95      0.94      0.95     11702\n",
      " samples avg       0.93      0.94      0.93     11702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13327/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss is 0.28693840838047774\n",
      "Epoch 19 loss is 0.20104936966743658\n",
      "Epoch 29 loss is 0.15755177961335037\n",
      "Epoch 39 loss is 0.1288596346987444\n",
      "Epoch 49 loss is 0.12720331433512763\n",
      "Epoch 59 loss is 0.12023218874962663\n",
      "Epoch 69 loss is 0.11721781830240018\n",
      "Epoch 79 loss is 0.10656089263296499\n",
      "Epoch 89 loss is 0.09562316810246828\n",
      "Epoch 99 loss is 0.09102231637919944\n",
      "Epoch 109 loss is 0.09233467007446912\n",
      "Epoch 119 loss is 0.09115643363442122\n",
      "Epoch 129 loss is 0.08620270800916764\n",
      "Epoch 139 loss is 0.11083394580512573\n",
      "Epoch 149 loss is 0.10150878655964381\n",
      "Epoch 159 loss is 0.10271093352938551\n",
      "Epoch 169 loss is 0.10444855459263125\n",
      "Epoch 179 loss is 0.09594796640621853\n",
      "Epoch 189 loss is 0.09849182497560287\n",
      "Epoch 199 loss is 0.1036780848914241\n",
      "Train Acc.:  0.924904394641827\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97      1063\n",
      "           1       0.91      0.88      0.89      1064\n",
      "           2       0.98      0.96      0.97      1064\n",
      "           3       0.96      0.97      0.97      1063\n",
      "           4       0.91      0.90      0.91      1064\n",
      "           5       0.91      0.91      0.91      1064\n",
      "           6       0.89      0.89      0.89      1064\n",
      "           7       1.00      0.99      0.99      1064\n",
      "           8       1.00      1.00      1.00      1064\n",
      "           9       0.94      0.93      0.93      1064\n",
      "          10       0.97      0.95      0.96      1064\n",
      "\n",
      "   micro avg       0.95      0.94      0.95     11702\n",
      "   macro avg       0.95      0.94      0.95     11702\n",
      "weighted avg       0.95      0.94      0.95     11702\n",
      " samples avg       0.93      0.94      0.93     11702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13327/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss is 0.3034027193057795\n",
      "Epoch 19 loss is 0.17692890093552524\n",
      "Epoch 29 loss is 0.13786514238212272\n",
      "Epoch 39 loss is 0.12331394422598127\n",
      "Epoch 49 loss is 0.1237987767889628\n",
      "Epoch 59 loss is 0.11048595570606672\n",
      "Epoch 69 loss is 0.09570147391418123\n",
      "Epoch 79 loss is 0.09912258426639196\n",
      "Epoch 89 loss is 0.09599648621108799\n",
      "Epoch 99 loss is 0.0873050642910436\n",
      "Epoch 109 loss is 0.10142020273437256\n",
      "Epoch 119 loss is 0.1003337232560557\n",
      "Epoch 129 loss is 0.10045847144167147\n",
      "Epoch 139 loss is 0.09709811021654463\n",
      "Epoch 149 loss is 0.0970311573500608\n",
      "Epoch 159 loss is 0.09226866990186595\n",
      "Epoch 169 loss is 0.08758580671534028\n",
      "Epoch 179 loss is 0.08792805539701785\n",
      "Epoch 189 loss is 0.08792941901672958\n",
      "Epoch 199 loss is 0.09815684767604878\n",
      "Train Acc.:  0.9300959258230607\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97      1064\n",
      "           1       0.91      0.90      0.91      1064\n",
      "           2       0.98      0.97      0.97      1064\n",
      "           3       0.98      0.95      0.97      1064\n",
      "           4       0.94      0.93      0.93      1064\n",
      "           5       0.93      0.93      0.93      1064\n",
      "           6       0.90      0.88      0.89      1063\n",
      "           7       1.00      0.99      1.00      1064\n",
      "           8       1.00      1.00      1.00      1063\n",
      "           9       0.93      0.89      0.91      1064\n",
      "          10       0.97      0.95      0.96      1064\n",
      "\n",
      "   micro avg       0.96      0.94      0.95     11702\n",
      "   macro avg       0.96      0.94      0.95     11702\n",
      "weighted avg       0.96      0.94      0.95     11702\n",
      " samples avg       0.93      0.94      0.93     11702\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "list_losses = []\n",
    "list_scores = []\n",
    "list_acc = []\n",
    "list_loss = []\n",
    "list_f1 = []\n",
    "list_precision = []\n",
    "list_recall = []\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    model_dict: dict = {}\n",
    "    x_train, x_valid, y_train, y_valid = get_splitted_data_by_index(\n",
    "        X, y, neuronCats, train_index, test_index\n",
    "    )\n",
    "\n",
    "    model = Model(categories=categories, periodicity=periodicity)\n",
    "    criterion = ComplexMSE_adjusted_error.apply\n",
    "    optimizer = ECL(model.parameters(), lr=lr)\n",
    "\n",
    "    losses, scores = fit(\n",
    "        model,\n",
    "        x_train,\n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        categories=categories,\n",
    "        periodicity=periodicity,\n",
    "    )\n",
    "\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "    list_scores.append(scores)\n",
    "    list_losses.append(losses)\n",
    "\n",
    "    y_pred = model.predict(x_train)\n",
    "    acc = accuracy(y_pred.squeeze(), y_train)\n",
    "    print(\"Train Acc.: \", acc)\n",
    "\n",
    "    y_pred = model.predict(x_valid)\n",
    "    acc = accuracy(y_pred.squeeze(), y_valid)\n",
    "    list_acc.append(acc)\n",
    "\n",
    "    print(classification_report(y_valid, y_pred.detach().numpy(), zero_division=0))\n",
    "    list_f1.append(\n",
    "        f1_score(y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0)\n",
    "    )\n",
    "    list_precision.append(\n",
    "        precision_score(\n",
    "            y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0\n",
    "        )\n",
    "    )\n",
    "    list_recall.append(\n",
    "        recall_score(\n",
    "            y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0\n",
    "        )\n",
    "    )\n",
    "\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_accuracy_mean\",\n",
    "    value=np.mean(list_acc),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_accuracy_std\",\n",
    "    value=np.std(list_acc),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_f1_mean\",\n",
    "    value=np.mean(list_f1),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_f1_std\",\n",
    "    value=np.std(list_f1),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_precision_mean\",\n",
    "    value=np.mean(list_precision),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_precision_std\",\n",
    "    value=np.std(list_precision),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_recall_mean\",\n",
    "    value=np.mean(list_recall),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_recall_std\",\n",
    "    value=np.std(list_recall),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "task.mark_completed()\n",
    "task.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLMVN [48-100-100-11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "PATH = str(Path.cwd() / \"models/autass-mlmvn_48-100-100-11.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, categories, periodicity):\n",
    "        super().__init__()\n",
    "        self.categories = categories\n",
    "        self.periodicity = periodicity\n",
    "        self.first_linear = FirstLayer(48, 100)\n",
    "        self.phase_act1 = cmplx_phase_activation()\n",
    "        self.hidden_layer = HiddenLayer(100, 100)\n",
    "        self.phase_act2 = cmplx_phase_activation()\n",
    "        self.linear_out = OutputLayer(100, 11)\n",
    "        self.phase_act3 = cmplx_phase_activation()\n",
    "        # Hooks\n",
    "        self.first_layer_hook_handle = self.first_linear.register_full_backward_hook(\n",
    "            self.first_layer_backward_hook\n",
    "        )\n",
    "        self.hidden_layer_hook_handle = self.hidden_layer.register_full_backward_hook(\n",
    "            self.hidden_layer_backward_hook\n",
    "        )\n",
    "        self.output_hook_handle = self.linear_out.register_full_backward_hook(\n",
    "            self.output_layer_backward_hook\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first_linear(x)\n",
    "        x = self.phase_act1(x)\n",
    "        x = self.hidden_layer(x)\n",
    "        x = self.phase_act2(x)\n",
    "        x = self.linear_out(x)\n",
    "        x = self.phase_act3(x)\n",
    "        return x\n",
    "\n",
    "    def first_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"first_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def hidden_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"hidden_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def output_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"output_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def angle2class(self, x: torch.tensor) -> torch.tensor:\n",
    "        tmp = x.angle() + 2 * np.pi\n",
    "        angle = torch.remainder(tmp, 2 * np.pi)\n",
    "\n",
    "        # This will be the discrete output (the number of sector)\n",
    "        o = torch.floor(self.categories * self.periodicity * angle / (2 * np.pi))\n",
    "        return torch.remainder(o, self.categories)\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Performs the prediction task of the network\n",
    "\n",
    "        Args:\n",
    "          x: torch.Tensor\n",
    "            Input tensor of size ([3])\n",
    "\n",
    "        Returns:\n",
    "          Most likely class i.e., Label with the highest score\n",
    "        \"\"\"\n",
    "        # Pass the data through the networks\n",
    "        output = self.forward(x)\n",
    "\n",
    "        # # Choose the label with the highest score\n",
    "        # return torch.argmax(output, 1)\n",
    "        return self.angle2class(output)\n",
    "\n",
    "\n",
    "def fit(model, X, y, epochs, batch_size, optimizer, criterion, categories, periodicity):\n",
    "    # List of losses for visualization\n",
    "    losses = []\n",
    "    scores = []\n",
    "    acc_best = 0\n",
    "\n",
    "    for i in range(epochs):\n",
    "        # Pass the data through the network and compute the loss\n",
    "        # We'll use the whole dataset during the training instead of using batches\n",
    "        # in to order to keep the code simple for now.\n",
    "\n",
    "        batch_loss = []\n",
    "\n",
    "        for j in range((X.shape[0] - 1) // batch_size + 1):\n",
    "            start_j = j * batch_size\n",
    "            end_j = start_j + batch_size\n",
    "            xb = X[start_j:end_j]\n",
    "            yb = y[start_j:end_j]\n",
    "\n",
    "            y_pred = model(xb)\n",
    "            loss = criterion(y_pred, yb, categories, periodicity)\n",
    "            batch_loss.append((torch.abs(loss)).detach().numpy())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step(inputs=xb, layers=list(model.children()))\n",
    "\n",
    "        losses.append(sum(batch_loss) / len(batch_loss))\n",
    "        if i % 10 == 9:\n",
    "            print(f\"Epoch {i} loss is {losses[-1]}\")\n",
    "        y_pred = model.predict(X)\n",
    "        scores.append(accuracy(y_pred.squeeze(), y))\n",
    "\n",
    "        if scores[-1] > acc_best:\n",
    "            acc_best = scores[-1]\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "    return losses, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=db0d87c02ed04e38adf49b0bfd539c5d\n",
      "ClearML results page: http://194.94.231.172:8080/projects/cdefd6ee85454e49be01962ad715eca0/experiments/db0d87c02ed04e38adf49b0bfd539c5d/output/log\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 1,\n",
       " 'epochs': 200,\n",
       " 'batch_size': 538,\n",
       " 'optim': 'ECL',\n",
       " 'categories': 2,\n",
       " 'periodicity': 1,\n",
       " 'layer': '[48-100-100-11]',\n",
       " 'loss': 'ComplexMSE_adjusted_error',\n",
       " 'clip_angle_value': 1000000}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = Task.init(\n",
    "    project_name=\"mlmvn\",\n",
    "    task_name=\"SDD-mlmvn-[48-100-100-11]\",\n",
    "    tags=[\"mlmvn\", \"SDD\", \"multiple_runs\", \"adjusted_loss_clip_angle_value\"],\n",
    ")\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# â€ƒcapture a dictionary of hyperparameters with config\n",
    "config_dict = {\n",
    "    \"learning_rate\": lr,\n",
    "    \"epochs\": epochs,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"optim\": \"ECL\",\n",
    "    \"categories\": categories,\n",
    "    \"periodicity\": periodicity,\n",
    "    \"layer\": \"[48-100-100-11]\",\n",
    "    \"loss\": \"ComplexMSE_adjusted_error\",\n",
    "    \"clip_angle_value\": clip_angle_value,\n",
    "}\n",
    "task.connect(config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13327/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-28 02:06:32,474 - clearml.frameworks - INFO - Found existing registered model id=bbd65d869dea4025af46d264d3c7bdee [/home/antonpfeifer/Documents/mlmvn/nbs/examples/autass/models/autass-mlmvn_48-100-100-11.pt] reusing it.\n",
      "Epoch 9 loss is 0.38493101436237465\n",
      "Epoch 19 loss is 0.1983475963903122\n",
      "Epoch 29 loss is 0.15240658259145864\n",
      "Epoch 39 loss is 0.12849809119734149\n",
      "Epoch 49 loss is 0.11291338514495056\n",
      "Epoch 59 loss is 0.10350603182093213\n",
      "Epoch 69 loss is 0.09896006818913682\n",
      "Epoch 79 loss is 0.09073580641413742\n",
      "Epoch 89 loss is 0.08624265189956253\n",
      "Epoch 99 loss is 0.07990884906610474\n",
      "Epoch 109 loss is 0.07774202154480073\n",
      "Epoch 119 loss is 0.0778207451859103\n",
      "Epoch 129 loss is 0.07292320971236593\n",
      "Epoch 139 loss is 0.08220096647261978\n",
      "Epoch 149 loss is 0.07259278084390995\n",
      "Epoch 159 loss is 0.07333743296400583\n",
      "Epoch 169 loss is 0.06768991486550634\n",
      "Epoch 179 loss is 0.06486413256485078\n",
      "Epoch 189 loss is 0.0663716789708822\n",
      "Epoch 199 loss is 0.06601747100440022\n",
      "Train Acc.:  0.9551562800435832\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      1063\n",
      "           1       0.93      0.92      0.93      1064\n",
      "           2       0.99      0.98      0.98      1064\n",
      "           3       0.99      0.98      0.98      1064\n",
      "           4       0.95      0.92      0.93      1064\n",
      "           5       0.94      0.94      0.94      1063\n",
      "           6       0.92      0.91      0.92      1064\n",
      "           7       1.00      1.00      1.00      1064\n",
      "           8       1.00      1.00      1.00      1064\n",
      "           9       0.94      0.92      0.93      1064\n",
      "          10       0.96      0.96      0.96      1064\n",
      "\n",
      "   micro avg       0.96      0.95      0.96     11702\n",
      "   macro avg       0.96      0.95      0.96     11702\n",
      "weighted avg       0.96      0.95      0.96     11702\n",
      " samples avg       0.94      0.95      0.95     11702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13327/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss is 0.4015647773116825\n",
      "Epoch 19 loss is 0.21324193953061343\n",
      "Epoch 29 loss is 0.16244134629623966\n",
      "Epoch 39 loss is 0.13968662879021496\n",
      "Epoch 49 loss is 0.1220346592068794\n",
      "Epoch 59 loss is 0.11857350072574051\n",
      "Epoch 69 loss is 0.10683356304935711\n",
      "Epoch 79 loss is 0.09876512760527531\n",
      "Epoch 89 loss is 0.10028214707730271\n",
      "Epoch 99 loss is 0.09386611501220359\n",
      "Epoch 109 loss is 0.09131180958378789\n",
      "Epoch 119 loss is 0.08078602213530815\n",
      "Epoch 129 loss is 0.07812674516622654\n",
      "Epoch 139 loss is 0.07368491314841398\n",
      "Epoch 149 loss is 0.07233171681695082\n",
      "Epoch 159 loss is 0.07153585909897314\n",
      "Epoch 169 loss is 0.07045204344853243\n",
      "Epoch 179 loss is 0.07031483192734578\n",
      "Epoch 189 loss is 0.06762652182875349\n",
      "Epoch 199 loss is 0.06935222633418742\n",
      "Train Acc.:  0.9489606255474609\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97      1063\n",
      "           1       0.94      0.90      0.92      1064\n",
      "           2       0.98      0.97      0.97      1064\n",
      "           3       0.98      0.97      0.97      1063\n",
      "           4       0.95      0.94      0.94      1064\n",
      "           5       0.94      0.93      0.93      1064\n",
      "           6       0.91      0.89      0.90      1064\n",
      "           7       1.00      1.00      1.00      1064\n",
      "           8       1.00      0.99      1.00      1064\n",
      "           9       0.96      0.94      0.95      1064\n",
      "          10       0.98      0.95      0.97      1064\n",
      "\n",
      "   micro avg       0.96      0.95      0.96     11702\n",
      "   macro avg       0.96      0.95      0.96     11702\n",
      "weighted avg       0.96      0.95      0.96     11702\n",
      " samples avg       0.94      0.95      0.94     11702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13327/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss is 0.35830112541567166\n",
      "Epoch 19 loss is 0.20503370425712947\n",
      "Epoch 29 loss is 0.1615004405052233\n",
      "Epoch 39 loss is 0.14478501770353844\n",
      "Epoch 49 loss is 0.13139543735043546\n",
      "Epoch 59 loss is 0.12132454251093122\n",
      "Epoch 69 loss is 0.11744575716216751\n",
      "Epoch 79 loss is 0.11623840924937114\n",
      "Epoch 89 loss is 0.11783017747510419\n",
      "Epoch 99 loss is 0.11593023945022461\n",
      "Epoch 109 loss is 0.11583587087231882\n",
      "Epoch 119 loss is 0.11662312303478367\n",
      "Epoch 129 loss is 0.11691969687131881\n",
      "Epoch 139 loss is 0.10854572296958728\n",
      "Epoch 149 loss is 0.10796596240824434\n",
      "Epoch 159 loss is 0.11262345830304454\n",
      "Epoch 169 loss is 0.10184479776708627\n",
      "Epoch 179 loss is 0.09605088202087457\n",
      "Epoch 189 loss is 0.09299509987805853\n",
      "Epoch 199 loss is 0.08898415836437445\n",
      "Train Acc.:  0.9210374516632127\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      1064\n",
      "           1       0.91      0.89      0.90      1064\n",
      "           2       0.98      0.95      0.97      1064\n",
      "           3       0.96      0.94      0.95      1063\n",
      "           4       0.92      0.88      0.90      1064\n",
      "           5       0.90      0.90      0.90      1064\n",
      "           6       0.89      0.88      0.89      1063\n",
      "           7       1.00      0.99      0.99      1064\n",
      "           8       1.00      0.99      1.00      1064\n",
      "           9       0.93      0.88      0.90      1064\n",
      "          10       0.97      0.95      0.96      1064\n",
      "\n",
      "   micro avg       0.95      0.93      0.94     11702\n",
      "   macro avg       0.95      0.93      0.94     11702\n",
      "weighted avg       0.95      0.93      0.94     11702\n",
      " samples avg       0.91      0.93      0.92     11702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13327/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss is 0.3732331507452995\n",
      "Epoch 19 loss is 0.2151142782886408\n",
      "Epoch 29 loss is 0.1693622907950432\n",
      "Epoch 39 loss is 0.14709019657419897\n",
      "Epoch 49 loss is 0.13360652890401162\n",
      "Epoch 59 loss is 0.12738859159159088\n",
      "Epoch 69 loss is 0.11634673967810212\n",
      "Epoch 79 loss is 0.10559853905524143\n",
      "Epoch 89 loss is 0.10185721106569144\n",
      "Epoch 99 loss is 0.10076346263612189\n",
      "Epoch 109 loss is 0.0951012106512096\n",
      "Epoch 119 loss is 0.0863301443776767\n",
      "Epoch 129 loss is 0.08374395534767522\n",
      "Epoch 139 loss is 0.08192660695129174\n",
      "Epoch 149 loss is 0.0808713694226275\n",
      "Epoch 159 loss is 0.08485596063007796\n",
      "Epoch 169 loss is 0.07577642509867422\n",
      "Epoch 179 loss is 0.07399703079870644\n",
      "Epoch 189 loss is 0.07316694645295278\n",
      "Epoch 199 loss is 0.07004600393121947\n",
      "Train Acc.:  0.9438972803213195\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98      1063\n",
      "           1       0.93      0.91      0.92      1064\n",
      "           2       0.98      0.96      0.97      1064\n",
      "           3       0.97      0.97      0.97      1063\n",
      "           4       0.94      0.92      0.93      1064\n",
      "           5       0.93      0.92      0.93      1064\n",
      "           6       0.90      0.89      0.89      1064\n",
      "           7       1.00      1.00      1.00      1064\n",
      "           8       1.00      1.00      1.00      1064\n",
      "           9       0.93      0.90      0.92      1064\n",
      "          10       0.96      0.95      0.96      1064\n",
      "\n",
      "   micro avg       0.96      0.95      0.95     11702\n",
      "   macro avg       0.96      0.95      0.95     11702\n",
      "weighted avg       0.96      0.95      0.95     11702\n",
      " samples avg       0.93      0.95      0.94     11702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13327/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss is 0.3860148494765397\n",
      "Epoch 19 loss is 0.20866529165214284\n",
      "Epoch 29 loss is 0.16247025892118347\n",
      "Epoch 39 loss is 0.13564982800723918\n",
      "Epoch 49 loss is 0.1240512973257284\n",
      "Epoch 59 loss is 0.113934101224775\n",
      "Epoch 69 loss is 0.11061596169703837\n",
      "Epoch 79 loss is 0.10461476570112285\n",
      "Epoch 89 loss is 0.10298748909019034\n",
      "Epoch 99 loss is 0.09786684313663066\n",
      "Epoch 109 loss is 0.0988537740332937\n",
      "Epoch 119 loss is 0.09090053269267047\n",
      "Epoch 129 loss is 0.08742530763329877\n",
      "Epoch 139 loss is 0.0841747421040788\n",
      "Epoch 149 loss is 0.08610848018045644\n",
      "Epoch 159 loss is 0.07819941018533352\n",
      "Epoch 169 loss is 0.07596165720615952\n",
      "Epoch 179 loss is 0.07426260096075489\n",
      "Epoch 189 loss is 0.07633927124679218\n",
      "Epoch 199 loss is 0.07405352525764859\n",
      "Train Acc.:  0.9421454056017262\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98      1064\n",
      "           1       0.91      0.90      0.91      1064\n",
      "           2       0.97      0.96      0.96      1064\n",
      "           3       0.97      0.96      0.97      1064\n",
      "           4       0.94      0.92      0.93      1064\n",
      "           5       0.93      0.94      0.94      1064\n",
      "           6       0.91      0.88      0.90      1063\n",
      "           7       1.00      0.99      1.00      1064\n",
      "           8       1.00      1.00      1.00      1063\n",
      "           9       0.93      0.90      0.92      1064\n",
      "          10       0.98      0.95      0.97      1064\n",
      "\n",
      "   micro avg       0.96      0.94      0.95     11702\n",
      "   macro avg       0.96      0.94      0.95     11702\n",
      "weighted avg       0.96      0.94      0.95     11702\n",
      " samples avg       0.93      0.94      0.94     11702\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "list_losses = []\n",
    "list_scores = []\n",
    "list_acc = []\n",
    "list_loss = []\n",
    "list_f1 = []\n",
    "list_precision = []\n",
    "list_recall = []\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    model_dict: dict = {}\n",
    "    x_train, x_valid, y_train, y_valid = get_splitted_data_by_index(\n",
    "        X, y, neuronCats, train_index, test_index\n",
    "    )\n",
    "\n",
    "    model = Model(categories=categories, periodicity=periodicity)\n",
    "    criterion = ComplexMSE_adjusted_error.apply\n",
    "    optimizer = ECL(model.parameters(), lr=lr)\n",
    "\n",
    "    losses, scores = fit(\n",
    "        model,\n",
    "        x_train,\n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        categories=categories,\n",
    "        periodicity=periodicity,\n",
    "    )\n",
    "\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "    list_scores.append(scores)\n",
    "    list_losses.append(losses)\n",
    "\n",
    "    y_pred = model.predict(x_train)\n",
    "    acc = accuracy(y_pred.squeeze(), y_train)\n",
    "    print(\"Train Acc.: \", acc)\n",
    "\n",
    "    y_pred = model.predict(x_valid)\n",
    "    acc = accuracy(y_pred.squeeze(), y_valid)\n",
    "    list_acc.append(acc)\n",
    "\n",
    "    print(classification_report(y_valid, y_pred.detach().numpy(), zero_division=0))\n",
    "    list_f1.append(\n",
    "        f1_score(y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0)\n",
    "    )\n",
    "    list_precision.append(\n",
    "        precision_score(\n",
    "            y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0\n",
    "        )\n",
    "    )\n",
    "    list_recall.append(\n",
    "        recall_score(\n",
    "            y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0\n",
    "        )\n",
    "    )\n",
    "\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_accuracy_mean\",\n",
    "    value=np.mean(list_acc),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_accuracy_std\",\n",
    "    value=np.std(list_acc),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_f1_mean\",\n",
    "    value=np.mean(list_f1),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_f1_std\",\n",
    "    value=np.std(list_f1),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_precision_mean\",\n",
    "    value=np.mean(list_precision),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_precision_std\",\n",
    "    value=np.std(list_precision),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_recall_mean\",\n",
    "    value=np.mean(list_recall),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_recall_std\",\n",
    "    value=np.std(list_recall),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "task.mark_completed()\n",
    "task.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('mlmvn')",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
