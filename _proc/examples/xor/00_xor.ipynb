{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: An example of how to solve the XOR problem with MLMVN.\n",
    "output-file: xor.html\n",
    "title: XOR\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The XOR problem is an example of how a single real-valued neuron cannot learn a simple but non-linear relationship. At least, this holds if we do not extend the dimensionality of the feature space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains four input-output mappings with binary classes. The two-dimensional input $x$ is mapped to a class label $y$. The following table shows the truth table with associated labels for the XOR gate.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\begin{array}{cc|c|cc}\n",
    "        x_1 & x_2 & y & z & arg(z) \\\\\n",
    "        \\hline\n",
    "\t\t1 &  1\t& 0\t&  1+j &  45째 \\\\\n",
    "\t\t1 & -1\t& 1\t&  1-j & 315째 \\\\\n",
    "\t\t-1 &  1\t& 1\t& -1+j & 135째 \\\\\n",
    "\t\t-1 & -1\t& 0\t& -1-j & 225째 \\\\\n",
    "    \\end{array}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "If we consider $x_1$ as $Re(z)$ and $x_2$ as $Im(z)$, the problem can also be expressed graphically into the complex domain. \n",
    "\n",
    "<center>\n",
    "    <img src=\"fig/xor_complex_domain.png\" width=320 />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Create data\n",
    "x = torch.Tensor([[1.0, 1.0], [1.0, -1.0], [-1.0, 1.0], [-1.0, -1.0]])\n",
    "\n",
    "x = x.type(torch.cdouble)\n",
    "\n",
    "y = torch.Tensor([0.0, 1.0, 1.0, 0.0]).reshape(x.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "class BasicModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = FirstLayer(2, 2)\n",
    "        self.phase_act = cmplx_phase_activation()\n",
    "        self.linear1 = OutputLayer(2, 1)\n",
    "        self.phase_act = cmplx_phase_activation()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.phase_act(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "model = BasicModel()\n",
    "criterion = ComplexMSELoss.apply\n",
    "optimizer = ECL(model.parameters(), lr=1)\n",
    "categories = 2\n",
    "periodicity = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.2833, dtype=torch.float64, grad_fn=<AbsBackward0>)\n",
      "1 tensor(1.3938, dtype=torch.float64, grad_fn=<AbsBackward0>)\n",
      "2 tensor(0.3198, dtype=torch.float64, grad_fn=<AbsBackward0>)\n",
      "3 tensor(0.0371, dtype=torch.float64, grad_fn=<AbsBackward0>)\n",
      "4 tensor(0.0036, dtype=torch.float64, grad_fn=<AbsBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for t in range(5):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = model(x)\n",
    "    loss = criterion(y_pred, y, categories, periodicity)\n",
    "    print(t, torch.abs(loss))\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step(inputs=x, layers=list(model.children()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "for idx, param in enumerate(model.parameters()):\n",
    "    param.real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "predictions = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.]], dtype=torch.float64, grad_fn=<RemainderBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def angle2class(x: torch.tensor, categories, periodicity) -> torch.tensor:\n",
    "    tmp = x.angle() + 2 * np.pi\n",
    "    angle = torch.remainder(tmp, 2 * np.pi)\n",
    "\n",
    "    # This will be the discrete output (the number of sector)\n",
    "    o = torch.floor(categories * periodicity * angle / (2 * np.pi))\n",
    "    return torch.remainder(o, categories)\n",
    "\n",
    "\n",
    "angle2class(predictions, 2, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('mlmvn')",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
