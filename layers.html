<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.251">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="Multi-layered feedforward structure with fully connected MVN.">

<title>mlmvn - Layers</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./favicon.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="styles.css">
<meta property="og:title" content="mlmvn - Layers">
<meta property="og:description" content="Multi-layered feedforward structure with fully connected MVN.">
<meta property="og:site-name" content="mlmvn">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">mlmvn</span>
    </a>
  </div>
          <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title">Layers</h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">MLMVN</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./layers.html" class="sidebar-item-text sidebar-link active">Layers</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./loss.html" class="sidebar-item-text sidebar-link">Loss</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./optim.html" class="sidebar-item-text sidebar-link">Optimizer</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Examples</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./examples/xor/xor.html" class="sidebar-item-text sidebar-link">XOR</a>
  </div>
</li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false">Moons</a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./examples/moons/moons.html" class="sidebar-item-text sidebar-link">Building a Binary Classifier</a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="false">SDD</a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="false">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  examples/autass/00_autass.ipynb
  </li>
      </ul>
  </li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#mlmvn" id="toc-mlmvn" class="nav-link active" data-scroll-target="#mlmvn">MLMVN</a>
  <ul>
  <li><a href="#firstlayerfb" id="toc-firstlayerfb" class="nav-link" data-scroll-target="#firstlayerfb">FirstLayerFB</a></li>
  <li><a href="#firstlayer" id="toc-firstlayer" class="nav-link" data-scroll-target="#firstlayer">FirstLayer</a></li>
  <li><a href="#hiddenlayerfb" id="toc-hiddenlayerfb" class="nav-link" data-scroll-target="#hiddenlayerfb">HiddenLayerFB</a></li>
  <li><a href="#hiddenlayer" id="toc-hiddenlayer" class="nav-link" data-scroll-target="#hiddenlayer">HiddenLayer</a></li>
  <li><a href="#outputlayerfb" id="toc-outputlayerfb" class="nav-link" data-scroll-target="#outputlayerfb">OutputLayerFB</a></li>
  <li><a href="#outputlayer" id="toc-outputlayer" class="nav-link" data-scroll-target="#outputlayer">OutputLayer</a></li>
  </ul></li>
  <li><a href="#activation" id="toc-activation" class="nav-link" data-scroll-target="#activation">Activation</a>
  <ul>
  <li><a href="#cmplx_phase_activation" id="toc-cmplx_phase_activation" class="nav-link" data-scroll-target="#cmplx_phase_activation">cmplx_phase_activation</a></li>
  <li><a href="#phase_activation" id="toc-phase_activation" class="nav-link" data-scroll-target="#phase_activation">phase_activation</a></li>
  </ul></li>
  <li><a href="#dropout" id="toc-dropout" class="nav-link" data-scroll-target="#dropout">Dropout</a>
  <ul>
  <li><a href="#mydropout" id="toc-mydropout" class="nav-link" data-scroll-target="#mydropout">MyDropout</a></li>
  <li><a href="#dropoutfb" id="toc-dropoutfb" class="nav-link" data-scroll-target="#dropoutfb">DropoutFB</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/antonpf/mlmvn/issues/new" class="toc-action">Report an issue</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block">Layers</h1>
</div>

<div>
  <div class="description">
    Multi-layered feedforward structure with fully connected MVN.
  </div>
</div>


<div class="quarto-title-meta">

    
    
  </div>
  

</header>

<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->
<p>The multi-layered feedforward structure with fully connected MVN is referred to as MLMVN. Considering a MLMVN structure <span class="math inline">\([n\)</span>-<span class="math inline">\(N_1\)</span>-<span class="math inline">\(\dots\)</span>-<span class="math inline">\(N_{m-1}\)</span>-<span class="math inline">\(N_m ]\)</span> with <span class="math inline">\(n\)</span> inputs in the input layer, <span class="math inline">\(m\)</span>-<span class="math inline">\(1\)</span> hidden layers, and the output layer <span class="math inline">\(m\)</span>. The algorithm is divided into three steps. Before starting the iterative algorithm, the weights are randomly initialized, and the biases are set to zero.</p>
<section id="mlmvn" class="level2">
<h2 class="anchored" data-anchor-id="mlmvn">MLMVN</h2>
<p>The algorithm is divided into three steps. Before starting the iterative algorithm, the weights are randomly initialized, and the biases are set to zero.</p>
<p>For weight adjustment three distinctions are made: the <a href="https://antonpf.github.io/mlmvn/layers.html#firstlayer"><code>FirstLayer</code></a>, <a href="https://antonpf.github.io/mlmvn/layers.html#hiddenlayer"><code>HiddenLayer</code></a> [<span class="math inline">\(2\)</span> to <span class="math inline">\(m-1\)</span>], and the <a href="https://antonpf.github.io/mlmvn/layers.html#outputlayer"><code>OutputLayer</code></a>. Thereby the weights are updated successively from layer <span class="math inline">\(1\)</span> to layer <span class="math inline">\(m\)</span>. The <span class="math inline">\(1st\)</span> hidden Layer is updated by <span class="math display">\[\begin{equation*}
    \tilde{w}_0^{k1} = w_0^{k1} + \frac{C_{k1}}{(n+1) \cdot |z_{k1}|} \cdot \delta_{k1} \,,
\end{equation*}\]</span></p>
<p><span class="math display">\[\begin{equation*}
    \tilde{w}_i^{k1} = w_i^{k1} + \frac{C_{k1}}{(n+1) \cdot |z_{k1}|} \cdot \delta_{k1} \cdot \bar{x}_{i} \,,
\end{equation*}\]</span></p>
<p><span class="math display">\[\begin{equation*}
    i = \{1, \dots, n\} \,.
\end{equation*}\]</span></p>
<hr>
<p><a href="https://github.com/antonpf/mlmvn/blob/main/mlmvn/layers.py#L44" target="_blank" style="float:right; font-size:smaller">source</a></p>
<section id="firstlayerfb" class="level3">
<h3 class="anchored" data-anchor-id="firstlayerfb">FirstLayerFB</h3>
<blockquote class="blockquote">
<pre><code> FirstLayerFB (*args, **kwargs)</code></pre>
</blockquote>
<p>Base class to create custom <code>autograd.Function</code></p>
<hr>
<p><a href="https://github.com/antonpf/mlmvn/blob/main/mlmvn/layers.py#L14" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="firstlayer" class="level3">
<h3 class="anchored" data-anchor-id="firstlayer">FirstLayer</h3>
<blockquote class="blockquote">
<pre><code> FirstLayer (size_in, size_out)</code></pre>
</blockquote>
<p>Custom first layer, mimics a standard linear layer.</p>
<p>The hidden layer <span class="math inline">\(2,\dots,m-1\)</span> is updated by</p>
<p><span class="math display">\[\begin{equation*}
    \tilde{w}_0^{kj} = w_0^{kj} + \frac{C_{kj}}{(N_{j-1}+1) \cdot |z_{kj}|} \cdot \delta_{kj}
\end{equation*}\]</span></p>
<p><span class="math display">\[\begin{equation*}
    \tilde{w}_i^{kj} = w_i^{kj} + \frac{C_{kj}}{(N_{j-1}+1) \cdot |z_{kj}|} \cdot \delta_{kj} \cdot \bar{\tilde{Y}}_{i,j-1}
\end{equation*}\]</span></p>
<p><span class="math display">\[\begin{equation*}
    i = \{1, \dots, N_{j-1}\}; j = \{2, \dots, m-1\}.
\end{equation*}\]</span></p>
<hr>
<p><a href="https://github.com/antonpf/mlmvn/blob/main/mlmvn/layers.py#L121" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="hiddenlayerfb" class="level3">
<h3 class="anchored" data-anchor-id="hiddenlayerfb">HiddenLayerFB</h3>
<blockquote class="blockquote">
<pre><code> HiddenLayerFB (*args, **kwargs)</code></pre>
</blockquote>
<p>Base class to create custom <code>autograd.Function</code></p>
<p>To create a custom <code>autograd.Function</code>, subclass this class and implement the :meth:<code>forward</code> and :meth:<code>backward</code> static methods. Then, to use your custom op in the forward pass, call the class method <code>apply</code>. Do not call :meth:<code>forward</code> directly.</p>
<p>To ensure correctness and best performance, make sure you are calling the correct methods on <code>ctx</code> and validating your backward function using :func:<code>torch.autograd.gradcheck</code>.</p>
<p>See :ref:<code>extending-autograd</code> for more details on how to use this class.</p>
<p>Examples::</p>
<pre><code>&gt;&gt;&gt; class Exp(Function):
&gt;&gt;&gt;     @staticmethod
&gt;&gt;&gt;     def forward(ctx, i):
&gt;&gt;&gt;         result = i.exp()
&gt;&gt;&gt;         ctx.save_for_backward(result)
&gt;&gt;&gt;         return result
&gt;&gt;&gt;
&gt;&gt;&gt;     @staticmethod
&gt;&gt;&gt;     def backward(ctx, grad_output):
&gt;&gt;&gt;         result, = ctx.saved_tensors
&gt;&gt;&gt;         return grad_output * result
&gt;&gt;&gt;
&gt;&gt;&gt; # Use it by calling the apply method:
&gt;&gt;&gt; output = Exp.apply(input)</code></pre>
<hr>
<p><a href="https://github.com/antonpf/mlmvn/blob/main/mlmvn/layers.py#L91" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="hiddenlayer" class="level3">
<h3 class="anchored" data-anchor-id="hiddenlayer">HiddenLayer</h3>
<blockquote class="blockquote">
<pre><code> HiddenLayer (size_in, size_out)</code></pre>
</blockquote>
<p>Custom hidden layer, mimics a standard linear layer.</p>
<p>Finally, the weights of the output layer <span class="math inline">\(m\)</span> are updated <span class="math display">\[\begin{equation*}
    \tilde{w}_0^{km} = w_0^{km} + \frac{C_{km}}{N_{m-1}+1} \cdot \delta_{km} \, ,
\end{equation*}\]</span></p>
<p><span class="math display">\[\begin{equation*}
    \tilde{w}_i^{km} = w_i^{km} + \frac{C_{km}}{N_{m-1}+1} \cdot \delta_{km} \cdot \bar{\tilde{Y}}_{i,m-1} \, ,
\end{equation*}\]</span></p>
<p><span class="math display">\[\begin{equation*}
    i = \{1, \dots, N_{m-1}\} \, ,
\end{equation*}\]</span> where <span class="math inline">\(\bar{\tilde{Y}}_{i,j-1}\)</span> is the updated complex conjugated output of the <span class="math inline">\(i\)</span>-th neuron from the <span class="math inline">\(j-1\)</span>-th layer. The variable learning rate <span class="math inline">\(\frac{1}{|z|}\)</span> is an additional parameter for nonlinear mappings that makes learning smoother. The variable learning rate can be omitted in the output layer since the exact error is known here, and it is not computed heuristically as in the previous layers.</p>
<hr>
<p><a href="https://github.com/antonpf/mlmvn/blob/main/mlmvn/layers.py#L197" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="outputlayerfb" class="level3">
<h3 class="anchored" data-anchor-id="outputlayerfb">OutputLayerFB</h3>
<blockquote class="blockquote">
<pre><code> OutputLayerFB (*args, **kwargs)</code></pre>
</blockquote>
<p>Base class to create custom <code>autograd.Function</code></p>
<p>To create a custom <code>autograd.Function</code>, subclass this class and implement the :meth:<code>forward</code> and :meth:<code>backward</code> static methods. Then, to use your custom op in the forward pass, call the class method <code>apply</code>. Do not call :meth:<code>forward</code> directly.</p>
<p>To ensure correctness and best performance, make sure you are calling the correct methods on <code>ctx</code> and validating your backward function using :func:<code>torch.autograd.gradcheck</code>.</p>
<p>See :ref:<code>extending-autograd</code> for more details on how to use this class.</p>
<p>Examples::</p>
<pre><code>&gt;&gt;&gt; class Exp(Function):
&gt;&gt;&gt;     @staticmethod
&gt;&gt;&gt;     def forward(ctx, i):
&gt;&gt;&gt;         result = i.exp()
&gt;&gt;&gt;         ctx.save_for_backward(result)
&gt;&gt;&gt;         return result
&gt;&gt;&gt;
&gt;&gt;&gt;     @staticmethod
&gt;&gt;&gt;     def backward(ctx, grad_output):
&gt;&gt;&gt;         result, = ctx.saved_tensors
&gt;&gt;&gt;         return grad_output * result
&gt;&gt;&gt;
&gt;&gt;&gt; # Use it by calling the apply method:
&gt;&gt;&gt; output = Exp.apply(input)</code></pre>
<hr>
<p><a href="https://github.com/antonpf/mlmvn/blob/main/mlmvn/layers.py#L166" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="outputlayer" class="level3">
<h3 class="anchored" data-anchor-id="outputlayer">OutputLayer</h3>
<blockquote class="blockquote">
<pre><code> OutputLayer (size_in, size_out)</code></pre>
</blockquote>
<p>Custom output layer, mimics a standard linear layer.</p>
</section>
</section>
<section id="activation" class="level2">
<h2 class="anchored" data-anchor-id="activation">Activation</h2>
<p>The activation function maps depending on the weighted sum <span class="math inline">\(z\)</span> to the unit circle, which is divided into <span class="math inline">\(k\)</span> sectors described by the set <span class="math display">\[\begin{equation}
    E_k = \{1, \varepsilon_k, \varepsilon_k^2, \dots, \varepsilon_k^{k-1}  \},
\end{equation}\]</span> with $ _k = e^{j} $, where <span class="math inline">\(j\)</span> is the imaginary unit and <span class="math inline">\(k \in \mathbb{N}_{&gt;0}\)</span>. Therefore, the activation function of a continuous MVN is defined by <span class="math display">\[\begin{equation}
    P(w_0 + w_1 x_1 + \dots + w_n x_n) = P(z) = e^{j\varphi} = \frac{z}{|z|},
\end{equation}\]</span> where <span class="math inline">\(w_0\)</span> is the bias, <span class="math inline">\(w_i\)</span> is the corresponding weight to the input <span class="math inline">\(x_i\)</span> with <span class="math inline">\(i = \{1,\dots,n\}\)</span> and <span class="math inline">\(\varphi \in [0,2\pi[\)</span> is the argument of the weighted sum <span class="math inline">\(z\)</span>. Fig. <span class="math inline">\(\ref{fig:complexActivation}\)</span> illustrates this context. The discrete activation function differs only in that the phase is adjusted to the nearest bisector, i.e.&nbsp;<span class="math inline">\(P(z) \in E_k \cdot e^{j\frac{\pi}{k}}\)</span>, where <span class="math inline">\(e^{j\frac{\pi}{k}}\)</span> realizes a shift of half a sector to move from the sector borders to the bisectors.</p>
<hr>
<p><a href="https://github.com/antonpf/mlmvn/blob/main/mlmvn/layers.py#L253" target="_blank" style="float:right; font-size:smaller">source</a></p>
<section id="cmplx_phase_activation" class="level3">
<h3 class="anchored" data-anchor-id="cmplx_phase_activation">cmplx_phase_activation</h3>
<blockquote class="blockquote">
<pre><code> cmplx_phase_activation ()</code></pre>
</blockquote>
<p>Custom Linear layer but mimics a standard linear layer</p>
<hr>
<p><a href="https://github.com/antonpf/mlmvn/blob/main/mlmvn/layers.py#L242" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="phase_activation" class="level3">
<h3 class="anchored" data-anchor-id="phase_activation">phase_activation</h3>
<blockquote class="blockquote">
<pre><code> phase_activation (*args, **kwargs)</code></pre>
</blockquote>
<p>Base class to create custom <code>autograd.Function</code></p>
<p>To create a custom <code>autograd.Function</code>, subclass this class and implement the :meth:<code>forward</code> and :meth:<code>backward</code> static methods. Then, to use your custom op in the forward pass, call the class method <code>apply</code>. Do not call :meth:<code>forward</code> directly.</p>
<p>To ensure correctness and best performance, make sure you are calling the correct methods on <code>ctx</code> and validating your backward function using :func:<code>torch.autograd.gradcheck</code>.</p>
<p>See :ref:<code>extending-autograd</code> for more details on how to use this class.</p>
<p>Examples::</p>
<pre><code>&gt;&gt;&gt; class Exp(Function):
&gt;&gt;&gt;     @staticmethod
&gt;&gt;&gt;     def forward(ctx, i):
&gt;&gt;&gt;         result = i.exp()
&gt;&gt;&gt;         ctx.save_for_backward(result)
&gt;&gt;&gt;         return result
&gt;&gt;&gt;
&gt;&gt;&gt;     @staticmethod
&gt;&gt;&gt;     def backward(ctx, grad_output):
&gt;&gt;&gt;         result, = ctx.saved_tensors
&gt;&gt;&gt;         return grad_output * result
&gt;&gt;&gt;
&gt;&gt;&gt; # Use it by calling the apply method:
&gt;&gt;&gt; output = Exp.apply(input)</code></pre>
</section>
</section>
<section id="dropout" class="level2">
<h2 class="anchored" data-anchor-id="dropout">Dropout</h2>
<hr>
<p><a href="https://github.com/antonpf/mlmvn/blob/main/mlmvn/layers.py#L276" target="_blank" style="float:right; font-size:smaller">source</a></p>
<section id="mydropout" class="level3">
<h3 class="anchored" data-anchor-id="mydropout">MyDropout</h3>
<blockquote class="blockquote">
<pre><code> MyDropout (p:float=0.5)</code></pre>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::</p>
<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))</code></pre>
<p>Submodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>.. note:: As per the example above, an <code>__init__()</code> call to the parent class must be made before assignment on the child.</p>
<p>:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool</p>
<hr>
<p><a href="https://github.com/antonpf/mlmvn/blob/main/mlmvn/layers.py#L263" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="dropoutfb" class="level3">
<h3 class="anchored" data-anchor-id="dropoutfb">DropoutFB</h3>
<blockquote class="blockquote">
<pre><code> DropoutFB (*args, **kwargs)</code></pre>
</blockquote>
<p>Base class to create custom <code>autograd.Function</code></p>
<p>To create a custom <code>autograd.Function</code>, subclass this class and implement the :meth:<code>forward</code> and :meth:<code>backward</code> static methods. Then, to use your custom op in the forward pass, call the class method <code>apply</code>. Do not call :meth:<code>forward</code> directly.</p>
<p>To ensure correctness and best performance, make sure you are calling the correct methods on <code>ctx</code> and validating your backward function using :func:<code>torch.autograd.gradcheck</code>.</p>
<p>See :ref:<code>extending-autograd</code> for more details on how to use this class.</p>
<p>Examples::</p>
<pre><code>&gt;&gt;&gt; class Exp(Function):
&gt;&gt;&gt;     @staticmethod
&gt;&gt;&gt;     def forward(ctx, i):
&gt;&gt;&gt;         result = i.exp()
&gt;&gt;&gt;         ctx.save_for_backward(result)
&gt;&gt;&gt;         return result
&gt;&gt;&gt;
&gt;&gt;&gt;     @staticmethod
&gt;&gt;&gt;     def backward(ctx, grad_output):
&gt;&gt;&gt;         result, = ctx.saved_tensors
&gt;&gt;&gt;         return grad_output * result
&gt;&gt;&gt;
&gt;&gt;&gt; # Use it by calling the apply method:
&gt;&gt;&gt; output = Exp.apply(input)</code></pre>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "î§‹";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>