{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensorless Drive Diagnosis\n",
    "\n",
    "> In this example, the main focus is the classification of individual states of a motor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from mlmvn.layers import FirstLayer, HiddenLayer, OutputLayer, cmplx_phase_activation\n",
    "from mlmvn.loss import ComplexMSELoss, ComplexMSE_adjusted_error\n",
    "from mlmvn.optim import MySGD, ECL\n",
    "from pathlib import Path\n",
    "from clearml import Task, Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# --- helper functions ---\n",
    "def reverse_one_hot(x, neuronCats):\n",
    "    a = np.zeros(len(x))\n",
    "    x = torch.detach(x)\n",
    "    for i in range(len(x)):\n",
    "        a[i] = torch.max(x[i]) - 1 + np.argmax(x[i]) * neuronCats\n",
    "    return a\n",
    "\n",
    "\n",
    "def accuracy(out, yb):\n",
    "    out = out.type(torch.double)\n",
    "    yb = yb.type(torch.double)\n",
    "    x = 0\n",
    "    for i in range(len(out)):\n",
    "        x += torch.equal(out[i], yb[i])\n",
    "    return x / len(out)\n",
    "\n",
    "\n",
    "def prepare_data(x_train, x_valid, y_train, y_valid, neuronCats):\n",
    "    # one-hot encoding\n",
    "    numSamples, numFeatures = x_valid.shape\n",
    "    y_valid_int = y_valid\n",
    "    y2 = y_valid + 1  # auxiliary variable so that classes start at 1 and not 0\n",
    "    numClasses = max(y2)\n",
    "    target_ids = range(numClasses)\n",
    "    no = int(np.ceil(numClasses / neuronCats))  # number of output neurons\n",
    "    if no != 1:\n",
    "        y_valid = torch.zeros(numSamples, no)\n",
    "        for i in range(numSamples):\n",
    "            k = int(np.ceil(y2[i] / neuronCats)) - 1\n",
    "            c = np.mod((y2[i] - 1), neuronCats) + 1\n",
    "            y_valid[i, k] = c\n",
    "    numSamples, numFeatures = x_train.shape\n",
    "    y_train_int = y_train\n",
    "    y2 = y_train + 1  # auxiliary variable so that classes start at 1 and not 0\n",
    "    if no != 1:\n",
    "        y_train = torch.zeros(numSamples, no)\n",
    "        for i in range(numSamples):\n",
    "            k = int(np.ceil(y2[i] / neuronCats)) - 1\n",
    "            c = np.mod((y2[i] - 1), neuronCats) + 1\n",
    "            y_train[i, k] = c\n",
    "    del y2\n",
    "\n",
    "    # Convert numpy arrays into torch tensors\n",
    "    x_train, y_train, x_valid, y_valid = map(\n",
    "        torch.tensor, (x_train, y_train, x_valid, y_valid)\n",
    "    )\n",
    "    if y_train.size().__len__() == 1:\n",
    "        y_train = torch.unsqueeze(y_train, 1)\n",
    "        y_valid = torch.unsqueeze(y_valid, 1)\n",
    "\n",
    "    # convert angles to complex numbers on unit-circle\n",
    "    x_train = torch.exp(1.0j * x_train)\n",
    "    x_valid = torch.exp(1.0j * x_valid)\n",
    "\n",
    "    return x_train, x_valid, y_train, y_valid\n",
    "\n",
    "\n",
    "def get_splitted_data(X, y, neuronCats):\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "        X, y, train_size=46806, random_state=42\n",
    "    )\n",
    "    x_train, x_valid, y_train, y_valid = prepare_data(\n",
    "        x_train, x_valid, y_train, y_valid, neuronCats\n",
    "    )\n",
    "\n",
    "    return x_train, x_valid, y_train, y_valid\n",
    "\n",
    "\n",
    "def get_splitted_data_by_index(X, y, neuronCats, train_index, test_index):\n",
    "    x_train, x_valid = X[train_index], X[test_index]\n",
    "    y_train, y_valid = y[train_index], y[test_index]\n",
    "    x_train, x_valid, y_train, y_valid = prepare_data(\n",
    "        x_train, x_valid, y_train, y_valid, neuronCats\n",
    "    )\n",
    "    return x_train, x_valid, y_train, y_valid\n",
    "\n",
    "\n",
    "# --- Plots ---\n",
    "def plot_loss(title, losses, scores):\n",
    "    plt.rcParams[\"axes.grid\"] = True\n",
    "    fig, (ax1) = plt.subplots(1, 1, figsize=(8, 4))\n",
    "    fig.suptitle(\"CVNN - Moons\")\n",
    "    ax1.plot(np.linspace(1, len(losses), len(losses)), losses)\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_xlim(0, len(losses))\n",
    "\n",
    "    ax1.plot(np.linspace(1, len(scores), len(scores)), scores)\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_xlim(0, len(losses))\n",
    "\n",
    "    ax1.legend([\"Acc\", \"Loss\"])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_weights(title, ylabel_1, ylabel_2, weights_real, weights_imag):\n",
    "    # y_min = np.min([np.min(weights_real), np.min(weights_imag)])\n",
    "    # y_max = np.max([np.max(weights_real), np.max(weights_imag)])\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=2, nrows=1, figsize=(14, 3))\n",
    "    fig.suptitle(title)\n",
    "    ax[0].plot(np.linspace(1, len(weights_real), len(weights_real)), weights_real)\n",
    "    ax[0].set_xlabel(\"Step\")\n",
    "    ax[0].set_ylabel(ylabel_1)\n",
    "    # ax[0].set_title(\"Real Valued Weigts\")\n",
    "    ax[0].set_xlim(0, len(weights_real))\n",
    "    # ax[0].set_ylim(y_min, y_max)\n",
    "\n",
    "    ax[1].plot(np.linspace(1, len(weights_imag), len(weights_imag)), weights_imag)\n",
    "    ax[1].set_xlabel(\"Step\")\n",
    "    ax[1].set_ylabel(ylabel_2)\n",
    "    # ax[1].set_title(\"Imaginary Valued Weights\")\n",
    "    ax[1].set_xlim(0, len(weights_imag))\n",
    "    # ax[1].set_ylim(y_min, y_max)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_loss_acc_list(title, list_losses, list_scores, image_name):\n",
    "    losses = np.mean(list_losses, axis=0)\n",
    "    scores = np.mean(list_scores, axis=0)\n",
    "\n",
    "    losses_std = np.std(list_losses, axis=0)\n",
    "    scores_std = np.std(list_scores, axis=0)\n",
    "\n",
    "    fig, (ax1) = plt.subplots(1, 1, figsize=(10, 3))\n",
    "    fig.suptitle(title)\n",
    "    ax1.plot(np.linspace(1, len(losses), len(losses)), losses)\n",
    "    ax1.fill_between(\n",
    "        np.linspace(1, len(losses), len(losses)),\n",
    "        losses + losses_std,\n",
    "        losses - losses_std,\n",
    "        alpha=0.5,\n",
    "        linewidth=0,\n",
    "    )\n",
    "\n",
    "    ax1.plot(np.linspace(1, len(scores), len(scores)), scores)\n",
    "    ax1.fill_between(\n",
    "        np.linspace(1, len(scores), len(scores)),\n",
    "        scores + scores_std,\n",
    "        scores - scores_std,\n",
    "        alpha=0.5,\n",
    "        linewidth=0,\n",
    "    )\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "\n",
    "    plt.legend([\"Loss Mean\", \"Loss Std\", \"Acc. Mean\", \"Acc. Std\"])\n",
    "    fig.savefig(image_name, format=\"png\", dpi=600)\n",
    "\n",
    "    plt.show()\n",
    "    # save\n",
    "    # fig.savefig(image_name + \".svg\", format=\"svg\", dpi=600)\n",
    "\n",
    "\n",
    "# --- Logging ---\n",
    "model_dict: dict = {}\n",
    "\n",
    "\n",
    "def fc_hook(layer_name, module, grad_input, grad_output):\n",
    "    if layer_name in model_dict:\n",
    "        model_dict[layer_name][\"weights\"] = module.weights.detach().clone()\n",
    "        model_dict[layer_name][\"bias\"] = module.bias.detach().clone()\n",
    "        model_dict[layer_name][\"grad_input\"] = grad_input\n",
    "        model_dict[layer_name][\"grad_output\"] = grad_output\n",
    "    else:\n",
    "        model_dict[layer_name] = {}\n",
    "        model_dict[layer_name][\"weights\"] = module.weights.detach().clone()\n",
    "        model_dict[layer_name][\"bias\"] = module.bias.detach().clone()\n",
    "        model_dict[layer_name][\"grad_input\"] = grad_input\n",
    "        model_dict[layer_name][\"grad_output\"] = grad_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "# control variables\n",
    "# number of categories a neuron can distinguish / parameter that determines the number of output neurons\n",
    "neuronCats = 1\n",
    "# number of categories per neuron, i.e. neuronCats (+ 1 for others in case of multiple Outputs)\n",
    "categories = 2\n",
    "# how often a classification sector occurs (1 means no periodicity)\n",
    "periodicity = 1\n",
    "# path to store best model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv(\n",
    "    \"data/autass_data2.csv\",\n",
    "    header=None,\n",
    "    dtype=np.double,\n",
    ")\n",
    "data = np.array(train_csv.values[:, 1:50])\n",
    "del train_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:, 0:48]\n",
    "y = data[:, 48].astype(int) - 1\n",
    "\n",
    "yt = copy.copy(y)\n",
    "yt[yt == 0] = 20\n",
    "yt[yt == 1] = 21\n",
    "yt[yt == 2] = 22\n",
    "yt[yt == 3] = 23\n",
    "yt[yt == 4] = 26\n",
    "yt[yt == 5] = 24\n",
    "yt[yt == 6] = 27\n",
    "yt[yt == 7] = 29\n",
    "yt[yt == 8] = 30\n",
    "yt[yt == 9] = 25\n",
    "yt[yt == 10] = 28\n",
    "yt -= 20\n",
    "y = yt\n",
    "del yt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "batch_size = 538\n",
    "lr = 1\n",
    "clip_angle_value = 1000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLMVN [48-10-11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = str(Path.cwd() / \"models/autass-mlmvn_48-10-11.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, categories, periodicity):\n",
    "        super().__init__()\n",
    "        self.categories = categories\n",
    "        self.periodicity = periodicity\n",
    "        self.first_linear = FirstLayer(48, 10)\n",
    "        self.phase_act1 = cmplx_phase_activation()\n",
    "        self.linear_out = OutputLayer(10, 11)\n",
    "        self.phase_act2 = cmplx_phase_activation()\n",
    "        # Hooks\n",
    "        self.first_layer_hook_handle = self.first_linear.register_full_backward_hook(\n",
    "            self.first_layer_backward_hook\n",
    "        )\n",
    "        self.output_hook_handle = self.linear_out.register_full_backward_hook(\n",
    "            self.output_layer_backward_hook\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first_linear(x)\n",
    "        x = self.phase_act1(x)\n",
    "        x = self.linear_out(x)\n",
    "        x = self.phase_act2(x)\n",
    "        return x\n",
    "\n",
    "    def first_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"first_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def hidden_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"hidden_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def output_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"output_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def angle2class(self, x: torch.tensor) -> torch.tensor:\n",
    "        tmp = x.angle() + 2 * np.pi\n",
    "        angle = torch.remainder(tmp, 2 * np.pi)\n",
    "\n",
    "        # This will be the discrete output (the number of sector)\n",
    "        o = torch.floor(self.categories * self.periodicity * angle / (2 * np.pi))\n",
    "        return torch.remainder(o, self.categories)\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Performs the prediction task of the network\n",
    "\n",
    "        Args:\n",
    "          x: torch.Tensor\n",
    "            Input tensor of size ([3])\n",
    "\n",
    "        Returns:\n",
    "          Most likely class i.e., Label with the highest score\n",
    "        \"\"\"\n",
    "        # Pass the data through the networks\n",
    "        output = self.forward(x)\n",
    "\n",
    "        # # Choose the label with the highest score\n",
    "        # return torch.argmax(output, 1)\n",
    "        return self.angle2class(output)\n",
    "\n",
    "\n",
    "def fit(model, X, y, epochs, batch_size, optimizer, criterion, categories, periodicity):\n",
    "    # List of losses for visualization\n",
    "    losses = []\n",
    "    scores = []\n",
    "    acc_best = 0\n",
    "\n",
    "    for i in range(epochs):\n",
    "        # Pass the data through the network and compute the loss\n",
    "        # We'll use the whole dataset during the training instead of using batches\n",
    "        # in to order to keep the code simple for now.\n",
    "\n",
    "        batch_loss = []\n",
    "\n",
    "        for j in range((X.shape[0] - 1) // batch_size + 1):\n",
    "            start_j = j * batch_size\n",
    "            end_j = start_j + batch_size\n",
    "            xb = X[start_j:end_j]\n",
    "            yb = y[start_j:end_j]\n",
    "\n",
    "            y_pred = model(xb)\n",
    "            loss = criterion(y_pred, yb, categories, periodicity)\n",
    "            batch_loss.append((torch.abs(loss)).detach().numpy())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step(inputs=xb, layers=list(model.children()))\n",
    "\n",
    "        losses.append(sum(batch_loss) / len(batch_loss))\n",
    "        if i % 10 == 9:\n",
    "            print(f\"Epoch {i} loss is {losses[-1]}\")\n",
    "        y_pred = model.predict(X)\n",
    "        scores.append(accuracy(y_pred.squeeze(), y))\n",
    "\n",
    "        if scores[-1] > acc_best:\n",
    "            acc_best = scores[-1]\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "    return losses, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=854e9bc7dc7e496ea841a13f617da653\n",
      "ClearML results page: http://194.94.231.172:8080/projects/cdefd6ee85454e49be01962ad715eca0/experiments/854e9bc7dc7e496ea841a13f617da653/output/log\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 1,\n",
       " 'epochs': 200,\n",
       " 'batch_size': 538,\n",
       " 'optim': 'ECL',\n",
       " 'categories': 2,\n",
       " 'periodicity': 1,\n",
       " 'layer': '[48-10-11]',\n",
       " 'clip_angle_value': 1000000}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = Task.init(\n",
    "    project_name=\"mlmvn\",\n",
    "    task_name=\"SDD-mlmvn-[48-10-11]\",\n",
    "    tags=[\"mlmvn\", \"SDD\", \"multiple_runs\", \"adjusted_loss\"],\n",
    ")\n",
    "writer = SummaryWriter()\n",
    "\n",
    "#  capture a dictionary of hyperparameters with config\n",
    "config_dict = {\n",
    "    \"learning_rate\": 1,\n",
    "    \"epochs\": epochs,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"optim\": \"ECL\",\n",
    "    \"categories\": categories,\n",
    "    \"periodicity\": periodicity,\n",
    "    \"layer\": \"[48-10-11]\",\n",
    "    \"loss\": \"ComplexMSE_adjusted_error\",\n",
    "}\n",
    "task.connect(config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10107/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-27 14:25:57,872 - clearml.frameworks - INFO - Found existing registered model id=caa96da5a415490ca1ea0f95b383f403 [/home/antonpfeifer/Documents/mlmvn/nbs/examples/autass/models/autass-mlmvn_48-10-11.pt] reusing it.\n",
      "Epoch 9 loss is 0.312786317016275\n",
      "Epoch 19 loss is 0.25568547822538934\n",
      "Epoch 29 loss is 0.3389669520974066\n",
      "Epoch 39 loss is 0.28586026849296975\n",
      "Epoch 49 loss is 0.2642590965695329\n",
      "Epoch 59 loss is 0.2561917205608428\n",
      "Epoch 69 loss is 0.2538907377290161\n",
      "Epoch 79 loss is 0.25494624541893784\n",
      "Epoch 89 loss is 0.2586601196421547\n",
      "Epoch 99 loss is 0.26136219948247824\n",
      "Epoch 109 loss is 0.25920406138033625\n",
      "Epoch 119 loss is 0.257771638513778\n",
      "Epoch 129 loss is 0.256717965344817\n",
      "Epoch 139 loss is 0.2562337465502512\n",
      "Epoch 149 loss is 0.25599395140123643\n",
      "Epoch 159 loss is 0.2555283782128066\n",
      "Epoch 169 loss is 0.25500644305516845\n",
      "Epoch 179 loss is 0.2546311936985765\n",
      "Epoch 189 loss is 0.2545335270219525\n",
      "Epoch 199 loss is 0.2544423936517196\n",
      "Train Acc.:  0.7605486358877945\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.85      0.89      1063\n",
      "           1       0.83      0.75      0.79      1064\n",
      "           2       0.90      0.72      0.80      1064\n",
      "           3       0.84      0.73      0.78      1064\n",
      "           4       0.78      0.68      0.73      1064\n",
      "           5       0.82      0.88      0.85      1063\n",
      "           6       0.75      0.59      0.66      1064\n",
      "           7       0.99      1.00      1.00      1064\n",
      "           8       1.00      1.00      1.00      1064\n",
      "           9       0.81      0.81      0.81      1064\n",
      "          10       0.89      0.87      0.88      1064\n",
      "\n",
      "   micro avg       0.87      0.81      0.84     11702\n",
      "   macro avg       0.87      0.81      0.83     11702\n",
      "weighted avg       0.87      0.81      0.83     11702\n",
      " samples avg       0.78      0.81      0.79     11702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10107/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss is 0.23875833944773336\n",
      "Epoch 19 loss is 0.35046091409537855\n",
      "Epoch 29 loss is 0.3474688264639837\n",
      "Epoch 39 loss is 0.3460845462685393\n",
      "Epoch 49 loss is 0.34521615010787904\n",
      "Epoch 59 loss is 0.34480239729514767\n",
      "Epoch 69 loss is 0.3445531601110381\n",
      "Epoch 79 loss is 0.344414452281505\n",
      "Epoch 89 loss is 0.3443463357528307\n",
      "Epoch 99 loss is 0.34433482782616937\n",
      "Epoch 109 loss is 0.3443202594365852\n",
      "Epoch 119 loss is 0.3443419606632198\n",
      "Epoch 129 loss is 0.34439574951313695\n",
      "Epoch 139 loss is 0.34447653188306476\n",
      "Epoch 149 loss is 0.34455745559313744\n",
      "Epoch 159 loss is 0.3446490512911633\n",
      "Epoch 169 loss is 0.34472025490019265\n",
      "Epoch 179 loss is 0.34483666034343385\n",
      "Epoch 189 loss is 0.3449189385351294\n",
      "Epoch 199 loss is 0.34502282438946064\n",
      "Train Acc.:  0.7681329715640823\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85      1063\n",
      "           1       0.88      0.68      0.77      1064\n",
      "           2       0.90      0.73      0.81      1064\n",
      "           3       0.86      0.74      0.80      1063\n",
      "           4       0.76      0.75      0.76      1064\n",
      "           5       0.81      0.74      0.77      1064\n",
      "           6       0.80      0.72      0.75      1064\n",
      "           7       0.99      0.97      0.98      1064\n",
      "           8       1.00      0.99      1.00      1064\n",
      "           9       0.88      0.84      0.86      1064\n",
      "          10       0.92      0.80      0.86      1064\n",
      "\n",
      "   micro avg       0.88      0.80      0.84     11702\n",
      "   macro avg       0.88      0.80      0.84     11702\n",
      "weighted avg       0.88      0.80      0.84     11702\n",
      " samples avg       0.78      0.80      0.79     11702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10107/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss is 0.2971094108173737\n",
      "Epoch 19 loss is 0.3869108816673947\n",
      "Epoch 29 loss is 0.4365067504356039\n",
      "Epoch 39 loss is 0.4177013765514301\n",
      "Epoch 49 loss is 0.4124413908694452\n",
      "Epoch 59 loss is 0.40500117037391986\n",
      "Epoch 69 loss is 0.41131196047303786\n",
      "Epoch 79 loss is 0.4181249931351551\n",
      "Epoch 89 loss is 0.41661642708626356\n",
      "Epoch 99 loss is 0.4181854146942287\n",
      "Epoch 109 loss is 0.4133348665799685\n",
      "Epoch 119 loss is 0.4099116159030149\n",
      "Epoch 129 loss is 0.4199283736599332\n",
      "Epoch 139 loss is 0.417771504949945\n",
      "Epoch 149 loss is 0.4188665644250296\n",
      "Epoch 159 loss is 0.42150588067988737\n",
      "Epoch 169 loss is 0.4230460352811647\n",
      "Epoch 179 loss is 0.4250528931966397\n",
      "Epoch 189 loss is 0.4252225452870114\n",
      "Epoch 199 loss is 0.42203162628683427\n",
      "Train Acc.:  0.7921464738180187\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.92      1064\n",
      "           1       0.85      0.66      0.75      1064\n",
      "           2       0.92      0.80      0.86      1064\n",
      "           3       0.88      0.83      0.86      1063\n",
      "           4       0.71      0.83      0.77      1064\n",
      "           5       0.78      0.88      0.83      1064\n",
      "           6       0.79      0.72      0.75      1063\n",
      "           7       1.00      0.97      0.99      1064\n",
      "           8       1.00      1.00      1.00      1064\n",
      "           9       0.84      0.79      0.81      1064\n",
      "          10       0.84      0.82      0.83      1064\n",
      "\n",
      "   micro avg       0.87      0.84      0.85     11702\n",
      "   macro avg       0.87      0.84      0.85     11702\n",
      "weighted avg       0.87      0.84      0.85     11702\n",
      " samples avg       0.81      0.84      0.82     11702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10107/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss is 0.2795195632281697\n",
      "Epoch 19 loss is 0.3375428780831629\n",
      "Epoch 29 loss is 0.33256474318305307\n",
      "Epoch 39 loss is 0.33185831863511417\n",
      "Epoch 49 loss is 0.3295307025439074\n",
      "Epoch 59 loss is 0.3210891922650079\n",
      "Epoch 69 loss is 0.32034934104938245\n",
      "Epoch 79 loss is 0.3163362890807787\n",
      "Epoch 89 loss is 0.315736489078309\n",
      "Epoch 99 loss is 0.3155383143134653\n",
      "Epoch 109 loss is 0.31553327463043673\n",
      "Epoch 119 loss is 0.31600845927522986\n",
      "Epoch 129 loss is 0.3150536779122853\n",
      "Epoch 139 loss is 0.3150594287707738\n",
      "Epoch 149 loss is 0.31524582921067934\n",
      "Epoch 159 loss is 0.3153440366348357\n",
      "Epoch 169 loss is 0.31513214139197515\n",
      "Epoch 179 loss is 0.3152703075228755\n",
      "Epoch 189 loss is 0.3215461540110862\n",
      "Epoch 199 loss is 0.31620214863132784\n",
      "Train Acc.:  0.7109833999188155\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91      1063\n",
      "           1       0.84      0.76      0.80      1064\n",
      "           2       0.82      0.71      0.76      1064\n",
      "           3       0.87      0.84      0.85      1063\n",
      "           4       0.82      0.53      0.64      1064\n",
      "           5       0.86      0.74      0.80      1064\n",
      "           6       0.90      0.02      0.04      1064\n",
      "           7       1.00      0.97      0.98      1064\n",
      "           8       0.99      1.00      1.00      1064\n",
      "           9       0.63      0.93      0.75      1064\n",
      "          10       0.91      0.84      0.87      1064\n",
      "\n",
      "   micro avg       0.85      0.75      0.80     11702\n",
      "   macro avg       0.87      0.75      0.76     11702\n",
      "weighted avg       0.87      0.75      0.76     11702\n",
      " samples avg       0.73      0.75      0.74     11702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10107/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss is 0.39677247203032356\n",
      "Epoch 19 loss is 0.35580593764225016\n",
      "Epoch 29 loss is 0.42506711288150867\n",
      "Epoch 39 loss is 0.4258715088317278\n",
      "Epoch 49 loss is 0.42243423247066575\n",
      "Epoch 59 loss is 0.4237868170495762\n",
      "Epoch 69 loss is 0.41925568150605863\n",
      "Epoch 79 loss is 0.439859722214063\n",
      "Epoch 89 loss is 0.4537169174860011\n",
      "Epoch 99 loss is 0.4516644332667944\n",
      "Epoch 109 loss is 0.4505254539904648\n",
      "Epoch 119 loss is 0.44988270158956056\n",
      "Epoch 129 loss is 0.4494370519612547\n",
      "Epoch 139 loss is 0.449528904207753\n",
      "Epoch 149 loss is 0.44943834853116904\n",
      "Epoch 159 loss is 0.449371091649806\n",
      "Epoch 169 loss is 0.4491654165153552\n",
      "Epoch 179 loss is 0.4491931206111527\n",
      "Epoch 189 loss is 0.44876226191301677\n",
      "Epoch 199 loss is 0.44890430281994864\n",
      "Train Acc.:  0.6543465720939176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.86      0.77      1064\n",
      "           1       0.00      0.00      0.00      1064\n",
      "           2       0.95      0.68      0.79      1064\n",
      "           3       0.88      0.71      0.78      1064\n",
      "           4       0.69      0.60      0.64      1064\n",
      "           5       0.63      0.84      0.72      1064\n",
      "           6       0.79      0.65      0.71      1063\n",
      "           7       0.97      0.98      0.98      1064\n",
      "           8       1.00      1.00      1.00      1063\n",
      "           9       0.75      0.75      0.75      1064\n",
      "          10       0.91      0.83      0.87      1064\n",
      "\n",
      "   micro avg       0.81      0.72      0.76     11702\n",
      "   macro avg       0.75      0.72      0.73     11702\n",
      "weighted avg       0.75      0.72      0.73     11702\n",
      " samples avg       0.69      0.72      0.70     11702\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "list_losses = []\n",
    "list_scores = []\n",
    "list_acc = []\n",
    "list_loss = []\n",
    "list_f1 = []\n",
    "list_precision = []\n",
    "list_recall = []\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    model_dict: dict = {}\n",
    "    x_train, x_valid, y_train, y_valid = get_splitted_data_by_index(\n",
    "        X, y, neuronCats, train_index, test_index\n",
    "    )\n",
    "\n",
    "    model = Model(categories=categories, periodicity=periodicity)\n",
    "    criterion = ComplexMSE_adjusted_error.apply\n",
    "    optimizer = ECL(model.parameters(), lr=lr)\n",
    "\n",
    "    losses, scores = fit(\n",
    "        model,\n",
    "        x_train,\n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        categories=categories,\n",
    "        periodicity=periodicity,\n",
    "    )\n",
    "\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "    list_scores.append(scores)\n",
    "    list_losses.append(losses)\n",
    "\n",
    "    y_pred = model.predict(x_train)\n",
    "    acc = accuracy(y_pred.squeeze(), y_train)\n",
    "    print(\"Train Acc.: \", acc)\n",
    "\n",
    "    y_pred = model.predict(x_valid)\n",
    "    acc = accuracy(y_pred.squeeze(), y_valid)\n",
    "    list_acc.append(acc)\n",
    "\n",
    "    print(classification_report(y_valid, y_pred.detach().numpy(), zero_division=0))\n",
    "    list_f1.append(\n",
    "        f1_score(y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0)\n",
    "    )\n",
    "    list_precision.append(\n",
    "        precision_score(\n",
    "            y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0\n",
    "        )\n",
    "    )\n",
    "    list_recall.append(\n",
    "        recall_score(\n",
    "            y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0\n",
    "        )\n",
    "    )\n",
    "\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_accuracy_mean\",\n",
    "    value=np.mean(list_acc),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_accuracy_std\",\n",
    "    value=np.std(list_acc),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_f1_mean\",\n",
    "    value=np.mean(list_f1),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_f1_std\",\n",
    "    value=np.std(list_f1),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_precision_mean\",\n",
    "    value=np.mean(list_precision),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_precision_std\",\n",
    "    value=np.std(list_precision),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_recall_mean\",\n",
    "    value=np.mean(list_recall),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_recall_std\",\n",
    "    value=np.std(list_recall),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.mark_completed()\n",
    "task.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLMVN [48-20-11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = str(Path.cwd() / \"models/autass-mlmvn_48-20-11.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, categories, periodicity):\n",
    "        super().__init__()\n",
    "        self.categories = categories\n",
    "        self.periodicity = periodicity\n",
    "        self.first_linear = FirstLayer(48, 20)\n",
    "        self.phase_act1 = cmplx_phase_activation()\n",
    "        self.linear_out = OutputLayer(20, 11)\n",
    "        self.phase_act2 = cmplx_phase_activation()\n",
    "        # Hooks\n",
    "        self.first_layer_hook_handle = self.first_linear.register_full_backward_hook(\n",
    "            self.first_layer_backward_hook\n",
    "        )\n",
    "        self.output_hook_handle = self.linear_out.register_full_backward_hook(\n",
    "            self.output_layer_backward_hook\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first_linear(x)\n",
    "        x = self.phase_act1(x)\n",
    "        x = self.linear_out(x)\n",
    "        x = self.phase_act2(x)\n",
    "        return x\n",
    "\n",
    "    def first_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"first_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def hidden_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"hidden_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def output_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"output_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def angle2class(self, x: torch.tensor) -> torch.tensor:\n",
    "        tmp = x.angle() + 2 * np.pi\n",
    "        angle = torch.remainder(tmp, 2 * np.pi)\n",
    "\n",
    "        # This will be the discrete output (the number of sector)\n",
    "        o = torch.floor(self.categories * self.periodicity * angle / (2 * np.pi))\n",
    "        return torch.remainder(o, self.categories)\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Performs the prediction task of the network\n",
    "\n",
    "        Args:\n",
    "          x: torch.Tensor\n",
    "            Input tensor of size ([3])\n",
    "\n",
    "        Returns:\n",
    "          Most likely class i.e., Label with the highest score\n",
    "        \"\"\"\n",
    "        # Pass the data through the networks\n",
    "        output = self.forward(x)\n",
    "\n",
    "        # # Choose the label with the highest score\n",
    "        # return torch.argmax(output, 1)\n",
    "        return self.angle2class(output)\n",
    "\n",
    "\n",
    "def fit(model, X, y, epochs, batch_size, optimizer, criterion, categories, periodicity):\n",
    "    # List of losses for visualization\n",
    "    losses = []\n",
    "    scores = []\n",
    "    acc_best = 0\n",
    "\n",
    "    for i in range(epochs):\n",
    "        # Pass the data through the network and compute the loss\n",
    "        # We'll use the whole dataset during the training instead of using batches\n",
    "        # in to order to keep the code simple for now.\n",
    "\n",
    "        batch_loss = []\n",
    "\n",
    "        for j in range((X.shape[0] - 1) // batch_size + 1):\n",
    "            start_j = j * batch_size\n",
    "            end_j = start_j + batch_size\n",
    "            xb = X[start_j:end_j]\n",
    "            yb = y[start_j:end_j]\n",
    "\n",
    "            y_pred = model(xb)\n",
    "            loss = criterion(y_pred, yb, categories, periodicity)\n",
    "            batch_loss.append((torch.abs(loss)).detach().numpy())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step(inputs=xb, layers=list(model.children()))\n",
    "\n",
    "        losses.append(sum(batch_loss) / len(batch_loss))\n",
    "        if i % 10 == 9:\n",
    "            print(f\"Epoch {i} loss is {losses[-1]}\")\n",
    "        y_pred = model.predict(X)\n",
    "        scores.append(accuracy(y_pred.squeeze(), y))\n",
    "\n",
    "        if scores[-1] > acc_best:\n",
    "            acc_best = scores[-1]\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "    return losses, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=47852b7bd30c475a9fbb69e5802aea36\n",
      "ClearML results page: http://194.94.231.172:8080/projects/cdefd6ee85454e49be01962ad715eca0/experiments/47852b7bd30c475a9fbb69e5802aea36/output/log\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 1,\n",
       " 'epochs': 200,\n",
       " 'batch_size': 538,\n",
       " 'optim': 'ECL',\n",
       " 'categories': 2,\n",
       " 'periodicity': 1,\n",
       " 'layer': '[48-20-11]',\n",
       " 'clip_angle_value': 1000000}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = Task.init(\n",
    "    project_name=\"mlmvn\",\n",
    "    task_name=\"SDD-mlmvn-[48-20-11]\",\n",
    "    tags=[\"mlmvn\", \"SDD\", \"multiple_runs\", \"adjusted_loss\"],\n",
    ")\n",
    "writer = SummaryWriter()\n",
    "\n",
    "#  capture a dictionary of hyperparameters with config\n",
    "config_dict = {\n",
    "    \"learning_rate\": 1,\n",
    "    \"epochs\": epochs,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"optim\": \"ECL\",\n",
    "    \"categories\": categories,\n",
    "    \"periodicity\": periodicity,\n",
    "    \"layer\": \"[48-20-11]\",\n",
    "    \"loss\": \"ComplexMSE_adjusted_error\",\n",
    "}\n",
    "task.connect(config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10107/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-27 14:42:43,693 - clearml.frameworks - INFO - Found existing registered model id=c337b94a22444d809d449783726d8ee2 [/home/antonpfeifer/Documents/mlmvn/nbs/examples/autass/models/autass-mlmvn_48-20-11.pt] reusing it.\n",
      "Epoch 9 loss is 0.15395791001477882\n",
      "Epoch 19 loss is 0.15815942352420895\n",
      "Epoch 29 loss is 0.1521475958209485\n",
      "Epoch 39 loss is 0.22264992876002446\n",
      "Epoch 49 loss is 0.2434950175800985\n",
      "Epoch 59 loss is 0.3000683165649394\n",
      "Epoch 69 loss is 0.2986102485389353\n",
      "Epoch 79 loss is 0.2978965348099431\n",
      "Epoch 89 loss is 0.2976461313968712\n",
      "Epoch 99 loss is 0.297615187920047\n",
      "Epoch 109 loss is 0.2975814279553468\n",
      "Epoch 119 loss is 0.2973692060082367\n",
      "Epoch 129 loss is 0.2971646093759705\n",
      "Epoch 139 loss is 0.2969823604569539\n",
      "Epoch 149 loss is 0.2968226945940804\n",
      "Epoch 159 loss is 0.29669339181528953\n",
      "Epoch 169 loss is 0.2965860987914452\n",
      "Epoch 179 loss is 0.2964960589856526\n",
      "Epoch 189 loss is 0.296397997745145\n",
      "Epoch 199 loss is 0.2963285508675669\n",
      "Train Acc.:  0.8742068494028671\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92      1063\n",
      "           1       0.91      0.89      0.90      1064\n",
      "           2       0.97      0.95      0.96      1064\n",
      "           3       0.95      0.93      0.94      1064\n",
      "           4       0.79      0.76      0.78      1064\n",
      "           5       0.89      0.90      0.90      1063\n",
      "           6       0.84      0.84      0.84      1064\n",
      "           7       1.00      1.00      1.00      1064\n",
      "           8       1.00      0.99      1.00      1064\n",
      "           9       0.89      0.87      0.88      1064\n",
      "          10       0.92      0.96      0.94      1064\n",
      "\n",
      "   micro avg       0.92      0.91      0.91     11702\n",
      "   macro avg       0.92      0.91      0.91     11702\n",
      "weighted avg       0.92      0.91      0.91     11702\n",
      " samples avg       0.89      0.91      0.89     11702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10107/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss is 0.23371587049756218\n",
      "Epoch 19 loss is 0.2171053793431578\n",
      "Epoch 29 loss is 0.2117481726413607\n",
      "Epoch 39 loss is 0.20548662762905423\n",
      "Epoch 49 loss is 0.20055165801015304\n",
      "Epoch 59 loss is 0.19926006465921117\n",
      "Epoch 69 loss is 0.20121967169245297\n",
      "Epoch 79 loss is 0.2012524994483403\n",
      "Epoch 89 loss is 0.2089158789663104\n",
      "Epoch 99 loss is 0.2069847307533938\n",
      "Epoch 109 loss is 0.20158804575222558\n",
      "Epoch 119 loss is 0.19908199121184547\n",
      "Epoch 129 loss is 0.1983263363973267\n",
      "Epoch 139 loss is 0.1981246632369139\n",
      "Epoch 149 loss is 0.19843244794655257\n",
      "Epoch 159 loss is 0.19990613128620335\n",
      "Epoch 169 loss is 0.20346991661240654\n",
      "Epoch 179 loss is 0.20220646457032931\n",
      "Epoch 189 loss is 0.20162040661533578\n",
      "Epoch 199 loss is 0.20261586962160896\n",
      "Train Acc.:  0.7864421988164163\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93      1063\n",
      "           1       0.90      0.78      0.84      1064\n",
      "           2       0.98      0.66      0.79      1064\n",
      "           3       0.88      0.91      0.90      1063\n",
      "           4       0.73      0.60      0.66      1064\n",
      "           5       0.81      0.92      0.86      1064\n",
      "           6       0.75      0.77      0.76      1064\n",
      "           7       1.00      1.00      1.00      1064\n",
      "           8       1.00      1.00      1.00      1064\n",
      "           9       0.85      0.87      0.86      1064\n",
      "          10       0.84      0.82      0.83      1064\n",
      "\n",
      "   micro avg       0.88      0.84      0.86     11702\n",
      "   macro avg       0.88      0.84      0.86     11702\n",
      "weighted avg       0.88      0.84      0.86     11702\n",
      " samples avg       0.81      0.84      0.82     11702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10107/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss is 0.17359070471532762\n",
      "Epoch 19 loss is 0.19923888591987557\n",
      "Epoch 29 loss is 0.22116873452047683\n",
      "Epoch 39 loss is 0.2029670658449249\n",
      "Epoch 49 loss is 0.20419508592690006\n",
      "Epoch 59 loss is 0.19794629333818395\n",
      "Epoch 69 loss is 0.1952743740865991\n",
      "Epoch 79 loss is 0.19510413114878267\n",
      "Epoch 89 loss is 0.19646997157487037\n",
      "Epoch 99 loss is 0.19606822933983284\n",
      "Epoch 109 loss is 0.19653955121411834\n",
      "Epoch 119 loss is 0.19678779104367372\n",
      "Epoch 129 loss is 0.19675274303142729\n",
      "Epoch 139 loss is 0.19700162446357028\n",
      "Epoch 149 loss is 0.1971595217735474\n",
      "Epoch 159 loss is 0.19742537431793827\n",
      "Epoch 169 loss is 0.19757406298027266\n",
      "Epoch 179 loss is 0.1976568692427292\n",
      "Epoch 189 loss is 0.19808705126678153\n",
      "Epoch 199 loss is 0.19829968689615954\n",
      "Train Acc.:  0.8086610976990621\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.91      1064\n",
      "           1       0.87      0.82      0.85      1064\n",
      "           2       0.97      0.91      0.94      1064\n",
      "           3       0.96      0.92      0.94      1063\n",
      "           4       0.65      0.71      0.68      1064\n",
      "           5       0.86      0.87      0.87      1064\n",
      "           6       0.78      0.75      0.77      1063\n",
      "           7       1.00      1.00      1.00      1064\n",
      "           8       1.00      1.00      1.00      1064\n",
      "           9       0.82      0.80      0.81      1064\n",
      "          10       0.95      0.90      0.92      1064\n",
      "\n",
      "   micro avg       0.89      0.87      0.88     11702\n",
      "   macro avg       0.89      0.87      0.88     11702\n",
      "weighted avg       0.89      0.87      0.88     11702\n",
      " samples avg       0.84      0.87      0.85     11702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10107/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss is 0.16241861081194287\n",
      "Epoch 19 loss is 0.142375697260239\n",
      "Epoch 29 loss is 0.15385840834181844\n",
      "Epoch 39 loss is 0.2138264016307598\n",
      "Epoch 49 loss is 0.2365240586587247\n",
      "Epoch 59 loss is 0.2929398953187324\n",
      "Epoch 69 loss is 0.2761381170166951\n",
      "Epoch 79 loss is 0.3456885180336249\n",
      "Epoch 89 loss is 0.34346247018042997\n",
      "Epoch 99 loss is 0.3458485532239313\n",
      "Epoch 109 loss is 0.3444044925757802\n",
      "Epoch 119 loss is 0.3440097919960899\n",
      "Epoch 129 loss is 0.34428306482555965\n",
      "Epoch 139 loss is 0.3449518206799149\n",
      "Epoch 149 loss is 0.3461375016053481\n",
      "Epoch 159 loss is 0.3476872522585145\n",
      "Epoch 169 loss is 0.34796445004321847\n",
      "Epoch 179 loss is 0.3482418109346652\n",
      "Epoch 189 loss is 0.34871055688690134\n",
      "Epoch 199 loss is 0.3490575960919955\n",
      "Train Acc.:  0.8840558036191168\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      1063\n",
      "           1       0.92      0.90      0.91      1064\n",
      "           2       0.97      0.93      0.95      1064\n",
      "           3       0.96      0.96      0.96      1063\n",
      "           4       0.93      0.78      0.85      1064\n",
      "           5       0.94      0.90      0.92      1064\n",
      "           6       0.90      0.77      0.83      1064\n",
      "           7       1.00      0.99      1.00      1064\n",
      "           8       1.00      1.00      1.00      1064\n",
      "           9       0.85      0.87      0.86      1064\n",
      "          10       0.94      0.92      0.93      1064\n",
      "\n",
      "   micro avg       0.94      0.91      0.92     11702\n",
      "   macro avg       0.94      0.91      0.92     11702\n",
      "weighted avg       0.94      0.91      0.92     11702\n",
      " samples avg       0.89      0.91      0.90     11702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10107/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss is 0.15193523247470855\n",
      "Epoch 19 loss is 0.1408373010379282\n",
      "Epoch 29 loss is 0.18472082419796915\n",
      "Epoch 39 loss is 0.1959035029241411\n",
      "Epoch 49 loss is 0.21619177741693082\n",
      "Epoch 59 loss is 0.21511564006011144\n",
      "Epoch 69 loss is 0.20399205995454375\n",
      "Epoch 79 loss is 0.20022756204760384\n",
      "Epoch 89 loss is 0.20033638712455112\n",
      "Epoch 99 loss is 0.19893451606025606\n",
      "Epoch 109 loss is 0.19786037468191467\n",
      "Epoch 119 loss is 0.19890569036312059\n",
      "Epoch 129 loss is 0.1990134917790664\n",
      "Epoch 139 loss is 0.19872859569206974\n",
      "Epoch 149 loss is 0.19751614804725498\n",
      "Epoch 159 loss is 0.19739665962479105\n",
      "Epoch 169 loss is 0.19784372444886006\n",
      "Epoch 179 loss is 0.19111926939075988\n",
      "Epoch 189 loss is 0.19073564886846614\n",
      "Epoch 199 loss is 0.18976225840289762\n",
      "Train Acc.:  0.8771764906958361\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95      1064\n",
      "           1       0.89      0.79      0.84      1064\n",
      "           2       0.97      0.93      0.95      1064\n",
      "           3       0.99      0.94      0.96      1064\n",
      "           4       0.90      0.85      0.88      1064\n",
      "           5       0.87      0.89      0.88      1064\n",
      "           6       0.89      0.77      0.83      1063\n",
      "           7       1.00      1.00      1.00      1064\n",
      "           8       1.00      1.00      1.00      1063\n",
      "           9       0.86      0.87      0.87      1064\n",
      "          10       0.97      0.90      0.93      1064\n",
      "\n",
      "   micro avg       0.93      0.90      0.92     11702\n",
      "   macro avg       0.93      0.90      0.92     11702\n",
      "weighted avg       0.93      0.90      0.92     11702\n",
      " samples avg       0.89      0.90      0.89     11702\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "list_losses = []\n",
    "list_scores = []\n",
    "list_acc = []\n",
    "list_loss = []\n",
    "list_f1 = []\n",
    "list_precision = []\n",
    "list_recall = []\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    model_dict: dict = {}\n",
    "    x_train, x_valid, y_train, y_valid = get_splitted_data_by_index(\n",
    "        X, y, neuronCats, train_index, test_index\n",
    "    )\n",
    "\n",
    "    model = Model(categories=categories, periodicity=periodicity)\n",
    "    criterion = ComplexMSE_adjusted_error.apply\n",
    "    optimizer = ECL(model.parameters(), lr=lr)\n",
    "\n",
    "    losses, scores = fit(\n",
    "        model,\n",
    "        x_train,\n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        categories=categories,\n",
    "        periodicity=periodicity,\n",
    "    )\n",
    "\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "    list_scores.append(scores)\n",
    "    list_losses.append(losses)\n",
    "\n",
    "    y_pred = model.predict(x_train)\n",
    "    acc = accuracy(y_pred.squeeze(), y_train)\n",
    "    print(\"Train Acc.: \", acc)\n",
    "\n",
    "    y_pred = model.predict(x_valid)\n",
    "    acc = accuracy(y_pred.squeeze(), y_valid)\n",
    "    list_acc.append(acc)\n",
    "\n",
    "    print(classification_report(y_valid, y_pred.detach().numpy(), zero_division=0))\n",
    "    list_f1.append(\n",
    "        f1_score(y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0)\n",
    "    )\n",
    "    list_precision.append(\n",
    "        precision_score(\n",
    "            y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0\n",
    "        )\n",
    "    )\n",
    "    list_recall.append(\n",
    "        recall_score(\n",
    "            y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0\n",
    "        )\n",
    "    )\n",
    "\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_accuracy_mean\",\n",
    "    value=np.mean(list_acc),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_accuracy_std\",\n",
    "    value=np.std(list_acc),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_f1_mean\",\n",
    "    value=np.mean(list_f1),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_f1_std\",\n",
    "    value=np.std(list_f1),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_precision_mean\",\n",
    "    value=np.mean(list_precision),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_precision_std\",\n",
    "    value=np.std(list_precision),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_recall_mean\",\n",
    "    value=np.mean(list_recall),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_recall_std\",\n",
    "    value=np.std(list_recall),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.mark_completed()\n",
    "task.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLMVN [48-50-11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = str(Path.cwd() / \"models/autass-mlmvn_48-50-11.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, categories, periodicity):\n",
    "        super().__init__()\n",
    "        self.categories = categories\n",
    "        self.periodicity = periodicity\n",
    "        self.first_linear = FirstLayer(48, 50)\n",
    "        self.phase_act1 = cmplx_phase_activation()\n",
    "        self.linear_out = OutputLayer(50, 11)\n",
    "        self.phase_act2 = cmplx_phase_activation()\n",
    "        # Hooks\n",
    "        self.first_layer_hook_handle = self.first_linear.register_full_backward_hook(\n",
    "            self.first_layer_backward_hook\n",
    "        )\n",
    "        self.output_hook_handle = self.linear_out.register_full_backward_hook(\n",
    "            self.output_layer_backward_hook\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first_linear(x)\n",
    "        x = self.phase_act1(x)\n",
    "        x = self.linear_out(x)\n",
    "        x = self.phase_act2(x)\n",
    "        return x\n",
    "\n",
    "    def first_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"first_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def hidden_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"hidden_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def output_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"output_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def angle2class(self, x: torch.tensor) -> torch.tensor:\n",
    "        tmp = x.angle() + 2 * np.pi\n",
    "        angle = torch.remainder(tmp, 2 * np.pi)\n",
    "\n",
    "        # This will be the discrete output (the number of sector)\n",
    "        o = torch.floor(self.categories * self.periodicity * angle / (2 * np.pi))\n",
    "        return torch.remainder(o, self.categories)\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Performs the prediction task of the network\n",
    "\n",
    "        Args:\n",
    "          x: torch.Tensor\n",
    "            Input tensor of size ([3])\n",
    "\n",
    "        Returns:\n",
    "          Most likely class i.e., Label with the highest score\n",
    "        \"\"\"\n",
    "        # Pass the data through the networks\n",
    "        output = self.forward(x)\n",
    "\n",
    "        # # Choose the label with the highest score\n",
    "        # return torch.argmax(output, 1)\n",
    "        return self.angle2class(output)\n",
    "\n",
    "\n",
    "def fit(model, X, y, epochs, batch_size, optimizer, criterion, categories, periodicity):\n",
    "    # List of losses for visualization\n",
    "    losses = []\n",
    "    scores = []\n",
    "    acc_best = 0\n",
    "\n",
    "    for i in range(epochs):\n",
    "        # Pass the data through the network and compute the loss\n",
    "        # We'll use the whole dataset during the training instead of using batches\n",
    "        # in to order to keep the code simple for now.\n",
    "\n",
    "        batch_loss = []\n",
    "\n",
    "        for j in range((X.shape[0] - 1) // batch_size + 1):\n",
    "            start_j = j * batch_size\n",
    "            end_j = start_j + batch_size\n",
    "            xb = X[start_j:end_j]\n",
    "            yb = y[start_j:end_j]\n",
    "\n",
    "            y_pred = model(xb)\n",
    "            loss = criterion(y_pred, yb, categories, periodicity)\n",
    "            batch_loss.append((torch.abs(loss)).detach().numpy())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step(inputs=xb, layers=list(model.children()))\n",
    "\n",
    "        losses.append(sum(batch_loss) / len(batch_loss))\n",
    "        if i % 10 == 9:\n",
    "            print(f\"Epoch {i} loss is {losses[-1]}\")\n",
    "        y_pred = model.predict(X)\n",
    "        scores.append(accuracy(y_pred.squeeze(), y))\n",
    "\n",
    "        if scores[-1] > acc_best:\n",
    "            acc_best = scores[-1]\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "    return losses, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=0e2885b9c6934f79849153fe8c7149d5\n",
      "ClearML results page: http://194.94.231.172:8080/projects/cdefd6ee85454e49be01962ad715eca0/experiments/0e2885b9c6934f79849153fe8c7149d5/output/log\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 1,\n",
       " 'epochs': 200,\n",
       " 'batch_size': 538,\n",
       " 'optim': 'ECL',\n",
       " 'categories': 2,\n",
       " 'periodicity': 1,\n",
       " 'layer': '[48-50-11]',\n",
       " 'clip_angle_value': 1000000}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = Task.init(\n",
    "    project_name=\"mlmvn\",\n",
    "    task_name=\"SDD-mlmvn-[48-50-11]\",\n",
    "    tags=[\"mlmvn\", \"SDD\", \"multiple_runs\", \"adjusted_loss\"],\n",
    ")\n",
    "writer = SummaryWriter()\n",
    "\n",
    "#  capture a dictionary of hyperparameters with config\n",
    "config_dict = {\n",
    "    \"learning_rate\": 1,\n",
    "    \"epochs\": epochs,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"optim\": \"ECL\",\n",
    "    \"categories\": categories,\n",
    "    \"periodicity\": periodicity,\n",
    "    \"layer\": \"[48-50-11]\",\n",
    "    \"loss\": \"ComplexMSE_adjusted_error\",\n",
    "}\n",
    "task.connect(config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10107/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-27 14:56:58,474 - clearml.frameworks - INFO - Found existing registered model id=bb96e63090904339bf87c4852d30bdb6 [/home/antonpfeifer/Documents/mlmvn/nbs/examples/autass/models/autass-mlmvn_48-50-11.pt] reusing it.\n",
      "Epoch 9 loss is 0.11677723785531834\n",
      "Epoch 19 loss is 0.08727784719556735\n",
      "Epoch 29 loss is 0.09157292581128637\n",
      "Epoch 39 loss is 0.07421681373324716\n",
      "Epoch 49 loss is 0.07697537707769428\n",
      "Epoch 59 loss is 0.06723158685548768\n",
      "Epoch 69 loss is 0.06324904770714807\n",
      "Epoch 79 loss is 0.0635766536591303\n",
      "Epoch 89 loss is 0.0689652033514836\n",
      "Epoch 99 loss is 0.09650615274908997\n",
      "Epoch 109 loss is 0.07453832805905608\n",
      "Epoch 119 loss is 0.07929171747710538\n",
      "Epoch 129 loss is 0.07981405980555767\n",
      "Epoch 139 loss is 0.09314429308579714\n",
      "Epoch 149 loss is 0.1007599468837455\n",
      "Epoch 159 loss is 0.1594258365172202\n",
      "Epoch 169 loss is 0.16438126926324473\n",
      "Epoch 179 loss is 0.1535026421169871\n",
      "Epoch 189 loss is 0.15247239398711698\n",
      "Epoch 199 loss is 0.1501105166766776\n",
      "Train Acc.:  0.9464609994231632\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      1063\n",
      "           1       0.95      0.92      0.93      1064\n",
      "           2       0.98      0.99      0.99      1064\n",
      "           3       0.98      0.98      0.98      1064\n",
      "           4       0.96      0.91      0.94      1064\n",
      "           5       0.94      0.93      0.93      1063\n",
      "           6       0.94      0.91      0.92      1064\n",
      "           7       1.00      1.00      1.00      1064\n",
      "           8       1.00      1.00      1.00      1064\n",
      "           9       0.96      0.93      0.94      1064\n",
      "          10       0.99      0.97      0.98      1064\n",
      "\n",
      "   micro avg       0.97      0.95      0.96     11702\n",
      "   macro avg       0.97      0.95      0.96     11702\n",
      "weighted avg       0.97      0.95      0.96     11702\n",
      " samples avg       0.95      0.95      0.95     11702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10107/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss is 0.10269231647718571\n",
      "Epoch 19 loss is 0.0828424365293163\n",
      "Epoch 29 loss is 0.0755315495091804\n",
      "Epoch 39 loss is 0.07214960396708685\n",
      "Epoch 49 loss is 0.06101909084585404\n",
      "Epoch 59 loss is 0.06839280821097835\n",
      "Epoch 69 loss is 0.0599125453507835\n",
      "Epoch 79 loss is 0.07335060013207284\n",
      "Epoch 89 loss is 0.07783843407293703\n",
      "Epoch 99 loss is 0.07579400460243982\n",
      "Epoch 109 loss is 0.08774453313883374\n"
     ]
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "list_losses = []\n",
    "list_scores = []\n",
    "list_acc = []\n",
    "list_loss = []\n",
    "list_f1 = []\n",
    "list_precision = []\n",
    "list_recall = []\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    model_dict: dict = {}\n",
    "    x_train, x_valid, y_train, y_valid = get_splitted_data_by_index(\n",
    "        X, y, neuronCats, train_index, test_index\n",
    "    )\n",
    "\n",
    "    model = Model(categories=categories, periodicity=periodicity)\n",
    "    criterion = ComplexMSE_adjusted_error.apply\n",
    "    optimizer = ECL(model.parameters(), lr=lr)\n",
    "\n",
    "    losses, scores = fit(\n",
    "        model,\n",
    "        x_train,\n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        categories=categories,\n",
    "        periodicity=periodicity,\n",
    "    )\n",
    "\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "    list_scores.append(scores)\n",
    "    list_losses.append(losses)\n",
    "\n",
    "    y_pred = model.predict(x_train)\n",
    "    acc = accuracy(y_pred.squeeze(), y_train)\n",
    "    print(\"Train Acc.: \", acc)\n",
    "\n",
    "    y_pred = model.predict(x_valid)\n",
    "    acc = accuracy(y_pred.squeeze(), y_valid)\n",
    "    list_acc.append(acc)\n",
    "\n",
    "    print(classification_report(y_valid, y_pred.detach().numpy(), zero_division=0))\n",
    "    list_f1.append(\n",
    "        f1_score(y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0)\n",
    "    )\n",
    "    list_precision.append(\n",
    "        precision_score(\n",
    "            y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0\n",
    "        )\n",
    "    )\n",
    "    list_recall.append(\n",
    "        recall_score(\n",
    "            y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0\n",
    "        )\n",
    "    )\n",
    "\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_accuracy_mean\",\n",
    "    value=np.mean(list_acc),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_accuracy_std\",\n",
    "    value=np.std(list_acc),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_f1_mean\",\n",
    "    value=np.mean(list_f1),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_f1_std\",\n",
    "    value=np.std(list_f1),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_precision_mean\",\n",
    "    value=np.mean(list_precision),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_precision_std\",\n",
    "    value=np.std(list_precision),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_recall_mean\",\n",
    "    value=np.mean(list_recall),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_recall_std\",\n",
    "    value=np.std(list_recall),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.mark_completed()\n",
    "task.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLMVN [48-100-11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = str(Path.cwd() / \"models/autass-mlmvn_48-100-11.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, categories, periodicity):\n",
    "        super().__init__()\n",
    "        self.categories = categories\n",
    "        self.periodicity = periodicity\n",
    "        self.first_linear = FirstLayer(48, 100)\n",
    "        self.phase_act1 = cmplx_phase_activation()\n",
    "        self.linear_out = OutputLayer(100, 11)\n",
    "        self.phase_act2 = cmplx_phase_activation()\n",
    "        # Hooks\n",
    "        self.first_layer_hook_handle = self.first_linear.register_full_backward_hook(\n",
    "            self.first_layer_backward_hook\n",
    "        )\n",
    "        self.output_hook_handle = self.linear_out.register_full_backward_hook(\n",
    "            self.output_layer_backward_hook\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first_linear(x)\n",
    "        x = self.phase_act1(x)\n",
    "        x = self.linear_out(x)\n",
    "        x = self.phase_act2(x)\n",
    "        return x\n",
    "\n",
    "    def first_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"first_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def hidden_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"hidden_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def output_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"output_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def angle2class(self, x: torch.tensor) -> torch.tensor:\n",
    "        tmp = x.angle() + 2 * np.pi\n",
    "        angle = torch.remainder(tmp, 2 * np.pi)\n",
    "\n",
    "        # This will be the discrete output (the number of sector)\n",
    "        o = torch.floor(self.categories * self.periodicity * angle / (2 * np.pi))\n",
    "        return torch.remainder(o, self.categories)\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Performs the prediction task of the network\n",
    "\n",
    "        Args:\n",
    "          x: torch.Tensor\n",
    "            Input tensor of size ([3])\n",
    "\n",
    "        Returns:\n",
    "          Most likely class i.e., Label with the highest score\n",
    "        \"\"\"\n",
    "        # Pass the data through the networks\n",
    "        output = self.forward(x)\n",
    "\n",
    "        # # Choose the label with the highest score\n",
    "        # return torch.argmax(output, 1)\n",
    "        return self.angle2class(output)\n",
    "\n",
    "\n",
    "def fit(model, X, y, epochs, batch_size, optimizer, criterion, categories, periodicity):\n",
    "    # List of losses for visualization\n",
    "    losses = []\n",
    "    scores = []\n",
    "    acc_best = 0\n",
    "\n",
    "    for i in range(epochs):\n",
    "        # Pass the data through the network and compute the loss\n",
    "        # We'll use the whole dataset during the training instead of using batches\n",
    "        # in to order to keep the code simple for now.\n",
    "\n",
    "        batch_loss = []\n",
    "\n",
    "        for j in range((X.shape[0] - 1) // batch_size + 1):\n",
    "            start_j = j * batch_size\n",
    "            end_j = start_j + batch_size\n",
    "            xb = X[start_j:end_j]\n",
    "            yb = y[start_j:end_j]\n",
    "\n",
    "            y_pred = model(xb)\n",
    "            loss = criterion(y_pred, yb, categories, periodicity)\n",
    "            batch_loss.append((torch.abs(loss)).detach().numpy())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step(inputs=xb, layers=list(model.children()))\n",
    "\n",
    "        losses.append(sum(batch_loss) / len(batch_loss))\n",
    "        if i % 10 == 9:\n",
    "            print(f\"Epoch {i} loss is {losses[-1]}\")\n",
    "        y_pred = model.predict(X)\n",
    "        scores.append(accuracy(y_pred.squeeze(), y))\n",
    "\n",
    "        if scores[-1] > acc_best:\n",
    "            acc_best = scores[-1]\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "    return losses, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=7b3abe9fb989495e892c444570be6067\n",
      "ClearML results page: http://194.94.231.172:8080/projects/cdefd6ee85454e49be01962ad715eca0/experiments/7b3abe9fb989495e892c444570be6067/output/log\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 1,\n",
       " 'epochs': 200,\n",
       " 'batch_size': 538,\n",
       " 'optim': 'ECL',\n",
       " 'categories': 2,\n",
       " 'periodicity': 1,\n",
       " 'layer': '[48-100-11]',\n",
       " 'clip_angle_value': 1000000}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = Task.init(\n",
    "    project_name=\"mlmvn\",\n",
    "    task_name=\"SDD-mlmvn-[48-100-11]\",\n",
    "    tags=[\"mlmvn\", \"SDD\", \"multiple_runs\", \"adjusted_loss\"],\n",
    ")\n",
    "writer = SummaryWriter()\n",
    "\n",
    "#  capture a dictionary of hyperparameters with config\n",
    "config_dict = {\n",
    "    \"learning_rate\": 1,\n",
    "    \"epochs\": epochs,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"optim\": \"ECL\",\n",
    "    \"categories\": categories,\n",
    "    \"periodicity\": periodicity,\n",
    "    \"layer\": \"[48-100-11]\",\n",
    "    \"loss\": \"ComplexMSE_adjusted_error\",\n",
    "}\n",
    "task.connect(config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2584/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-22 19:35:24,268 - clearml.frameworks - INFO - Found existing registered model id=0f73e6db01fc42988672e4f44c0add5f [/home/antonpfeifer/Documents/mlmvn/nbs/examples/autass/models/autass-mlmvn_48-100-11.pt] reusing it.\n",
      "Epoch 9 loss is 0.09364351451345408\n",
      "Epoch 19 loss is 0.06047805760727481\n",
      "Epoch 29 loss is 0.0578744128569904\n",
      "Epoch 39 loss is 0.04534195824524318\n",
      "Epoch 49 loss is 0.04307949224899972\n",
      "Epoch 59 loss is 0.041017087963280054\n",
      "Epoch 69 loss is 0.03752497958328672\n",
      "Epoch 79 loss is 0.03929154410570669\n",
      "Epoch 89 loss is 0.03530748449555099\n",
      "Epoch 99 loss is 0.03361906166904868\n",
      "Epoch 109 loss is 0.03500346362768258\n",
      "Epoch 119 loss is 0.03421256406705508\n",
      "Epoch 129 loss is 0.03967580897383263\n",
      "Epoch 139 loss is 0.03983386888202658\n",
      "Epoch 149 loss is 0.035099183909890475\n",
      "Epoch 159 loss is 0.039366477472969064\n",
      "Epoch 169 loss is 0.039393422961427775\n",
      "Epoch 179 loss is 0.03634864197734159\n",
      "Epoch 189 loss is 0.03297036735253193\n",
      "Epoch 199 loss is 0.03543338693745545\n",
      "Train Acc.:  0.9744477203777293\n",
      "Val Acc.:  0.9567632231051867\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98      1074\n",
      "           1       0.97      0.97      0.97      1089\n",
      "           2       0.99      0.98      0.99      1044\n",
      "           3       0.98      0.98      0.98      1048\n",
      "           4       0.95      0.96      0.95      1057\n",
      "           5       0.97      0.96      0.96      1072\n",
      "           6       0.95      0.95      0.95      1066\n",
      "           7       1.00      1.00      1.00      1103\n",
      "           8       1.00      1.00      1.00      1108\n",
      "           9       0.97      0.95      0.96      1030\n",
      "          10       0.99      0.96      0.97      1012\n",
      "\n",
      "   micro avg       0.98      0.97      0.97     11703\n",
      "   macro avg       0.98      0.97      0.97     11703\n",
      "weighted avg       0.98      0.97      0.97     11703\n",
      " samples avg       0.96      0.97      0.97     11703\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "list_losses = []\n",
    "list_scores = []\n",
    "list_acc = []\n",
    "list_loss = []\n",
    "list_f1 = []\n",
    "list_precision = []\n",
    "list_recall = []\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    model_dict: dict = {}\n",
    "    x_train, x_valid, y_train, y_valid = get_splitted_data_by_index(\n",
    "        X, y, neuronCats, train_index, test_index\n",
    "    )\n",
    "\n",
    "    model = Model(categories=categories, periodicity=periodicity)\n",
    "    criterion = ComplexMSE_adjusted_error.apply\n",
    "    optimizer = ECL(model.parameters(), lr=lr)\n",
    "\n",
    "    losses, scores = fit(\n",
    "        model,\n",
    "        x_train,\n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        categories=categories,\n",
    "        periodicity=periodicity,\n",
    "    )\n",
    "\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "    list_scores.append(scores)\n",
    "    list_losses.append(losses)\n",
    "\n",
    "    y_pred = model.predict(x_train)\n",
    "    acc = accuracy(y_pred.squeeze(), y_train)\n",
    "    print(\"Train Acc.: \", acc)\n",
    "\n",
    "    y_pred = model.predict(x_valid)\n",
    "    acc = accuracy(y_pred.squeeze(), y_valid)\n",
    "    list_acc.append(acc)\n",
    "\n",
    "    print(classification_report(y_valid, y_pred.detach().numpy(), zero_division=0))\n",
    "    list_f1.append(\n",
    "        f1_score(y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0)\n",
    "    )\n",
    "    list_precision.append(\n",
    "        precision_score(\n",
    "            y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0\n",
    "        )\n",
    "    )\n",
    "    list_recall.append(\n",
    "        recall_score(\n",
    "            y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0\n",
    "        )\n",
    "    )\n",
    "\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_accuracy_mean\",\n",
    "    value=np.mean(list_acc),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_accuracy_std\",\n",
    "    value=np.std(list_acc),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_f1_mean\",\n",
    "    value=np.mean(list_f1),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_f1_std\",\n",
    "    value=np.std(list_f1),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_precision_mean\",\n",
    "    value=np.mean(list_precision),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_precision_std\",\n",
    "    value=np.std(list_precision),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_recall_mean\",\n",
    "    value=np.mean(list_recall),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_recall_std\",\n",
    "    value=np.std(list_recall),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.mark_completed()\n",
    "task.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLMVN [48-10-10-11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = str(Path.cwd() / \"models/autass-mlmvn_48-10-10-11.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, categories, periodicity):\n",
    "        super().__init__()\n",
    "        self.categories = categories\n",
    "        self.periodicity = periodicity\n",
    "        self.first_linear = FirstLayer(48, 10)\n",
    "        self.phase_act1 = cmplx_phase_activation()\n",
    "        self.hidden_layer = HiddenLayer(10, 10)\n",
    "        self.phase_act2 = cmplx_phase_activation()\n",
    "        self.linear_out = OutputLayer(10, 11)\n",
    "        self.phase_act3 = cmplx_phase_activation()\n",
    "        # Hooks\n",
    "        self.first_layer_hook_handle = self.first_linear.register_full_backward_hook(\n",
    "            self.first_layer_backward_hook\n",
    "        )\n",
    "        self.hidden_layer_hook_handle = self.hidden_layer.register_full_backward_hook(\n",
    "            self.hidden_layer_backward_hook\n",
    "        )\n",
    "        self.output_hook_handle = self.linear_out.register_full_backward_hook(\n",
    "            self.output_layer_backward_hook\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first_linear(x)\n",
    "        x = self.phase_act1(x)\n",
    "        x = self.hidden_layer(x)\n",
    "        x = self.phase_act2(x)\n",
    "        x = self.linear_out(x)\n",
    "        x = self.phase_act3(x)\n",
    "        return x\n",
    "\n",
    "    def first_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"first_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def hidden_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"hidden_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def output_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"output_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def angle2class(self, x: torch.tensor) -> torch.tensor:\n",
    "        tmp = x.angle() + 2 * np.pi\n",
    "        angle = torch.remainder(tmp, 2 * np.pi)\n",
    "\n",
    "        # This will be the discrete output (the number of sector)\n",
    "        o = torch.floor(self.categories * self.periodicity * angle / (2 * np.pi))\n",
    "        return torch.remainder(o, self.categories)\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Performs the prediction task of the network\n",
    "\n",
    "        Args:\n",
    "          x: torch.Tensor\n",
    "            Input tensor of size ([3])\n",
    "\n",
    "        Returns:\n",
    "          Most likely class i.e., Label with the highest score\n",
    "        \"\"\"\n",
    "        # Pass the data through the networks\n",
    "        output = self.forward(x)\n",
    "\n",
    "        # # Choose the label with the highest score\n",
    "        # return torch.argmax(output, 1)\n",
    "        return self.angle2class(output)\n",
    "\n",
    "\n",
    "def fit(model, X, y, epochs, batch_size, optimizer, criterion, categories, periodicity):\n",
    "    # List of losses for visualization\n",
    "    losses = []\n",
    "    scores = []\n",
    "    acc_best = 0\n",
    "\n",
    "    for i in range(epochs):\n",
    "        # Pass the data through the network and compute the loss\n",
    "        # We'll use the whole dataset during the training instead of using batches\n",
    "        # in to order to keep the code simple for now.\n",
    "\n",
    "        batch_loss = []\n",
    "\n",
    "        for j in range((X.shape[0] - 1) // batch_size + 1):\n",
    "            start_j = j * batch_size\n",
    "            end_j = start_j + batch_size\n",
    "            xb = X[start_j:end_j]\n",
    "            yb = y[start_j:end_j]\n",
    "\n",
    "            y_pred = model(xb)\n",
    "            loss = criterion(y_pred, yb, categories, periodicity)\n",
    "            batch_loss.append((torch.abs(loss)).detach().numpy())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step(inputs=xb, layers=list(model.children()))\n",
    "\n",
    "        losses.append(sum(batch_loss) / len(batch_loss))\n",
    "        if i % 10 == 9:\n",
    "            print(f\"Epoch {i} loss is {losses[-1]}\")\n",
    "        y_pred = model.predict(X)\n",
    "        scores.append(accuracy(y_pred.squeeze(), y))\n",
    "\n",
    "        if scores[-1] > acc_best:\n",
    "            acc_best = scores[-1]\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "    return losses, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=9f8e1bb1a8ce4055b17fd15ff8f5f96e\n",
      "ClearML results page: http://194.94.231.172:8080/projects/cdefd6ee85454e49be01962ad715eca0/experiments/9f8e1bb1a8ce4055b17fd15ff8f5f96e/output/log\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 1,\n",
       " 'epochs': 200,\n",
       " 'batch_size': 538,\n",
       " 'optim': 'ECL',\n",
       " 'categories': 2,\n",
       " 'periodicity': 1,\n",
       " 'layer': '[48-10-10-11]',\n",
       " 'clip_angle_value': 1000000}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = Task.init(\n",
    "    project_name=\"mlmvn\",\n",
    "    task_name=\"SDD-mlmvn-[48-10-10-11]\",\n",
    "    tags=[\"mlmvn\", \"SDD\", \"multiple_runs\", \"adjusted_loss\"],\n",
    ")\n",
    "writer = SummaryWriter()\n",
    "\n",
    "#  capture a dictionary of hyperparameters with config\n",
    "config_dict = {\n",
    "    \"learning_rate\": 1,\n",
    "    \"epochs\": epochs,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"optim\": \"ECL\",\n",
    "    \"categories\": categories,\n",
    "    \"periodicity\": periodicity,\n",
    "    \"layer\": \"[48-10-10-11]\",\n",
    "    \"loss\": \"ComplexMSE_adjusted_error\",\n",
    "}\n",
    "task.connect(config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2584/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-22 19:47:37,678 - clearml.frameworks - INFO - Found existing registered model id=410edb2915b24269b7d34f2e38593dff [/home/antonpfeifer/Documents/mlmvn/nbs/examples/autass/models/autass-mlmvn_48-10-10-11.pt] reusing it.\n",
      "Epoch 9 loss is 0.3190616793468566\n",
      "Epoch 19 loss is 0.3316516310882961\n",
      "Epoch 29 loss is 0.3159845589401083\n",
      "Epoch 39 loss is 0.2897936458677712\n",
      "Epoch 49 loss is 0.29438441483606387\n",
      "Epoch 59 loss is 0.29755967444288156\n",
      "Epoch 69 loss is 0.2976103369922987\n",
      "Epoch 79 loss is 0.3521991805852908\n",
      "Epoch 89 loss is 0.3175364303332033\n",
      "Epoch 99 loss is 0.3012195794930889\n",
      "Epoch 109 loss is 0.3188232513425489\n",
      "Epoch 119 loss is 0.32362149784936967\n",
      "Epoch 129 loss is 0.3005814172908205\n",
      "Epoch 139 loss is 0.2813095426634295\n",
      "Epoch 149 loss is 0.26490572151648945\n",
      "Epoch 159 loss is 0.311720634966309\n",
      "Epoch 169 loss is 0.2963948818829981\n",
      "Epoch 179 loss is 0.2921389037327001\n",
      "Epoch 189 loss is 0.3533133125418626\n",
      "Epoch 199 loss is 0.3518870098072943\n",
      "Train Acc.:  0.7671666025723198\n",
      "Val Acc.:  0.7652738614030591\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88      1074\n",
      "           1       0.86      0.83      0.84      1089\n",
      "           2       0.94      0.84      0.89      1044\n",
      "           3       0.92      0.76      0.84      1048\n",
      "           4       0.88      0.49      0.63      1057\n",
      "           5       0.80      0.86      0.83      1072\n",
      "           6       0.76      0.53      0.63      1066\n",
      "           7       0.99      0.99      0.99      1103\n",
      "           8       1.00      1.00      1.00      1108\n",
      "           9       0.84      0.75      0.79      1030\n",
      "          10       0.70      0.91      0.79      1012\n",
      "\n",
      "   micro avg       0.87      0.81      0.84     11703\n",
      "   macro avg       0.87      0.81      0.83     11703\n",
      "weighted avg       0.87      0.81      0.83     11703\n",
      " samples avg       0.79      0.81      0.79     11703\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "list_losses = []\n",
    "list_scores = []\n",
    "list_acc = []\n",
    "list_loss = []\n",
    "list_f1 = []\n",
    "list_precision = []\n",
    "list_recall = []\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    model_dict: dict = {}\n",
    "    x_train, x_valid, y_train, y_valid = get_splitted_data_by_index(\n",
    "        X, y, neuronCats, train_index, test_index\n",
    "    )\n",
    "\n",
    "    model = Model(categories=categories, periodicity=periodicity)\n",
    "    criterion = ComplexMSE_adjusted_error.apply\n",
    "    optimizer = ECL(model.parameters(), lr=lr)\n",
    "\n",
    "    losses, scores = fit(\n",
    "        model,\n",
    "        x_train,\n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        categories=categories,\n",
    "        periodicity=periodicity,\n",
    "    )\n",
    "\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "    list_scores.append(scores)\n",
    "    list_losses.append(losses)\n",
    "\n",
    "    y_pred = model.predict(x_train)\n",
    "    acc = accuracy(y_pred.squeeze(), y_train)\n",
    "    print(\"Train Acc.: \", acc)\n",
    "\n",
    "    y_pred = model.predict(x_valid)\n",
    "    acc = accuracy(y_pred.squeeze(), y_valid)\n",
    "    list_acc.append(acc)\n",
    "\n",
    "    print(classification_report(y_valid, y_pred.detach().numpy(), zero_division=0))\n",
    "    list_f1.append(\n",
    "        f1_score(y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0)\n",
    "    )\n",
    "    list_precision.append(\n",
    "        precision_score(\n",
    "            y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0\n",
    "        )\n",
    "    )\n",
    "    list_recall.append(\n",
    "        recall_score(\n",
    "            y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0\n",
    "        )\n",
    "    )\n",
    "\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_accuracy_mean\",\n",
    "    value=np.mean(list_acc),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_accuracy_std\",\n",
    "    value=np.std(list_acc),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_f1_mean\",\n",
    "    value=np.mean(list_f1),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_f1_std\",\n",
    "    value=np.std(list_f1),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_precision_mean\",\n",
    "    value=np.mean(list_precision),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_precision_std\",\n",
    "    value=np.std(list_precision),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_recall_mean\",\n",
    "    value=np.mean(list_recall),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_recall_std\",\n",
    "    value=np.std(list_recall),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.mark_completed()\n",
    "task.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLMVN [48-20-20-11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = str(Path.cwd() / \"models/autass-mlmvn_48-20-20-11.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, categories, periodicity):\n",
    "        super().__init__()\n",
    "        self.categories = categories\n",
    "        self.periodicity = periodicity\n",
    "        self.first_linear = FirstLayer(48, 20)\n",
    "        self.phase_act1 = cmplx_phase_activation()\n",
    "        self.hidden_layer = HiddenLayer(20, 20)\n",
    "        self.phase_act2 = cmplx_phase_activation()\n",
    "        self.linear_out = OutputLayer(20, 11)\n",
    "        self.phase_act3 = cmplx_phase_activation()\n",
    "        # Hooks\n",
    "        self.first_layer_hook_handle = self.first_linear.register_full_backward_hook(\n",
    "            self.first_layer_backward_hook\n",
    "        )\n",
    "        self.hidden_layer_hook_handle = self.hidden_layer.register_full_backward_hook(\n",
    "            self.hidden_layer_backward_hook\n",
    "        )\n",
    "        self.output_hook_handle = self.linear_out.register_full_backward_hook(\n",
    "            self.output_layer_backward_hook\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first_linear(x)\n",
    "        x = self.phase_act1(x)\n",
    "        x = self.hidden_layer(x)\n",
    "        x = self.phase_act2(x)\n",
    "        x = self.linear_out(x)\n",
    "        x = self.phase_act3(x)\n",
    "        return x\n",
    "\n",
    "    def first_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"first_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def hidden_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"hidden_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def output_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"output_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def angle2class(self, x: torch.tensor) -> torch.tensor:\n",
    "        tmp = x.angle() + 2 * np.pi\n",
    "        angle = torch.remainder(tmp, 2 * np.pi)\n",
    "\n",
    "        # This will be the discrete output (the number of sector)\n",
    "        o = torch.floor(self.categories * self.periodicity * angle / (2 * np.pi))\n",
    "        return torch.remainder(o, self.categories)\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Performs the prediction task of the network\n",
    "\n",
    "        Args:\n",
    "          x: torch.Tensor\n",
    "            Input tensor of size ([3])\n",
    "\n",
    "        Returns:\n",
    "          Most likely class i.e., Label with the highest score\n",
    "        \"\"\"\n",
    "        # Pass the data through the networks\n",
    "        output = self.forward(x)\n",
    "\n",
    "        # # Choose the label with the highest score\n",
    "        # return torch.argmax(output, 1)\n",
    "        return self.angle2class(output)\n",
    "\n",
    "\n",
    "def fit(model, X, y, epochs, batch_size, optimizer, criterion, categories, periodicity):\n",
    "    # List of losses for visualization\n",
    "    losses = []\n",
    "    scores = []\n",
    "    acc_best = 0\n",
    "\n",
    "    for i in range(epochs):\n",
    "        # Pass the data through the network and compute the loss\n",
    "        # We'll use the whole dataset during the training instead of using batches\n",
    "        # in to order to keep the code simple for now.\n",
    "\n",
    "        batch_loss = []\n",
    "\n",
    "        for j in range((X.shape[0] - 1) // batch_size + 1):\n",
    "            start_j = j * batch_size\n",
    "            end_j = start_j + batch_size\n",
    "            xb = X[start_j:end_j]\n",
    "            yb = y[start_j:end_j]\n",
    "\n",
    "            y_pred = model(xb)\n",
    "            loss = criterion(y_pred, yb, categories, periodicity)\n",
    "            batch_loss.append((torch.abs(loss)).detach().numpy())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step(inputs=xb, layers=list(model.children()))\n",
    "\n",
    "        losses.append(sum(batch_loss) / len(batch_loss))\n",
    "        if i % 10 == 9:\n",
    "            print(f\"Epoch {i} loss is {losses[-1]}\")\n",
    "        y_pred = model.predict(X)\n",
    "        scores.append(accuracy(y_pred.squeeze(), y))\n",
    "\n",
    "        if scores[-1] > acc_best:\n",
    "            acc_best = scores[-1]\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "    return losses, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=1b1a786365114896aa361f7567b2a590\n",
      "ClearML results page: http://194.94.231.172:8080/projects/cdefd6ee85454e49be01962ad715eca0/experiments/1b1a786365114896aa361f7567b2a590/output/log\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 1,\n",
       " 'epochs': 200,\n",
       " 'batch_size': 538,\n",
       " 'optim': 'ECL',\n",
       " 'categories': 2,\n",
       " 'periodicity': 1,\n",
       " 'layer': '[48-20-20-11]',\n",
       " 'clip_angle_value': 1000000}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = Task.init(\n",
    "    project_name=\"mlmvn\",\n",
    "    task_name=\"SDD-mlmvn-[48-20-20-11]\",\n",
    "    tags=[\"mlmvn\", \"SDD\", \"multiple_runs\", \"adjusted_loss\"],\n",
    ")\n",
    "writer = SummaryWriter()\n",
    "\n",
    "#  capture a dictionary of hyperparameters with config\n",
    "config_dict = {\n",
    "    \"learning_rate\": 1,\n",
    "    \"epochs\": epochs,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"optim\": \"ECL\",\n",
    "    \"categories\": categories,\n",
    "    \"periodicity\": periodicity,\n",
    "    \"layer\": \"[48-20-20-11]\",\n",
    "    \"loss\": \"ComplexMSE_adjusted_error\",\n",
    "}\n",
    "task.connect(config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2584/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-22 19:56:38,160 - clearml.frameworks - INFO - Found existing registered model id=22ba5a4169ed406a9e74f40200bd29a1 [/home/antonpfeifer/Documents/mlmvn/nbs/examples/autass/models/autass-mlmvn_48-20-20-11.pt] reusing it.\n",
      "Epoch 9 loss is 0.22423453263455123\n",
      "Epoch 19 loss is 0.2417288273187978\n",
      "Epoch 29 loss is 0.24098897281491427\n",
      "Epoch 39 loss is 0.25785384004717277\n",
      "Epoch 49 loss is 0.20411375730867218\n",
      "Epoch 59 loss is 0.19907421010282828\n",
      "Epoch 69 loss is 0.21536965079441342\n",
      "Epoch 79 loss is 0.21283156041274492\n",
      "Epoch 89 loss is 0.20860426362519324\n",
      "Epoch 99 loss is 0.1986070523113828\n",
      "Epoch 109 loss is 0.21692347488143257\n",
      "Epoch 119 loss is 0.23349276288092297\n",
      "Epoch 129 loss is 0.21625116723365828\n",
      "Epoch 139 loss is 0.23410189520133975\n",
      "Epoch 149 loss is 0.23888556577670042\n",
      "Epoch 159 loss is 0.23277480097426984\n",
      "Epoch 169 loss is 0.20190034595150705\n",
      "Epoch 179 loss is 0.20968810270215624\n",
      "Epoch 189 loss is 0.2009444427805874\n",
      "Epoch 199 loss is 0.2018091584845151\n",
      "Train Acc.:  0.8408537367004231\n",
      "Val Acc.:  0.8437152866786294\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92      1074\n",
      "           1       0.88      0.87      0.88      1089\n",
      "           2       0.93      0.88      0.90      1044\n",
      "           3       0.94      0.94      0.94      1048\n",
      "           4       0.88      0.66      0.75      1057\n",
      "           5       0.90      0.87      0.88      1072\n",
      "           6       0.81      0.65      0.72      1066\n",
      "           7       1.00      1.00      1.00      1103\n",
      "           8       1.00      1.00      1.00      1108\n",
      "           9       0.86      0.87      0.86      1030\n",
      "          10       0.90      0.85      0.87      1012\n",
      "\n",
      "   micro avg       0.91      0.87      0.89     11703\n",
      "   macro avg       0.91      0.87      0.88     11703\n",
      "weighted avg       0.91      0.87      0.89     11703\n",
      " samples avg       0.86      0.87      0.86     11703\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "list_losses = []\n",
    "list_scores = []\n",
    "list_acc = []\n",
    "list_loss = []\n",
    "list_f1 = []\n",
    "list_precision = []\n",
    "list_recall = []\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    model_dict: dict = {}\n",
    "    x_train, x_valid, y_train, y_valid = get_splitted_data_by_index(\n",
    "        X, y, neuronCats, train_index, test_index\n",
    "    )\n",
    "\n",
    "    model = Model(categories=categories, periodicity=periodicity)\n",
    "    criterion = ComplexMSE_adjusted_error.apply\n",
    "    optimizer = ECL(model.parameters(), lr=lr)\n",
    "\n",
    "    losses, scores = fit(\n",
    "        model,\n",
    "        x_train,\n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        categories=categories,\n",
    "        periodicity=periodicity,\n",
    "    )\n",
    "\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "    list_scores.append(scores)\n",
    "    list_losses.append(losses)\n",
    "\n",
    "    y_pred = model.predict(x_train)\n",
    "    acc = accuracy(y_pred.squeeze(), y_train)\n",
    "    print(\"Train Acc.: \", acc)\n",
    "\n",
    "    y_pred = model.predict(x_valid)\n",
    "    acc = accuracy(y_pred.squeeze(), y_valid)\n",
    "    list_acc.append(acc)\n",
    "\n",
    "    print(classification_report(y_valid, y_pred.detach().numpy(), zero_division=0))\n",
    "    list_f1.append(\n",
    "        f1_score(y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0)\n",
    "    )\n",
    "    list_precision.append(\n",
    "        precision_score(\n",
    "            y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0\n",
    "        )\n",
    "    )\n",
    "    list_recall.append(\n",
    "        recall_score(\n",
    "            y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0\n",
    "        )\n",
    "    )\n",
    "\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_accuracy_mean\",\n",
    "    value=np.mean(list_acc),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_accuracy_std\",\n",
    "    value=np.std(list_acc),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_f1_mean\",\n",
    "    value=np.mean(list_f1),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_f1_std\",\n",
    "    value=np.std(list_f1),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_precision_mean\",\n",
    "    value=np.mean(list_precision),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_precision_std\",\n",
    "    value=np.std(list_precision),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_recall_mean\",\n",
    "    value=np.mean(list_recall),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_recall_std\",\n",
    "    value=np.std(list_recall),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.mark_completed()\n",
    "task.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLMVN [48-50-50-11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = str(Path.cwd() / \"models/autass-mlmvn_48-50-50-11.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, categories, periodicity):\n",
    "        super().__init__()\n",
    "        self.categories = categories\n",
    "        self.periodicity = periodicity\n",
    "        self.first_linear = FirstLayer(48, 50)\n",
    "        self.phase_act1 = cmplx_phase_activation()\n",
    "        self.hidden_layer = HiddenLayer(50, 50)\n",
    "        self.phase_act2 = cmplx_phase_activation()\n",
    "        self.linear_out = OutputLayer(50, 11)\n",
    "        self.phase_act3 = cmplx_phase_activation()\n",
    "        # Hooks\n",
    "        self.first_layer_hook_handle = self.first_linear.register_full_backward_hook(\n",
    "            self.first_layer_backward_hook\n",
    "        )\n",
    "        self.hidden_layer_hook_handle = self.hidden_layer.register_full_backward_hook(\n",
    "            self.hidden_layer_backward_hook\n",
    "        )\n",
    "        self.output_hook_handle = self.linear_out.register_full_backward_hook(\n",
    "            self.output_layer_backward_hook\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first_linear(x)\n",
    "        x = self.phase_act1(x)\n",
    "        x = self.hidden_layer(x)\n",
    "        x = self.phase_act2(x)\n",
    "        x = self.linear_out(x)\n",
    "        x = self.phase_act3(x)\n",
    "        return x\n",
    "\n",
    "    def first_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"first_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def hidden_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"hidden_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def output_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"output_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def angle2class(self, x: torch.tensor) -> torch.tensor:\n",
    "        tmp = x.angle() + 2 * np.pi\n",
    "        angle = torch.remainder(tmp, 2 * np.pi)\n",
    "\n",
    "        # This will be the discrete output (the number of sector)\n",
    "        o = torch.floor(self.categories * self.periodicity * angle / (2 * np.pi))\n",
    "        return torch.remainder(o, self.categories)\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Performs the prediction task of the network\n",
    "\n",
    "        Args:\n",
    "          x: torch.Tensor\n",
    "            Input tensor of size ([3])\n",
    "\n",
    "        Returns:\n",
    "          Most likely class i.e., Label with the highest score\n",
    "        \"\"\"\n",
    "        # Pass the data through the networks\n",
    "        output = self.forward(x)\n",
    "\n",
    "        # # Choose the label with the highest score\n",
    "        # return torch.argmax(output, 1)\n",
    "        return self.angle2class(output)\n",
    "\n",
    "\n",
    "def fit(model, X, y, epochs, batch_size, optimizer, criterion, categories, periodicity):\n",
    "    # List of losses for visualization\n",
    "    losses = []\n",
    "    scores = []\n",
    "    acc_best = 0\n",
    "\n",
    "    for i in range(epochs):\n",
    "        # Pass the data through the network and compute the loss\n",
    "        # We'll use the whole dataset during the training instead of using batches\n",
    "        # in to order to keep the code simple for now.\n",
    "\n",
    "        batch_loss = []\n",
    "\n",
    "        for j in range((X.shape[0] - 1) // batch_size + 1):\n",
    "            start_j = j * batch_size\n",
    "            end_j = start_j + batch_size\n",
    "            xb = X[start_j:end_j]\n",
    "            yb = y[start_j:end_j]\n",
    "\n",
    "            y_pred = model(xb)\n",
    "            loss = criterion(y_pred, yb, categories, periodicity)\n",
    "            batch_loss.append((torch.abs(loss)).detach().numpy())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step(inputs=xb, layers=list(model.children()))\n",
    "\n",
    "        losses.append(sum(batch_loss) / len(batch_loss))\n",
    "        if i % 10 == 9:\n",
    "            print(f\"Epoch {i} loss is {losses[-1]}\")\n",
    "        y_pred = model.predict(X)\n",
    "        scores.append(accuracy(y_pred.squeeze(), y))\n",
    "\n",
    "        if scores[-1] > acc_best:\n",
    "            acc_best = scores[-1]\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "    return losses, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=88a9a42920894ee480fda889218b6295\n",
      "ClearML results page: http://194.94.231.172:8080/projects/cdefd6ee85454e49be01962ad715eca0/experiments/88a9a42920894ee480fda889218b6295/output/log\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 1,\n",
       " 'epochs': 200,\n",
       " 'batch_size': 538,\n",
       " 'optim': 'ECL',\n",
       " 'categories': 2,\n",
       " 'periodicity': 1,\n",
       " 'layer': '[48-50-50-11]',\n",
       " 'clip_angle_value': 1000000}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = Task.init(\n",
    "    project_name=\"mlmvn\",\n",
    "    task_name=\"SDD-mlmvn-[48-50-50-11]\",\n",
    "    tags=[\"mlmvn\", \"SDD\", \"multiple_runs\", \"adjusted_loss\"],\n",
    ")\n",
    "writer = SummaryWriter()\n",
    "\n",
    "#  capture a dictionary of hyperparameters with config\n",
    "config_dict = {\n",
    "    \"learning_rate\": 1,\n",
    "    \"epochs\": epochs,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"optim\": \"ECL\",\n",
    "    \"categories\": categories,\n",
    "    \"periodicity\": periodicity,\n",
    "    \"layer\": \"[48-50-50-11]\",\n",
    "    \"loss\": \"ComplexMSE_adjusted_error\",\n",
    "}\n",
    "task.connect(config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2584/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-22 20:06:38,774 - clearml.frameworks - INFO - Found existing registered model id=f13061c5d03a4e96b788becd5e54443a [/home/antonpfeifer/Documents/mlmvn/nbs/examples/autass/models/autass-mlmvn_48-50-50-11.pt] reusing it.\n",
      "Epoch 9 loss is 0.12497814221423068\n",
      "Epoch 19 loss is 0.11329098739263005\n",
      "Epoch 29 loss is 0.1134584198279062\n",
      "Epoch 39 loss is 0.10747780190630066\n",
      "Epoch 49 loss is 0.10495547213762008\n",
      "Epoch 59 loss is 0.10659716730495539\n",
      "Epoch 69 loss is 0.09905256375984144\n",
      "Epoch 79 loss is 0.09258128419659628\n",
      "Epoch 89 loss is 0.08945538147457059\n",
      "Epoch 99 loss is 0.10534673199439117\n",
      "Epoch 109 loss is 0.09873397783198988\n",
      "Epoch 119 loss is 0.0957623519177352\n",
      "Epoch 129 loss is 0.1089078274844085\n",
      "Epoch 139 loss is 0.10761467200030443\n",
      "Epoch 149 loss is 0.0974923953101792\n",
      "Epoch 159 loss is 0.10399220587872246\n",
      "Epoch 169 loss is 0.11563031956286923\n",
      "Epoch 179 loss is 0.1356005221774724\n",
      "Epoch 189 loss is 0.11880395204472788\n",
      "Epoch 199 loss is 0.11979121066603561\n",
      "Train Acc.:  0.934709225312994\n",
      "Val Acc.:  0.9241220199948731\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1074\n",
      "           1       0.93      0.90      0.91      1089\n",
      "           2       0.99      0.97      0.98      1044\n",
      "           3       0.98      0.97      0.97      1048\n",
      "           4       0.94      0.89      0.92      1057\n",
      "           5       0.90      0.90      0.90      1072\n",
      "           6       0.89      0.87      0.88      1066\n",
      "           7       1.00      1.00      1.00      1103\n",
      "           8       1.00      1.00      1.00      1108\n",
      "           9       0.90      0.91      0.91      1030\n",
      "          10       0.98      0.95      0.96      1012\n",
      "\n",
      "   micro avg       0.95      0.94      0.95     11703\n",
      "   macro avg       0.95      0.94      0.95     11703\n",
      "weighted avg       0.95      0.94      0.95     11703\n",
      " samples avg       0.93      0.94      0.93     11703\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "list_losses = []\n",
    "list_scores = []\n",
    "list_acc = []\n",
    "list_loss = []\n",
    "list_f1 = []\n",
    "list_precision = []\n",
    "list_recall = []\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    model_dict: dict = {}\n",
    "    x_train, x_valid, y_train, y_valid = get_splitted_data_by_index(\n",
    "        X, y, neuronCats, train_index, test_index\n",
    "    )\n",
    "\n",
    "    model = Model(categories=categories, periodicity=periodicity)\n",
    "    criterion = ComplexMSE_adjusted_error.apply\n",
    "    optimizer = ECL(model.parameters(), lr=lr)\n",
    "\n",
    "    losses, scores = fit(\n",
    "        model,\n",
    "        x_train,\n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        categories=categories,\n",
    "        periodicity=periodicity,\n",
    "    )\n",
    "\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "    list_scores.append(scores)\n",
    "    list_losses.append(losses)\n",
    "\n",
    "    y_pred = model.predict(x_train)\n",
    "    acc = accuracy(y_pred.squeeze(), y_train)\n",
    "    print(\"Train Acc.: \", acc)\n",
    "\n",
    "    y_pred = model.predict(x_valid)\n",
    "    acc = accuracy(y_pred.squeeze(), y_valid)\n",
    "    list_acc.append(acc)\n",
    "\n",
    "    print(classification_report(y_valid, y_pred.detach().numpy(), zero_division=0))\n",
    "    list_f1.append(\n",
    "        f1_score(y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0)\n",
    "    )\n",
    "    list_precision.append(\n",
    "        precision_score(\n",
    "            y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0\n",
    "        )\n",
    "    )\n",
    "    list_recall.append(\n",
    "        recall_score(\n",
    "            y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0\n",
    "        )\n",
    "    )\n",
    "\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_accuracy_mean\",\n",
    "    value=np.mean(list_acc),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_accuracy_std\",\n",
    "    value=np.std(list_acc),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_f1_mean\",\n",
    "    value=np.mean(list_f1),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_f1_std\",\n",
    "    value=np.std(list_f1),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_precision_mean\",\n",
    "    value=np.mean(list_precision),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_precision_std\",\n",
    "    value=np.std(list_precision),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_recall_mean\",\n",
    "    value=np.mean(list_recall),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_recall_std\",\n",
    "    value=np.std(list_recall),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.mark_completed()\n",
    "task.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLMVN [48-100-100-11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = str(Path.cwd() / \"models/autass-mlmvn_48-100-100-11.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, categories, periodicity):\n",
    "        super().__init__()\n",
    "        self.categories = categories\n",
    "        self.periodicity = periodicity\n",
    "        self.first_linear = FirstLayer(48, 100)\n",
    "        self.phase_act1 = cmplx_phase_activation()\n",
    "        self.hidden_layer = HiddenLayer(100, 100)\n",
    "        self.phase_act2 = cmplx_phase_activation()\n",
    "        self.linear_out = OutputLayer(100, 11)\n",
    "        self.phase_act3 = cmplx_phase_activation()\n",
    "        # Hooks\n",
    "        self.first_layer_hook_handle = self.first_linear.register_full_backward_hook(\n",
    "            self.first_layer_backward_hook\n",
    "        )\n",
    "        self.hidden_layer_hook_handle = self.hidden_layer.register_full_backward_hook(\n",
    "            self.hidden_layer_backward_hook\n",
    "        )\n",
    "        self.output_hook_handle = self.linear_out.register_full_backward_hook(\n",
    "            self.output_layer_backward_hook\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first_linear(x)\n",
    "        x = self.phase_act1(x)\n",
    "        x = self.hidden_layer(x)\n",
    "        x = self.phase_act2(x)\n",
    "        x = self.linear_out(x)\n",
    "        x = self.phase_act3(x)\n",
    "        return x\n",
    "\n",
    "    def first_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"first_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def hidden_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"hidden_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def output_layer_backward_hook(self, module, grad_input, grad_output):\n",
    "        fc_hook(\"output_layer\", module, grad_input, grad_output)\n",
    "\n",
    "    def angle2class(self, x: torch.tensor) -> torch.tensor:\n",
    "        tmp = x.angle() + 2 * np.pi\n",
    "        angle = torch.remainder(tmp, 2 * np.pi)\n",
    "\n",
    "        # This will be the discrete output (the number of sector)\n",
    "        o = torch.floor(self.categories * self.periodicity * angle / (2 * np.pi))\n",
    "        return torch.remainder(o, self.categories)\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Performs the prediction task of the network\n",
    "\n",
    "        Args:\n",
    "          x: torch.Tensor\n",
    "            Input tensor of size ([3])\n",
    "\n",
    "        Returns:\n",
    "          Most likely class i.e., Label with the highest score\n",
    "        \"\"\"\n",
    "        # Pass the data through the networks\n",
    "        output = self.forward(x)\n",
    "\n",
    "        # # Choose the label with the highest score\n",
    "        # return torch.argmax(output, 1)\n",
    "        return self.angle2class(output)\n",
    "\n",
    "\n",
    "def fit(model, X, y, epochs, batch_size, optimizer, criterion, categories, periodicity):\n",
    "    # List of losses for visualization\n",
    "    losses = []\n",
    "    scores = []\n",
    "    acc_best = 0\n",
    "\n",
    "    for i in range(epochs):\n",
    "        # Pass the data through the network and compute the loss\n",
    "        # We'll use the whole dataset during the training instead of using batches\n",
    "        # in to order to keep the code simple for now.\n",
    "\n",
    "        batch_loss = []\n",
    "\n",
    "        for j in range((X.shape[0] - 1) // batch_size + 1):\n",
    "            start_j = j * batch_size\n",
    "            end_j = start_j + batch_size\n",
    "            xb = X[start_j:end_j]\n",
    "            yb = y[start_j:end_j]\n",
    "\n",
    "            y_pred = model(xb)\n",
    "            loss = criterion(y_pred, yb, categories, periodicity)\n",
    "            batch_loss.append((torch.abs(loss)).detach().numpy())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step(inputs=xb, layers=list(model.children()))\n",
    "\n",
    "        losses.append(sum(batch_loss) / len(batch_loss))\n",
    "        if i % 10 == 9:\n",
    "            print(f\"Epoch {i} loss is {losses[-1]}\")\n",
    "        y_pred = model.predict(X)\n",
    "        scores.append(accuracy(y_pred.squeeze(), y))\n",
    "\n",
    "        if scores[-1] > acc_best:\n",
    "            acc_best = scores[-1]\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "    return losses, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=d9b3caa55d294da8b5913a5161413f86\n",
      "ClearML results page: http://194.94.231.172:8080/projects/cdefd6ee85454e49be01962ad715eca0/experiments/d9b3caa55d294da8b5913a5161413f86/output/log\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 1,\n",
       " 'epochs': 200,\n",
       " 'batch_size': 538,\n",
       " 'optim': 'ECL',\n",
       " 'categories': 2,\n",
       " 'periodicity': 1,\n",
       " 'layer': '[48-100-100-11]',\n",
       " 'clip_angle_value': 1000000}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = Task.init(\n",
    "    project_name=\"mlmvn\",\n",
    "    task_name=\"SDD-mlmvn-[48-100-100-11]\",\n",
    "    tags=[\"mlmvn\", \"SDD\", \"multiple_runs\", \"adjusted_loss\"],\n",
    ")\n",
    "writer = SummaryWriter()\n",
    "\n",
    "#  capture a dictionary of hyperparameters with config\n",
    "config_dict = {\n",
    "    \"learning_rate\": lr,\n",
    "    \"epochs\": epochs,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"optim\": \"ECL\",\n",
    "    \"categories\": categories,\n",
    "    \"periodicity\": periodicity,\n",
    "    \"layer\": \"[48-100-100-11]\",\n",
    "    \"loss\": \"ComplexMSE_adjusted_error\",\n",
    "}\n",
    "task.connect(config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2584/161459083.py:46: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-22 20:18:40,249 - clearml.frameworks - INFO - Found existing registered model id=bbd65d869dea4025af46d264d3c7bdee [/home/antonpfeifer/Documents/mlmvn/nbs/examples/autass/models/autass-mlmvn_48-100-100-11.pt] reusing it.\n",
      "Epoch 9 loss is 0.13289887250103694\n",
      "Epoch 19 loss is 0.0969205175520467\n",
      "Epoch 29 loss is 0.0876257468319937\n",
      "Epoch 39 loss is 0.09244551632670642\n",
      "Epoch 49 loss is 0.06913963450583839\n",
      "Epoch 59 loss is 0.05862448278693276\n",
      "Epoch 69 loss is 0.06090114262274447\n",
      "Epoch 79 loss is 0.05708236092705054\n",
      "Epoch 89 loss is 0.056327734121452935\n",
      "Epoch 99 loss is 0.058758856743251306\n",
      "Epoch 109 loss is 0.05308146111475717\n",
      "Epoch 119 loss is 0.05663969716960362\n",
      "Epoch 129 loss is 0.050931966043855297\n",
      "Epoch 139 loss is 0.0470478870489573\n",
      "Epoch 149 loss is 0.04390343749136136\n",
      "Epoch 159 loss is 0.0413619943037058\n",
      "Epoch 169 loss is 0.04258073464153097\n",
      "Epoch 179 loss is 0.044157359217192584\n",
      "Epoch 189 loss is 0.04075450701217185\n",
      "Epoch 199 loss is 0.03822650540962055\n",
      "Train Acc.:  0.9713711917275563\n",
      "Val Acc.:  0.9542852260104246\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98      1074\n",
      "           1       0.96      0.95      0.95      1089\n",
      "           2       0.99      0.98      0.99      1044\n",
      "           3       0.99      0.98      0.98      1048\n",
      "           4       0.96      0.95      0.96      1057\n",
      "           5       0.95      0.95      0.95      1072\n",
      "           6       0.94      0.92      0.93      1066\n",
      "           7       1.00      1.00      1.00      1103\n",
      "           8       1.00      1.00      1.00      1108\n",
      "           9       0.94      0.95      0.94      1030\n",
      "          10       0.99      0.96      0.97      1012\n",
      "\n",
      "   micro avg       0.97      0.96      0.97     11703\n",
      "   macro avg       0.97      0.96      0.97     11703\n",
      "weighted avg       0.97      0.96      0.97     11703\n",
      " samples avg       0.96      0.96      0.96     11703\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "list_losses = []\n",
    "list_scores = []\n",
    "list_acc = []\n",
    "list_loss = []\n",
    "list_f1 = []\n",
    "list_precision = []\n",
    "list_recall = []\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    model_dict: dict = {}\n",
    "    x_train, x_valid, y_train, y_valid = get_splitted_data_by_index(\n",
    "        X, y, neuronCats, train_index, test_index\n",
    "    )\n",
    "\n",
    "    model = Model(categories=categories, periodicity=periodicity)\n",
    "    criterion = ComplexMSE_adjusted_error.apply\n",
    "    optimizer = ECL(model.parameters(), lr=lr)\n",
    "\n",
    "    losses, scores = fit(\n",
    "        model,\n",
    "        x_train,\n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        categories=categories,\n",
    "        periodicity=periodicity,\n",
    "    )\n",
    "\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "\n",
    "    list_scores.append(scores)\n",
    "    list_losses.append(losses)\n",
    "\n",
    "    y_pred = model.predict(x_train)\n",
    "    acc = accuracy(y_pred.squeeze(), y_train)\n",
    "    print(\"Train Acc.: \", acc)\n",
    "\n",
    "    y_pred = model.predict(x_valid)\n",
    "    acc = accuracy(y_pred.squeeze(), y_valid)\n",
    "    list_acc.append(acc)\n",
    "\n",
    "    print(classification_report(y_valid, y_pred.detach().numpy(), zero_division=0))\n",
    "    list_f1.append(\n",
    "        f1_score(y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0)\n",
    "    )\n",
    "    list_precision.append(\n",
    "        precision_score(\n",
    "            y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0\n",
    "        )\n",
    "    )\n",
    "    list_recall.append(\n",
    "        recall_score(\n",
    "            y_valid, y_pred.detach().numpy(), average=\"weighted\", zero_division=0\n",
    "        )\n",
    "    )\n",
    "\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_accuracy_mean\",\n",
    "    value=np.mean(list_acc),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_accuracy_std\",\n",
    "    value=np.std(list_acc),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_f1_mean\",\n",
    "    value=np.mean(list_f1),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_f1_std\",\n",
    "    value=np.std(list_f1),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_precision_mean\",\n",
    "    value=np.mean(list_precision),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_precision_std\",\n",
    "    value=np.std(list_precision),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_recall_mean\",\n",
    "    value=np.mean(list_recall),\n",
    ")\n",
    "Logger.current_logger().report_single_value(\n",
    "    name=\"val_recall_std\",\n",
    "    value=np.std(list_recall),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task.mark_completed()\n",
    "task.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('mlmvn')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
