{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XOR\n",
    "\n",
    "> An example of how to solve the XOR problem with MLMVN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The XOR problem is an example of how a single real-valued neuron cannot learn a simple but non-linear relationship. At least, this holds if we do not extend the dimensionality of the feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# |hide\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from mlmvn.layers import OutputLayer, cmplx_phase_activation\n",
    "from mlmvn.loss import ComplexMSELoss\n",
    "from mlmvn.optim import ECL\n",
    "\n",
    "torch.manual_seed(0)  #  for repeatable results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    epochs=20,\n",
    "    classes=2,\n",
    "    kernels=[2],\n",
    "    batch_size=4,\n",
    "    learning_rate=1,\n",
    "    dataset=\"XOR\",\n",
    "    architecture=\"MLMVN\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains four input-output mappings with binary classes. The two-dimensional input $x$ is mapped to a class label $y$. The following table shows the truth table with associated labels for the XOR gate.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\begin{array}{cc|c|cc}\n",
    "        x_1 & x_2 & y & z & arg(z) \\\\\n",
    "        \\hline\n",
    "\t\t1 &  1\t& 0\t&  1+j &  45째 \\\\\n",
    "\t\t1 & -1\t& 1\t&  1-j & 315째 \\\\\n",
    "\t\t-1 &  1\t& 1\t& -1+j & 135째 \\\\\n",
    "\t\t-1 & -1\t& 0\t& -1-j & 225째 \\\\\n",
    "    \\end{array}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "If we consider $x_1$ as $Re(z)$ and $x_2$ as $Im(z)$, the problem can also be expressed graphically into the complex domain. \n",
    "\n",
    "<center>\n",
    "    <img src=\"fig/xor_complex_domain.png\" width=320 />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data\n",
    "x = torch.Tensor([[1.0, 1.0], [1.0, -1.0], [-1.0, 1.0], [-1.0, -1.0]])\n",
    "\n",
    "x = x.type(torch.cdouble)\n",
    "\n",
    "y = torch.Tensor([0.0, 1.0, 1.0, 0.0]).reshape(x.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = OutputLayer(2, 20)\n",
    "        self.phase_act = cmplx_phase_activation()\n",
    "        self.linear1 = OutputLayer(20, 1)\n",
    "        self.phase_act = cmplx_phase_activation()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.phase_act(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BasicModel()\n",
    "criterion = ComplexMSELoss.apply\n",
    "optimizer = ECL(model.parameters(), lr=1)\n",
    "categories = 2\n",
    "periodicity = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(5):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = model(x)\n",
    "\n",
    "    loss = criterion(y_pred, y, categories, periodicity)\n",
    "    # wandb.log({\"loss\": torch.abs(loss)})\n",
    "\n",
    "    if t % 10 == 9:\n",
    "        print(t, torch.abs(loss))\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step(inputs=x, layers=list(model.children()))\n",
    "\n",
    "    # for idx, param in enumerate(model.parameters()):\n",
    "    #     wandb.log({\"weights_layer\"+str(idx)+\"_real\": param.real})\n",
    "    #     wandb.log({\"weights_layer\"+str(idx)+\"_imag\": param.imag})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, param in enumerate(model.parameters()):\n",
    "    param.real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.]], dtype=torch.float64, grad_fn=<RemainderBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def angle2class(x: torch.tensor, categories, periodicity) -> torch.tensor:\n",
    "    tmp = x.angle() + 2 * np.pi\n",
    "    angle = torch.remainder(tmp, 2 * np.pi)\n",
    "\n",
    "    # This will be the discrete output (the number of sector)\n",
    "    o = torch.floor(categories * periodicity * angle / (2 * np.pi))\n",
    "    return torch.remainder(o, categories)\n",
    "\n",
    "\n",
    "angle2class(predictions, 2, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('mlmvn')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
